{
	"amazon-bedrock": {
		"anthropic.claude-3-5-haiku-20241022-v1:0": {
			"id": "anthropic.claude-3-5-haiku-20241022-v1:0",
			"name": "Claude Haiku 3.5",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.8,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic.claude-3-5-sonnet-20240620-v1:0": {
			"id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
			"name": "Claude Sonnet 3.5",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic.claude-3-5-sonnet-20241022-v2:0": {
			"id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
			"name": "Claude Sonnet 3.5 v2",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic.claude-3-haiku-20240307-v1:0": {
			"id": "anthropic.claude-3-haiku-20240307-v1:0",
			"name": "Claude Haiku 3",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 1.25,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic.claude-3-opus-20240229-v1:0": {
			"id": "anthropic.claude-3-opus-20240229-v1:0",
			"name": "Claude Opus 3",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic.claude-3-sonnet-20240229-v1:0": {
			"id": "anthropic.claude-3-sonnet-20240229-v1:0",
			"name": "Claude Sonnet 3",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic.claude-opus-4-6-v1": {
			"id": "anthropic.claude-opus-4-6-v1",
			"name": "Claude Opus 4.6",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"cohere.command-r-plus-v1:0": {
			"id": "cohere.command-r-plus-v1:0",
			"name": "Command R+",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"cohere.command-r-v1:0": {
			"id": "cohere.command-r-v1:0",
			"name": "Command R",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"deepseek.v3-v1:0": {
			"id": "deepseek.v3-v1:0",
			"name": "DeepSeek-V3.1",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.58,
				"output": 1.68,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 81920
		},
		"deepseek.v3.2-v1:0": {
			"id": "deepseek.v3.2-v1:0",
			"name": "DeepSeek-V3.2",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.62,
				"output": 1.85,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 81920
		},
		"eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
			"id": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
			"name": "Claude Haiku 3.5 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.8,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
			"id": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
			"name": "Claude Sonnet 3.5 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
			"id": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
			"name": "Claude Sonnet 3.5 v2 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
			"id": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
			"name": "Claude Sonnet 3.7 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"eu.anthropic.claude-3-haiku-20240307-v1:0": {
			"id": "eu.anthropic.claude-3-haiku-20240307-v1:0",
			"name": "Claude Haiku 3 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 1.25,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"eu.anthropic.claude-3-opus-20240229-v1:0": {
			"id": "eu.anthropic.claude-3-opus-20240229-v1:0",
			"name": "Claude Opus 3 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"eu.anthropic.claude-3-sonnet-20240229-v1:0": {
			"id": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
			"name": "Claude Sonnet 3 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
			"id": "eu.anthropic.claude-haiku-4-5-20251001-v1:0",
			"name": "Claude Haiku 4.5 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"eu.anthropic.claude-opus-4-1-20250805-v1:0": {
			"id": "eu.anthropic.claude-opus-4-1-20250805-v1:0",
			"name": "Claude Opus 4.1 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"eu.anthropic.claude-opus-4-20250514-v1:0": {
			"id": "eu.anthropic.claude-opus-4-20250514-v1:0",
			"name": "Claude Opus 4 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"eu.anthropic.claude-opus-4-5-20251101-v1:0": {
			"id": "eu.anthropic.claude-opus-4-5-20251101-v1:0",
			"name": "Claude Opus 4.5 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"eu.anthropic.claude-opus-4-6-v1": {
			"id": "eu.anthropic.claude-opus-4-6-v1",
			"name": "Claude Opus 4.6 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"eu.anthropic.claude-sonnet-4-20250514-v1:0": {
			"id": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
			"name": "Claude Sonnet 4 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
			"id": "eu.anthropic.claude-sonnet-4-5-20250929-v1:0",
			"name": "Claude Sonnet 4.5 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"eu.anthropic.claude-sonnet-4-6": {
			"id": "eu.anthropic.claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6 (EU)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"global.amazon.nova-2-lite-v1:0": {
			"id": "global.amazon.nova-2-lite-v1:0",
			"name": "Nova 2 Lite",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.33,
				"output": 2.75,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"global.anthropic.claude-haiku-4-5-20251001-v1:0": {
			"id": "global.anthropic.claude-haiku-4-5-20251001-v1:0",
			"name": "Claude Haiku 4.5 (Global)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"global.anthropic.claude-opus-4-5-20251101-v1:0": {
			"id": "global.anthropic.claude-opus-4-5-20251101-v1:0",
			"name": "Claude Opus 4.5 (Global)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"global.anthropic.claude-opus-4-6-v1": {
			"id": "global.anthropic.claude-opus-4-6-v1",
			"name": "Claude Opus 4.6 (Global)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"global.anthropic.claude-sonnet-4-20250514-v1:0": {
			"id": "global.anthropic.claude-sonnet-4-20250514-v1:0",
			"name": "Claude Sonnet 4",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
			"id": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
			"name": "Claude Sonnet 4.5",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"global.anthropic.claude-sonnet-4-6": {
			"id": "global.anthropic.claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"google.gemma-3-27b-it": {
			"id": "google.gemma-3-27b-it",
			"name": "Google Gemma 3 27B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.12,
				"output": 0.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 8192
		},
		"google.gemma-3-4b-it": {
			"id": "google.gemma-3-4b-it",
			"name": "Gemma 3 4B IT",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.04,
				"output": 0.08,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta.llama3-1-70b-instruct-v1:0": {
			"id": "meta.llama3-1-70b-instruct-v1:0",
			"name": "Llama 3.1 70B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.72,
				"output": 0.72,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta.llama3-1-8b-instruct-v1:0": {
			"id": "meta.llama3-1-8b-instruct-v1:0",
			"name": "Llama 3.1 8B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.22,
				"output": 0.22,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"minimax.minimax-m2": {
			"id": "minimax.minimax-m2",
			"name": "MiniMax M2",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204608,
			"maxTokens": 128000
		},
		"minimax.minimax-m2.1": {
			"id": "minimax.minimax-m2.1",
			"name": "MiniMax M2.1",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"mistral.ministral-3-14b-instruct": {
			"id": "mistral.ministral-3-14b-instruct",
			"name": "Ministral 14B 3.0",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.2,
				"output": 0.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"mistral.ministral-3-8b-instruct": {
			"id": "mistral.ministral-3-8b-instruct",
			"name": "Ministral 3 8B",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"mistral.mistral-large-2402-v1:0": {
			"id": "mistral.mistral-large-2402-v1:0",
			"name": "Mistral Large (24.02)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"mistral.voxtral-mini-3b-2507": {
			"id": "mistral.voxtral-mini-3b-2507",
			"name": "Voxtral Mini 3B 2507",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.04,
				"output": 0.04,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"mistral.voxtral-small-24b-2507": {
			"id": "mistral.voxtral-small-24b-2507",
			"name": "Voxtral Small 24B 2507",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.35,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 8192
		},
		"moonshot.kimi-k2-thinking": {
			"id": "moonshot.kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"moonshotai.kimi-k2.5": {
			"id": "moonshotai.kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.6,
				"output": 3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"nvidia.nemotron-nano-12b-v2": {
			"id": "nvidia.nemotron-nano-12b-v2",
			"name": "NVIDIA Nemotron Nano 12B v2 VL BF16",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.2,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia.nemotron-nano-9b-v2": {
			"id": "nvidia.nemotron-nano-9b-v2",
			"name": "NVIDIA Nemotron Nano 9B v2",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.06,
				"output": 0.23,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai.gpt-oss-120b-1:0": {
			"id": "openai.gpt-oss-120b-1:0",
			"name": "gpt-oss-120b",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai.gpt-oss-20b-1:0": {
			"id": "openai.gpt-oss-20b-1:0",
			"name": "gpt-oss-20b",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai.gpt-oss-safeguard-120b": {
			"id": "openai.gpt-oss-safeguard-120b",
			"name": "GPT OSS Safeguard 120B",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai.gpt-oss-safeguard-20b": {
			"id": "openai.gpt-oss-safeguard-20b",
			"name": "GPT OSS Safeguard 20B",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"qwen.qwen3-235b-a22b-2507-v1:0": {
			"id": "qwen.qwen3-235b-a22b-2507-v1:0",
			"name": "Qwen3 235B A22B 2507",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.22,
				"output": 0.88,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 131072
		},
		"qwen.qwen3-32b-v1:0": {
			"id": "qwen.qwen3-32b-v1:0",
			"name": "Qwen3 32B (dense)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 16384,
			"maxTokens": 16384
		},
		"qwen.qwen3-coder-30b-a3b-v1:0": {
			"id": "qwen.qwen3-coder-30b-a3b-v1:0",
			"name": "Qwen3 Coder 30B A3B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 131072
		},
		"qwen.qwen3-coder-480b-a35b-v1:0": {
			"id": "qwen.qwen3-coder-480b-a35b-v1:0",
			"name": "Qwen3 Coder 480B A35B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.22,
				"output": 1.8,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"qwen.qwen3-next-80b-a3b": {
			"id": "qwen.qwen3-next-80b-a3b",
			"name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.14,
				"output": 1.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262000,
			"maxTokens": 262000
		},
		"qwen.qwen3-vl-235b-a22b": {
			"id": "qwen.qwen3-vl-235b-a22b",
			"name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262000,
			"maxTokens": 262000
		},
		"us.amazon.nova-lite-v1:0": {
			"id": "us.amazon.nova-lite-v1:0",
			"name": "Nova Lite",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.06,
				"output": 0.24,
				"cacheRead": 0.015,
				"cacheWrite": 0
			},
			"contextWindow": 300000,
			"maxTokens": 8192
		},
		"us.amazon.nova-micro-v1:0": {
			"id": "us.amazon.nova-micro-v1:0",
			"name": "Nova Micro",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.035,
				"output": 0.14,
				"cacheRead": 0.00875,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"us.amazon.nova-premier-v1:0": {
			"id": "us.amazon.nova-premier-v1:0",
			"name": "Nova Premier",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 12.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 16384
		},
		"us.amazon.nova-pro-v1:0": {
			"id": "us.amazon.nova-pro-v1:0",
			"name": "Nova Pro",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.8,
				"output": 3.2,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 300000,
			"maxTokens": 8192
		},
		"us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
			"id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
			"name": "Claude Sonnet 3.7",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"us.anthropic.claude-haiku-4-5-20251001-v1:0": {
			"id": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
			"name": "Claude Haiku 4.5 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"us.anthropic.claude-opus-4-1-20250805-v1:0": {
			"id": "us.anthropic.claude-opus-4-1-20250805-v1:0",
			"name": "Claude Opus 4.1",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"us.anthropic.claude-opus-4-20250514-v1:0": {
			"id": "us.anthropic.claude-opus-4-20250514-v1:0",
			"name": "Claude Opus 4 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"us.anthropic.claude-opus-4-5-20251101-v1:0": {
			"id": "us.anthropic.claude-opus-4-5-20251101-v1:0",
			"name": "Claude Opus 4.5 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"us.anthropic.claude-opus-4-6-v1": {
			"id": "us.anthropic.claude-opus-4-6-v1",
			"name": "Claude Opus 4.6 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"us.anthropic.claude-sonnet-4-20250514-v1:0": {
			"id": "us.anthropic.claude-sonnet-4-20250514-v1:0",
			"name": "Claude Sonnet 4 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
			"id": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
			"name": "Claude Sonnet 4.5 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"us.anthropic.claude-sonnet-4-6": {
			"id": "us.anthropic.claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6 (US)",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"us.deepseek.r1-v1:0": {
			"id": "us.deepseek.r1-v1:0",
			"name": "DeepSeek-R1",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.35,
				"output": 5.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32768
		},
		"us.meta.llama3-2-11b-instruct-v1:0": {
			"id": "us.meta.llama3-2-11b-instruct-v1:0",
			"name": "Llama 3.2 11B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.16,
				"output": 0.16,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"us.meta.llama3-2-1b-instruct-v1:0": {
			"id": "us.meta.llama3-2-1b-instruct-v1:0",
			"name": "Llama 3.2 1B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.1,
				"output": 0.1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 4096
		},
		"us.meta.llama3-2-3b-instruct-v1:0": {
			"id": "us.meta.llama3-2-3b-instruct-v1:0",
			"name": "Llama 3.2 3B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 4096
		},
		"us.meta.llama3-2-90b-instruct-v1:0": {
			"id": "us.meta.llama3-2-90b-instruct-v1:0",
			"name": "Llama 3.2 90B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.72,
				"output": 0.72,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"us.meta.llama3-3-70b-instruct-v1:0": {
			"id": "us.meta.llama3-3-70b-instruct-v1:0",
			"name": "Llama 3.3 70B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.72,
				"output": 0.72,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"us.meta.llama4-maverick-17b-instruct-v1:0": {
			"id": "us.meta.llama4-maverick-17b-instruct-v1:0",
			"name": "Llama 4 Maverick 17B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.24,
				"output": 0.97,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 16384
		},
		"us.meta.llama4-scout-17b-instruct-v1:0": {
			"id": "us.meta.llama4-scout-17b-instruct-v1:0",
			"name": "Llama 4 Scout 17B Instruct",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.17,
				"output": 0.66,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 3500000,
			"maxTokens": 16384
		},
		"writer.palmyra-x4-v1:0": {
			"id": "writer.palmyra-x4-v1:0",
			"name": "Palmyra X4",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 122880,
			"maxTokens": 8192
		},
		"writer.palmyra-x5-v1:0": {
			"id": "writer.palmyra-x5-v1:0",
			"name": "Palmyra X5",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1040000,
			"maxTokens": 8192
		},
		"zai.glm-4.7": {
			"id": "zai.glm-4.7",
			"name": "GLM-4.7",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"zai.glm-4.7-flash": {
			"id": "zai.glm-4.7-flash",
			"name": "GLM-4.7-Flash",
			"api": "bedrock-converse-stream",
			"provider": "amazon-bedrock",
			"baseUrl": "https://bedrock-runtime.us-east-1.amazonaws.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 131072
		}
	},
	"cloudflare-ai-gateway": {
		"anthropic/claude-3-5-haiku": {
			"id": "anthropic/claude-3-5-haiku",
			"name": "Claude Haiku 3.5 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.8,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3-haiku": {
			"id": "anthropic/claude-3-haiku",
			"name": "Claude Haiku 3",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 1.25,
				"cacheRead": 0.03,
				"cacheWrite": 0.3
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic/claude-3-opus": {
			"id": "anthropic/claude-3-opus",
			"name": "Claude Opus 3",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic/claude-3-sonnet": {
			"id": "anthropic/claude-3-sonnet",
			"name": "Claude Sonnet 3",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 0.3
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic/claude-3.5-haiku": {
			"id": "anthropic/claude-3.5-haiku",
			"name": "Claude Haiku 3.5 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.8,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.5-sonnet": {
			"id": "anthropic/claude-3.5-sonnet",
			"name": "Claude Sonnet 3.5 v2",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-haiku-4-5": {
			"id": "anthropic/claude-haiku-4-5",
			"name": "Claude Haiku 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-opus-4": {
			"id": "anthropic/claude-opus-4",
			"name": "Claude Opus 4 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4-1": {
			"id": "anthropic/claude-opus-4-1",
			"name": "Claude Opus 4.1 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4-5": {
			"id": "anthropic/claude-opus-4-5",
			"name": "Claude Opus 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-opus-4-6": {
			"id": "anthropic/claude-opus-4-6",
			"name": "Claude Opus 4.6 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"anthropic/claude-sonnet-4": {
			"id": "anthropic/claude-sonnet-4",
			"name": "Claude Sonnet 4 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4-5": {
			"id": "anthropic/claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4-6": {
			"id": "anthropic/claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5": {
			"id": "claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"openai/gpt-4": {
			"id": "openai/gpt-4",
			"name": "GPT-4",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 30,
				"output": 60,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"openai/gpt-4-turbo": {
			"id": "openai/gpt-4-turbo",
			"name": "GPT-4 Turbo",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4o": {
			"id": "openai/gpt-4o",
			"name": "GPT-4o",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-mini": {
			"id": "openai/gpt-4o-mini",
			"name": "GPT-4o mini",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.08,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5.1": {
			"id": "openai/gpt-5.1",
			"name": "GPT-5.1",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex": {
			"id": "openai/gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2": {
			"id": "openai/gpt-5.2",
			"name": "GPT-5.2",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-codex": {
			"id": "openai/gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.3-codex": {
			"id": "openai/gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/o1": {
			"id": "openai/o1",
			"name": "o1",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 60,
				"cacheRead": 7.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3": {
			"id": "openai/o3",
			"name": "o3",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-mini": {
			"id": "openai/o3-mini",
			"name": "o3-mini",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-pro": {
			"id": "openai/o3-pro",
			"name": "o3-pro",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 20,
				"output": 80,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini": {
			"id": "openai/o4-mini",
			"name": "o4-mini",
			"api": "anthropic-messages",
			"provider": "cloudflare-ai-gateway",
			"baseUrl": "https://gateway.ai.cloudflare.com/v1/<account>/<gateway>/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.28,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		}
	},
	"opencode": {
		"big-pickle": {
			"id": "big-pickle",
			"name": "Big Pickle",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"claude-3-5-haiku": {
			"id": "claude-3-5-haiku",
			"name": "Claude Haiku 3.5",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.8,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"claude-haiku-4-5": {
			"id": "claude-haiku-4-5",
			"name": "Claude Haiku 4.5",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-1": {
			"id": "claude-opus-4-1",
			"name": "Claude Opus 4.1",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-5": {
			"id": "claude-opus-4-5",
			"name": "Claude Opus 4.5",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-6": {
			"id": "claude-opus-4-6",
			"name": "Claude Opus 4.6",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"claude-sonnet-4": {
			"id": "claude-sonnet-4",
			"name": "Claude Sonnet 4",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5": {
			"id": "claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-6": {
			"id": "claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"gemini-3-flash": {
			"id": "gemini-3-flash",
			"name": "Gemini 3 Flash",
			"api": "google-generative-ai",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 3,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro": {
			"id": "gemini-3-pro",
			"name": "Gemini 3 Pro",
			"api": "google-generative-ai",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3.1-pro": {
			"id": "gemini-3.1-pro",
			"name": "Gemini 3.1 Pro Preview",
			"api": "google-generative-ai",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"glm-4.6": {
			"id": "glm-4.6",
			"name": "GLM-4.6",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.2,
				"cacheRead": 0.1,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-4.7": {
			"id": "glm-4.7",
			"name": "GLM-4.7",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.2,
				"cacheRead": 0.1,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-5": {
			"id": "glm-5",
			"name": "GLM-5",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3.2,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-5-free": {
			"id": "glm-5-free",
			"name": "GLM-5 Free",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"gpt-5": {
			"id": "gpt-5",
			"name": "GPT-5",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.07,
				"output": 8.5,
				"cacheRead": 0.107,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5-codex": {
			"id": "gpt-5-codex",
			"name": "GPT-5 Codex",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.07,
				"output": 8.5,
				"cacheRead": 0.107,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5-nano": {
			"id": "gpt-5-nano",
			"name": "GPT-5 Nano",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.1": {
			"id": "gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.07,
				"output": 8.5,
				"cacheRead": 0.107,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex": {
			"id": "gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.07,
				"output": 8.5,
				"cacheRead": 0.107,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-max": {
			"id": "gpt-5.1-codex-max",
			"name": "GPT-5.1 Codex Max",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-mini": {
			"id": "gpt-5.1-codex-mini",
			"name": "GPT-5.1 Codex Mini",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.2": {
			"id": "gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.2-codex": {
			"id": "gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex": {
			"id": "gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-responses",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"kimi-k2": {
			"id": "kimi-k2",
			"name": "Kimi K2",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.4,
				"output": 2.5,
				"cacheRead": 0.4,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"kimi-k2-thinking": {
			"id": "kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.4,
				"output": 2.5,
				"cacheRead": 0.4,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"kimi-k2.5": {
			"id": "kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.6,
				"output": 3,
				"cacheRead": 0.08,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"kimi-k2.5-free": {
			"id": "kimi-k2.5-free",
			"name": "Kimi K2.5 Free",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"minimax-m2.1": {
			"id": "minimax-m2.1",
			"name": "MiniMax M2.1",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.1,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"minimax-m2.5": {
			"id": "minimax-m2.5",
			"name": "MiniMax M2.5",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.06,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"minimax-m2.5-free": {
			"id": "minimax-m2.5-free",
			"name": "MiniMax M2.5 Free",
			"api": "anthropic-messages",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"trinity-large-preview-free": {
			"id": "trinity-large-preview-free",
			"name": "Trinity Large Preview",
			"api": "openai-completions",
			"provider": "opencode",
			"baseUrl": "https://opencode.ai/zen/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		}
	},
	"anthropic": {
		"claude-3-5-sonnet-20240620": {
			"id": "claude-3-5-sonnet-20240620",
			"name": "Claude Sonnet 3.5",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"claude-3-5-sonnet-20241022": {
			"id": "claude-3-5-sonnet-20241022",
			"name": "Claude Sonnet 3.5 v2",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"claude-3-haiku-20240307": {
			"id": "claude-3-haiku-20240307",
			"name": "Claude Haiku 3",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 1.25,
				"cacheRead": 0.03,
				"cacheWrite": 0.3
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"claude-haiku-4-5": {
			"id": "claude-haiku-4-5",
			"name": "Claude Haiku 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-haiku-4-5-20251001": {
			"id": "claude-haiku-4-5-20251001",
			"name": "Claude Haiku 4.5",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-0": {
			"id": "claude-opus-4-0",
			"name": "Claude Opus 4 (latest)",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-1": {
			"id": "claude-opus-4-1",
			"name": "Claude Opus 4.1 (latest)",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-1-20250805": {
			"id": "claude-opus-4-1-20250805",
			"name": "Claude Opus 4.1",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-20250514": {
			"id": "claude-opus-4-20250514",
			"name": "Claude Opus 4",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-5": {
			"id": "claude-opus-4-5",
			"name": "Claude Opus 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-5-20251101": {
			"id": "claude-opus-4-5-20251101",
			"name": "Claude Opus 4.5",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-6": {
			"id": "claude-opus-4-6",
			"name": "Claude Opus 4.6",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"claude-sonnet-4-0": {
			"id": "claude-sonnet-4-0",
			"name": "Claude Sonnet 4 (latest)",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-20250514": {
			"id": "claude-sonnet-4-20250514",
			"name": "Claude Sonnet 4",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5": {
			"id": "claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5 (latest)",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5-20250929": {
			"id": "claude-sonnet-4-5-20250929",
			"name": "Claude Sonnet 4.5",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-6": {
			"id": "claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "anthropic-messages",
			"provider": "anthropic",
			"baseUrl": "https://api.anthropic.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		}
	},
	"github-copilot": {
		"claude-haiku-4.5": {
			"id": "claude-haiku-4.5",
			"name": "Claude Haiku 4.5",
			"api": "anthropic-messages",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"claude-opus-4.5": {
			"id": "claude-opus-4.5",
			"name": "Claude Opus 4.5",
			"api": "anthropic-messages",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"claude-opus-4.6": {
			"id": "claude-opus-4.6",
			"name": "Claude Opus 4.6",
			"api": "anthropic-messages",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"claude-sonnet-4": {
			"id": "claude-sonnet-4",
			"name": "Claude Sonnet 4",
			"api": "anthropic-messages",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"claude-sonnet-4.5": {
			"id": "claude-sonnet-4.5",
			"name": "Claude Sonnet 4.5",
			"api": "anthropic-messages",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"claude-sonnet-4.6": {
			"id": "claude-sonnet-4.6",
			"name": "Claude Sonnet 4.6",
			"api": "anthropic-messages",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 32000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gemini-3-flash-preview": {
			"id": "gemini-3-flash-preview",
			"name": "Gemini 3 Flash",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gemini-3.1-pro-preview": {
			"id": "gemini-3.1-pro-preview",
			"name": "Gemini 3.1 Pro Preview",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gpt-4.1": {
			"id": "gpt-4.1",
			"name": "GPT-4.1",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 64000,
			"maxTokens": 16384,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gpt-4o": {
			"id": "gpt-4o",
			"name": "GPT-4o",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 64000,
			"maxTokens": 16384,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gpt-5": {
			"id": "gpt-5",
			"name": "GPT-5",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5-mini": {
			"id": "gpt-5-mini",
			"name": "GPT-5-mini",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5.1": {
			"id": "gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5.1-codex": {
			"id": "gpt-5.1-codex",
			"name": "GPT-5.1-Codex",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5.1-codex-max": {
			"id": "gpt-5.1-codex-max",
			"name": "GPT-5.1-Codex-max",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5.1-codex-mini": {
			"id": "gpt-5.1-codex-mini",
			"name": "GPT-5.1-Codex-mini",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5.2": {
			"id": "gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"gpt-5.2-codex": {
			"id": "gpt-5.2-codex",
			"name": "GPT-5.2-Codex",
			"api": "openai-responses",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			}
		},
		"grok-code-fast-1": {
			"id": "grok-code-fast-1",
			"name": "Grok Code Fast 1",
			"api": "openai-completions",
			"provider": "github-copilot",
			"baseUrl": "https://api.individual.githubcopilot.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		}
	},
	"mistral": {
		"codestral-latest": {
			"id": "codestral-latest",
			"name": "Codestral",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.9,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 4096
		},
		"devstral-2512": {
			"id": "devstral-2512",
			"name": "Devstral 2",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.4,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"devstral-medium-2507": {
			"id": "devstral-medium-2507",
			"name": "Devstral Medium",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.4,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"devstral-medium-latest": {
			"id": "devstral-medium-latest",
			"name": "Devstral 2",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.4,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"devstral-small-2505": {
			"id": "devstral-small-2505",
			"name": "Devstral Small 2505",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.1,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"devstral-small-2507": {
			"id": "devstral-small-2507",
			"name": "Devstral Small",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.1,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"labs-devstral-small-2512": {
			"id": "labs-devstral-small-2512",
			"name": "Devstral Small 2",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"magistral-medium-latest": {
			"id": "magistral-medium-latest",
			"name": "Magistral Medium",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"magistral-small": {
			"id": "magistral-small",
			"name": "Magistral Small",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"ministral-3b-latest": {
			"id": "ministral-3b-latest",
			"name": "Ministral 3B",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.04,
				"output": 0.04,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"ministral-8b-latest": {
			"id": "ministral-8b-latest",
			"name": "Ministral 8B",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.1,
				"output": 0.1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"mistral-large-2411": {
			"id": "mistral-large-2411",
			"name": "Mistral Large 2.1",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"mistral-large-2512": {
			"id": "mistral-large-2512",
			"name": "Mistral Large 3",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistral-large-latest": {
			"id": "mistral-large-latest",
			"name": "Mistral Large",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistral-medium-2505": {
			"id": "mistral-medium-2505",
			"name": "Mistral Medium 3",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.4,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"mistral-medium-2508": {
			"id": "mistral-medium-2508",
			"name": "Mistral Medium 3.1",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.4,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistral-medium-latest": {
			"id": "mistral-medium-latest",
			"name": "Mistral Medium",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.4,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"mistral-nemo": {
			"id": "mistral-nemo",
			"name": "Mistral Nemo",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"mistral-small-2506": {
			"id": "mistral-small-2506",
			"name": "Mistral Small 3.2",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"mistral-small-latest": {
			"id": "mistral-small-latest",
			"name": "Mistral Small",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"open-mistral-7b": {
			"id": "open-mistral-7b",
			"name": "Mistral 7B",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 0.25,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8000,
			"maxTokens": 8000
		},
		"open-mixtral-8x22b": {
			"id": "open-mixtral-8x22b",
			"name": "Mixtral 8x22B",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 64000,
			"maxTokens": 64000
		},
		"open-mixtral-8x7b": {
			"id": "open-mixtral-8x7b",
			"name": "Mixtral 8x7B",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.7,
				"output": 0.7,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 32000
		},
		"pixtral-12b": {
			"id": "pixtral-12b",
			"name": "Pixtral 12B",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"pixtral-large-latest": {
			"id": "pixtral-large-latest",
			"name": "Pixtral Large",
			"api": "openai-completions",
			"provider": "mistral",
			"baseUrl": "https://api.mistral.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		}
	},
	"openai": {
		"codex-mini-latest": {
			"id": "codex-mini-latest",
			"name": "Codex Mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.5,
				"output": 6,
				"cacheRead": 0.375,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 100000
		},
		"gpt-4": {
			"id": "gpt-4",
			"name": "GPT-4",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 30,
				"output": 60,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"gpt-4-turbo": {
			"id": "gpt-4-turbo",
			"name": "GPT-4 Turbo",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"gpt-4.1": {
			"id": "gpt-4.1",
			"name": "GPT-4.1",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"gpt-4.1-mini": {
			"id": "gpt-4.1-mini",
			"name": "GPT-4.1 mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.4,
				"output": 1.6,
				"cacheRead": 0.1,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"gpt-4.1-nano": {
			"id": "gpt-4.1-nano",
			"name": "GPT-4.1 nano",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"gpt-4o": {
			"id": "gpt-4o",
			"name": "GPT-4o",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-4o-2024-05-13": {
			"id": "gpt-4o-2024-05-13",
			"name": "GPT-4o (2024-05-13)",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"gpt-4o-2024-08-06": {
			"id": "gpt-4o-2024-08-06",
			"name": "GPT-4o (2024-08-06)",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-4o-2024-11-20": {
			"id": "gpt-4o-2024-11-20",
			"name": "GPT-4o (2024-11-20)",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-4o-mini": {
			"id": "gpt-4o-mini",
			"name": "GPT-4o mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.08,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-5": {
			"id": "gpt-5",
			"name": "GPT-5",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5-chat-latest": {
			"id": "gpt-5-chat-latest",
			"name": "GPT-5 Chat Latest",
			"api": "openai-responses",
			"baseUrl": "https://api.openai.com/v1",
			"provider": "openai",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-5-codex": {
			"id": "gpt-5-codex",
			"name": "GPT-5-Codex",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5-mini": {
			"id": "gpt-5-mini",
			"name": "GPT-5 Mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5-nano": {
			"id": "gpt-5-nano",
			"name": "GPT-5 Nano",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.05,
				"output": 0.4,
				"cacheRead": 0.005,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5-pro": {
			"id": "gpt-5-pro",
			"name": "GPT-5 Pro",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 120,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 272000
		},
		"gpt-5.1": {
			"id": "gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.1-chat-latest": {
			"id": "gpt-5.1-chat-latest",
			"name": "GPT-5.1 Chat",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-5.1-codex": {
			"id": "gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-max": {
			"id": "gpt-5.1-codex-max",
			"name": "GPT-5.1 Codex Max",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-mini": {
			"id": "gpt-5.1-codex-mini",
			"name": "GPT-5.1 Codex mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.2": {
			"id": "gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.2-chat-latest": {
			"id": "gpt-5.2-chat-latest",
			"name": "GPT-5.2 Chat",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"gpt-5.2-codex": {
			"id": "gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.2-pro": {
			"id": "gpt-5.2-pro",
			"name": "GPT-5.2 Pro",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 21,
				"output": 168,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex": {
			"id": "gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex-spark": {
			"id": "gpt-5.3-codex-spark",
			"name": "GPT-5.3 Codex Spark",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000,
			"contextPromotionTarget": "openai/gpt-5.3-codex"
		},
		"o1": {
			"id": "o1",
			"name": "o1",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 60,
				"cacheRead": 7.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o1-pro": {
			"id": "o1-pro",
			"name": "o1-pro",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 150,
				"output": 600,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o3": {
			"id": "o3",
			"name": "o3",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o3-deep-research": {
			"id": "o3-deep-research",
			"name": "o3-deep-research",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 40,
				"cacheRead": 2.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o3-mini": {
			"id": "o3-mini",
			"name": "o3-mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o3-pro": {
			"id": "o3-pro",
			"name": "o3-pro",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 20,
				"output": 80,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o4-mini": {
			"id": "o4-mini",
			"name": "o4-mini",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.28,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"o4-mini-deep-research": {
			"id": "o4-mini-deep-research",
			"name": "o4-mini-deep-research",
			"api": "openai-responses",
			"provider": "openai",
			"baseUrl": "https://api.openai.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		}
	},
	"nvidia": {
		"deepseek-ai/deepseek-coder-6.7b-instruct": {
			"id": "deepseek-ai/deepseek-coder-6.7b-instruct",
			"name": "Deepseek Coder 6.7b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"deepseek-ai/deepseek-r1-0528": {
			"id": "deepseek-ai/deepseek-r1-0528",
			"name": "Deepseek R1 0528",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"deepseek-ai/deepseek-v3.1": {
			"id": "deepseek-ai/deepseek-v3.1",
			"name": "DeepSeek V3.1",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"deepseek-ai/deepseek-v3.1-terminus": {
			"id": "deepseek-ai/deepseek-v3.1-terminus",
			"name": "DeepSeek V3.1 Terminus",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"deepseek-ai/deepseek-v3.2": {
			"id": "deepseek-ai/deepseek-v3.2",
			"name": "DeepSeek V3.2",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 65536
		},
		"google/gemma-2-27b-it": {
			"id": "google/gemma-2-27b-it",
			"name": "Gemma 2 27b It",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-2-2b-it": {
			"id": "google/gemma-2-2b-it",
			"name": "Gemma 2 2b It",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-3-12b-it": {
			"id": "google/gemma-3-12b-it",
			"name": "Gemma 3 12b It",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-3-1b-it": {
			"id": "google/gemma-3-1b-it",
			"name": "Gemma 3 1b It",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-3-27b-it": {
			"id": "google/gemma-3-27b-it",
			"name": "Gemma-3-27B-IT",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"google/gemma-3n-e2b-it": {
			"id": "google/gemma-3n-e2b-it",
			"name": "Gemma 3n E2b It",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-3n-e4b-it": {
			"id": "google/gemma-3n-e4b-it",
			"name": "Gemma 3n E4b It",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-3.1-405b-instruct": {
			"id": "meta/llama-3.1-405b-instruct",
			"name": "Llama 3.1 405b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-3.1-70b-instruct": {
			"id": "meta/llama-3.1-70b-instruct",
			"name": "Llama 3.1 70b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-3.2-11b-vision-instruct": {
			"id": "meta/llama-3.2-11b-vision-instruct",
			"name": "Llama 3.2 11b Vision Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-3.2-1b-instruct": {
			"id": "meta/llama-3.2-1b-instruct",
			"name": "Llama 3.2 1b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-3.3-70b-instruct": {
			"id": "meta/llama-3.3-70b-instruct",
			"name": "Llama 3.3 70b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-4-maverick-17b-128e-instruct": {
			"id": "meta/llama-4-maverick-17b-128e-instruct",
			"name": "Llama 4 Maverick 17b 128e Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama-4-scout-17b-16e-instruct": {
			"id": "meta/llama-4-scout-17b-16e-instruct",
			"name": "Llama 4 Scout 17b 16e Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama3-70b-instruct": {
			"id": "meta/llama3-70b-instruct",
			"name": "Llama3 70b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"meta/llama3-8b-instruct": {
			"id": "meta/llama3-8b-instruct",
			"name": "Llama3 8b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"microsoft/phi-3-medium-128k-instruct": {
			"id": "microsoft/phi-3-medium-128k-instruct",
			"name": "Phi 3 Medium 128k Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"microsoft/phi-3-medium-4k-instruct": {
			"id": "microsoft/phi-3-medium-4k-instruct",
			"name": "Phi 3 Medium 4k Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4000,
			"maxTokens": 4096
		},
		"microsoft/phi-3-small-128k-instruct": {
			"id": "microsoft/phi-3-small-128k-instruct",
			"name": "Phi 3 Small 128k Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"microsoft/phi-3-small-8k-instruct": {
			"id": "microsoft/phi-3-small-8k-instruct",
			"name": "Phi 3 Small 8k Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8000,
			"maxTokens": 4096
		},
		"microsoft/phi-3-vision-128k-instruct": {
			"id": "microsoft/phi-3-vision-128k-instruct",
			"name": "Phi 3 Vision 128k Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"microsoft/phi-3.5-moe-instruct": {
			"id": "microsoft/phi-3.5-moe-instruct",
			"name": "Phi 3.5 Moe Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"microsoft/phi-3.5-vision-instruct": {
			"id": "microsoft/phi-3.5-vision-instruct",
			"name": "Phi 3.5 Vision Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"microsoft/phi-4-mini-instruct": {
			"id": "microsoft/phi-4-mini-instruct",
			"name": "Phi-4-Mini",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"minimaxai/minimax-m2": {
			"id": "minimaxai/minimax-m2",
			"name": "MiniMax-M2",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"minimaxai/minimax-m2.1": {
			"id": "minimaxai/minimax-m2.1",
			"name": "MiniMax-M2.1",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"mistralai/codestral-22b-instruct-v0.1": {
			"id": "mistralai/codestral-22b-instruct-v0.1",
			"name": "Codestral 22b Instruct V0.1",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"mistralai/devstral-2-123b-instruct-2512": {
			"id": "mistralai/devstral-2-123b-instruct-2512",
			"name": "Devstral-2-123B-Instruct-2512",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistralai/ministral-14b-instruct-2512": {
			"id": "mistralai/ministral-14b-instruct-2512",
			"name": "Ministral 3 14B Instruct 2512",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistralai/mistral-large-2-instruct": {
			"id": "mistralai/mistral-large-2-instruct",
			"name": "Mistral Large 2 Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"mistralai/mistral-large-3-675b-instruct-2512": {
			"id": "mistralai/mistral-large-3-675b-instruct-2512",
			"name": "Mistral Large 3 675B Instruct 2512",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistralai/mistral-small-3.1-24b-instruct-2503": {
			"id": "mistralai/mistral-small-3.1-24b-instruct-2503",
			"name": "Mistral Small 3.1 24b Instruct 2503",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"moonshotai/kimi-k2-instruct": {
			"id": "moonshotai/kimi-k2-instruct",
			"name": "Kimi K2 Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"moonshotai/kimi-k2-instruct-0905": {
			"id": "moonshotai/kimi-k2-instruct-0905",
			"name": "Kimi K2 0905",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2-thinking": {
			"id": "moonshotai/kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2.5": {
			"id": "moonshotai/kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"nvidia/llama-3.1-nemotron-51b-instruct": {
			"id": "nvidia/llama-3.1-nemotron-51b-instruct",
			"name": "Llama 3.1 Nemotron 51b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia/llama-3.1-nemotron-70b-instruct": {
			"id": "nvidia/llama-3.1-nemotron-70b-instruct",
			"name": "Llama 3.1 Nemotron 70b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia/llama-3.1-nemotron-ultra-253b-v1": {
			"id": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
			"name": "Llama-3.1-Nemotron-Ultra-253B-v1",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"nvidia/llama3-chatqa-1.5-70b": {
			"id": "nvidia/llama3-chatqa-1.5-70b",
			"name": "Llama3 Chatqa 1.5 70b",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia/mistral-nemo-minitron-8b-8k-instruct": {
			"id": "nvidia/mistral-nemo-minitron-8b-8k-instruct",
			"name": "nvidia/mistral-nemo-minitron-8b-8k-instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 4096
		},
		"nvidia/nemotron-3-nano-30b-a3b": {
			"id": "nvidia/nemotron-3-nano-30b-a3b",
			"name": "nemotron-3-nano-30b-a3b",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"nvidia/nemotron-4-340b-instruct": {
			"id": "nvidia/nemotron-4-340b-instruct",
			"name": "Nemotron 4 340b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia/nvidia-nemotron-nano-9b-v2": {
			"id": "nvidia/nvidia-nemotron-nano-9b-v2",
			"name": "nvidia-nemotron-nano-9b-v2",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"qwen/qwen2.5-coder-32b-instruct": {
			"id": "qwen/qwen2.5-coder-32b-instruct",
			"name": "Qwen2.5 Coder 32b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"qwen/qwen2.5-coder-7b-instruct": {
			"id": "qwen/qwen2.5-coder-7b-instruct",
			"name": "Qwen2.5 Coder 7b Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"qwen/qwen3-235b-a22b": {
			"id": "qwen/qwen3-235b-a22b",
			"name": "Qwen3-235B-A22B",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"qwen/qwen3-coder-480b-a35b-instruct": {
			"id": "qwen/qwen3-coder-480b-a35b-instruct",
			"name": "Qwen3 Coder 480B A35B Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 66536
		},
		"qwen/qwen3-next-80b-a3b-instruct": {
			"id": "qwen/qwen3-next-80b-a3b-instruct",
			"name": "Qwen3-Next-80B-A3B-Instruct",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"qwen/qwen3-next-80b-a3b-thinking": {
			"id": "qwen/qwen3-next-80b-a3b-thinking",
			"name": "Qwen3-Next-80B-A3B-Thinking",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"z-ai/glm4.7": {
			"id": "z-ai/glm4.7",
			"name": "GLM-4.7",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"z-ai/glm5": {
			"id": "z-ai/glm5",
			"name": "GLM5",
			"api": "openai-completions",
			"provider": "nvidia",
			"baseUrl": "https://integrate.api.nvidia.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 131000
		}
	},
	"groq": {
		"deepseek-r1-distill-llama-70b": {
			"id": "deepseek-r1-distill-llama-70b",
			"name": "DeepSeek R1 Distill Llama 70B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.75,
				"output": 0.99,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"gemma2-9b-it": {
			"id": "gemma2-9b-it",
			"name": "Gemma 2 9B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.2,
				"output": 0.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"llama-3.1-8b-instant": {
			"id": "llama-3.1-8b-instant",
			"name": "Llama 3.1 8B Instant",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.05,
				"output": 0.08,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"llama-3.3-70b-versatile": {
			"id": "llama-3.3-70b-versatile",
			"name": "Llama 3.3 70B Versatile",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.59,
				"output": 0.79,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"llama3-70b-8192": {
			"id": "llama3-70b-8192",
			"name": "Llama 3 70B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.59,
				"output": 0.79,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"llama3-8b-8192": {
			"id": "llama3-8b-8192",
			"name": "Llama 3 8B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.05,
				"output": 0.08,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"meta-llama/llama-4-maverick-17b-128e-instruct": {
			"id": "meta-llama/llama-4-maverick-17b-128e-instruct",
			"name": "Llama 4 Maverick 17B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.2,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"meta-llama/llama-4-scout-17b-16e-instruct": {
			"id": "meta-llama/llama-4-scout-17b-16e-instruct",
			"name": "Llama 4 Scout 17B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.11,
				"output": 0.34,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"mistral-saba-24b": {
			"id": "mistral-saba-24b",
			"name": "Mistral Saba 24B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.79,
				"output": 0.79,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"moonshotai/kimi-k2-instruct": {
			"id": "moonshotai/kimi-k2-instruct",
			"name": "Kimi K2 Instruct",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"moonshotai/kimi-k2-instruct-0905": {
			"id": "moonshotai/kimi-k2-instruct-0905",
			"name": "Kimi K2 Instruct 0905",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"openai/gpt-oss-120b": {
			"id": "openai/gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-20b": {
			"id": "openai/gpt-oss-20b",
			"name": "GPT OSS 20B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"qwen-qwq-32b": {
			"id": "qwen-qwq-32b",
			"name": "Qwen QwQ 32B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.29,
				"output": 0.39,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"qwen/qwen3-32b": {
			"id": "qwen/qwen3-32b",
			"name": "Qwen3 32B",
			"api": "openai-completions",
			"provider": "groq",
			"baseUrl": "https://api.groq.com/openai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.29,
				"output": 0.59,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		}
	},
	"google": {
		"gemini-1.5-flash": {
			"id": "gemini-1.5-flash",
			"name": "Gemini 1.5 Flash",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0.01875,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 8192
		},
		"gemini-1.5-flash-8b": {
			"id": "gemini-1.5-flash-8b",
			"name": "Gemini 1.5 Flash-8B",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.0375,
				"output": 0.15,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 8192
		},
		"gemini-1.5-pro": {
			"id": "gemini-1.5-pro",
			"name": "Gemini 1.5 Pro",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 5,
				"cacheRead": 0.3125,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 8192
		},
		"gemini-2.0-flash": {
			"id": "gemini-2.0-flash",
			"name": "Gemini 2.0 Flash",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"gemini-2.0-flash-lite": {
			"id": "gemini-2.0-flash-lite",
			"name": "Gemini 2.0 Flash Lite",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"gemini-2.5-flash": {
			"id": "gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite": {
			"id": "gemini-2.5-flash-lite",
			"name": "Gemini 2.5 Flash Lite",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite-preview-06-17": {
			"id": "gemini-2.5-flash-lite-preview-06-17",
			"name": "Gemini 2.5 Flash Lite Preview 06-17",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite-preview-09-2025": {
			"id": "gemini-2.5-flash-lite-preview-09-2025",
			"name": "Gemini 2.5 Flash Lite Preview 09-25",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-preview-04-17": {
			"id": "gemini-2.5-flash-preview-04-17",
			"name": "Gemini 2.5 Flash Preview 04-17",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.0375,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-preview-05-20": {
			"id": "gemini-2.5-flash-preview-05-20",
			"name": "Gemini 2.5 Flash Preview 05-20",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.0375,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-preview-09-2025": {
			"id": "gemini-2.5-flash-preview-09-2025",
			"name": "Gemini 2.5 Flash Preview 09-25",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.31,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro-preview-05-06": {
			"id": "gemini-2.5-pro-preview-05-06",
			"name": "Gemini 2.5 Pro Preview 05-06",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.31,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro-preview-06-05": {
			"id": "gemini-2.5-pro-preview-06-05",
			"name": "Gemini 2.5 Pro Preview 06-05",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.31,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-flash-preview": {
			"id": "gemini-3-flash-preview",
			"name": "Gemini 3 Flash Preview",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 3,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"gemini-3.1-pro-preview": {
			"id": "gemini-3.1-pro-preview",
			"name": "Gemini 3.1 Pro Preview",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3.1-pro-preview-customtools": {
			"id": "gemini-3.1-pro-preview-customtools",
			"name": "Gemini 3.1 Pro Preview Custom Tools",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-flash-latest": {
			"id": "gemini-flash-latest",
			"name": "Gemini Flash Latest",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-flash-lite-latest": {
			"id": "gemini-flash-lite-latest",
			"name": "Gemini Flash-Lite Latest",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-live-2.5-flash": {
			"id": "gemini-live-2.5-flash",
			"name": "Gemini Live 2.5 Flash",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8000
		},
		"gemini-live-2.5-flash-preview-native-audio": {
			"id": "gemini-live-2.5-flash-preview-native-audio",
			"name": "Gemini Live 2.5 Flash Preview Native Audio",
			"api": "google-generative-ai",
			"provider": "google",
			"baseUrl": "https://generativelanguage.googleapis.com/v1beta",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		}
	},
	"zai": {
		"glm-4.5": {
			"id": "glm-4.5",
			"name": "GLM-4.5",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 98304
		},
		"glm-4.5-air": {
			"id": "glm-4.5-air",
			"name": "GLM-4.5-Air",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 98304
		},
		"glm-4.5-flash": {
			"id": "glm-4.5-flash",
			"name": "GLM-4.5-Flash",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 98304
		},
		"glm-4.5v": {
			"id": "glm-4.5v",
			"name": "GLM-4.5V",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 64000,
			"maxTokens": 16384
		},
		"glm-4.6": {
			"id": "glm-4.6",
			"name": "GLM-4.6",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-4.6v": {
			"id": "glm-4.6v",
			"name": "GLM-4.6V",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32768
		},
		"glm-4.7": {
			"id": "glm-4.7",
			"name": "GLM-4.7",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-4.7-flash": {
			"id": "glm-4.7-flash",
			"name": "GLM-4.7-Flash",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 131072
		},
		"glm-4.7-flashx": {
			"id": "glm-4.7-flashx",
			"name": "GLM-4.7-FlashX",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.4,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 131072
		},
		"glm-5": {
			"id": "glm-5",
			"name": "GLM-5",
			"api": "anthropic-messages",
			"provider": "zai",
			"baseUrl": "https://api.z.ai/api/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		}
	},
	"cerebras": {
		"gpt-oss-120b": {
			"id": "gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "openai-completions",
			"provider": "cerebras",
			"baseUrl": "https://api.cerebras.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 0.69,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"llama3.1-8b": {
			"id": "llama3.1-8b",
			"name": "Llama 3.1 8B",
			"api": "openai-completions",
			"provider": "cerebras",
			"baseUrl": "https://api.cerebras.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.1,
				"output": 0.1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 8000
		},
		"qwen-3-235b-a22b-instruct-2507": {
			"id": "qwen-3-235b-a22b-instruct-2507",
			"name": "Qwen 3 235B Instruct",
			"api": "openai-completions",
			"provider": "cerebras",
			"baseUrl": "https://api.cerebras.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 32000
		},
		"qwen-3-coder-480b": {
			"id": "qwen-3-coder-480b",
			"name": "qwen-3-coder-480b",
			"api": "openai-completions",
			"provider": "cerebras",
			"baseUrl": "https://api.cerebras.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"zai-glm-4.6": {
			"id": "zai-glm-4.6",
			"name": "zai-glm-4.6",
			"api": "openai-completions",
			"provider": "cerebras",
			"baseUrl": "https://api.cerebras.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"zai-glm-4.7": {
			"id": "zai-glm-4.7",
			"name": "Z.AI GLM-4.7",
			"api": "openai-completions",
			"provider": "cerebras",
			"baseUrl": "https://api.cerebras.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.25,
				"output": 2.75,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 40000
		}
	},
	"xai": {
		"grok-2": {
			"id": "grok-2",
			"name": "Grok 2",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 2,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-2-1212": {
			"id": "grok-2-1212",
			"name": "Grok 2 (1212)",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 2,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-2-latest": {
			"id": "grok-2-latest",
			"name": "Grok 2 Latest",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 2,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-2-vision": {
			"id": "grok-2-vision",
			"name": "Grok 2 Vision",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 2,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 4096
		},
		"grok-2-vision-1212": {
			"id": "grok-2-vision-1212",
			"name": "Grok 2 Vision (1212)",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 2,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 4096
		},
		"grok-2-vision-latest": {
			"id": "grok-2-vision-latest",
			"name": "Grok 2 Vision Latest",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 2,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 4096
		},
		"grok-3": {
			"id": "grok-3",
			"name": "Grok 3",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.75,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-fast": {
			"id": "grok-3-fast",
			"name": "Grok 3 Fast",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-fast-latest": {
			"id": "grok-3-fast-latest",
			"name": "Grok 3 Fast Latest",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-latest": {
			"id": "grok-3-latest",
			"name": "Grok 3 Latest",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.75,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-mini": {
			"id": "grok-3-mini",
			"name": "Grok 3 Mini",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-mini-fast": {
			"id": "grok-3-mini-fast",
			"name": "Grok 3 Mini Fast",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 4,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-mini-fast-latest": {
			"id": "grok-3-mini-fast-latest",
			"name": "Grok 3 Mini Fast Latest",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 4,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-3-mini-latest": {
			"id": "grok-3-mini-latest",
			"name": "Grok 3 Mini Latest",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"grok-4": {
			"id": "grok-4",
			"name": "Grok 4",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.75,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 64000
		},
		"grok-4-1-fast": {
			"id": "grok-4-1-fast",
			"name": "Grok 4.1 Fast",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.2,
				"output": 0.5,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"grok-4-1-fast-non-reasoning": {
			"id": "grok-4-1-fast-non-reasoning",
			"name": "Grok 4.1 Fast (Non-Reasoning)",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.2,
				"output": 0.5,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"grok-4-fast": {
			"id": "grok-4-fast",
			"name": "Grok 4 Fast",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.2,
				"output": 0.5,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"grok-4-fast-non-reasoning": {
			"id": "grok-4-fast-non-reasoning",
			"name": "Grok 4 Fast (Non-Reasoning)",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.2,
				"output": 0.5,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"grok-beta": {
			"id": "grok-beta",
			"name": "Grok Beta",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 5,
				"output": 15,
				"cacheRead": 5,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 4096
		},
		"grok-code-fast-1": {
			"id": "grok-code-fast-1",
			"name": "Grok Code Fast 1",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.2,
				"output": 1.5,
				"cacheRead": 0.02,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 10000
		},
		"grok-vision-beta": {
			"id": "grok-vision-beta",
			"name": "Grok Vision Beta",
			"api": "openai-completions",
			"provider": "xai",
			"baseUrl": "https://api.x.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 15,
				"cacheRead": 5,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 4096
		}
	},
	"xiaomi": {
		"mimo-v2-flash": {
			"id": "mimo-v2-flash",
			"name": "MiMo-V2-Flash",
			"api": "anthropic-messages",
			"provider": "xiaomi",
			"baseUrl": "https://api.xiaomimimo.com/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.21,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 32000
		}
	},
	"minimax-code": {
		"MiniMax-M2": {
			"id": "MiniMax-M2",
			"name": "MiniMax-M2",
			"api": "openai-completions",
			"provider": "minimax-code",
			"baseUrl": "https://api.minimax.io/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 128000,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.1": {
			"id": "MiniMax-M2.1",
			"name": "MiniMax-M2.1",
			"api": "openai-completions",
			"provider": "minimax-code",
			"baseUrl": "https://api.minimax.io/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.1-lightning": {
			"id": "MiniMax-M2.1-lightning",
			"name": "MiniMax M2.1 Lightning (Coding Plan)",
			"api": "openai-completions",
			"provider": "minimax-code",
			"baseUrl": "https://api.minimax.io/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"compat": {
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			},
			"contextWindow": 1000000,
			"maxTokens": 32000
		},
		"MiniMax-M2.5": {
			"id": "MiniMax-M2.5",
			"name": "MiniMax-M2.5",
			"api": "openai-completions",
			"provider": "minimax-code",
			"baseUrl": "https://api.minimax.io/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.5-highspeed": {
			"id": "MiniMax-M2.5-highspeed",
			"name": "MiniMax-M2.5-highspeed",
			"api": "openai-completions",
			"provider": "minimax-code",
			"baseUrl": "https://api.minimax.io/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.5-lightning": {
			"id": "MiniMax-M2.5-lightning",
			"name": "MiniMax M2.5 Lightning (Coding Plan)",
			"api": "openai-completions",
			"provider": "minimax-code",
			"baseUrl": "https://api.minimax.io/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"compat": {
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			},
			"contextWindow": 204800,
			"maxTokens": 32000
		}
	},
	"minimax-code-cn": {
		"MiniMax-M2": {
			"id": "MiniMax-M2",
			"name": "MiniMax-M2",
			"api": "openai-completions",
			"provider": "minimax-code-cn",
			"baseUrl": "https://api.minimaxi.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 128000,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.1": {
			"id": "MiniMax-M2.1",
			"name": "MiniMax-M2.1",
			"api": "openai-completions",
			"provider": "minimax-code-cn",
			"baseUrl": "https://api.minimaxi.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.1-lightning": {
			"id": "MiniMax-M2.1-lightning",
			"name": "MiniMax M2.1 Lightning (Coding Plan CN)",
			"api": "openai-completions",
			"provider": "minimax-code-cn",
			"baseUrl": "https://api.minimaxi.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"compat": {
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			},
			"contextWindow": 1000000,
			"maxTokens": 32000
		},
		"MiniMax-M2.5": {
			"id": "MiniMax-M2.5",
			"name": "MiniMax-M2.5",
			"api": "openai-completions",
			"provider": "minimax-code-cn",
			"baseUrl": "https://api.minimaxi.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.5-highspeed": {
			"id": "MiniMax-M2.5-highspeed",
			"name": "MiniMax-M2.5-highspeed",
			"api": "openai-completions",
			"provider": "minimax-code-cn",
			"baseUrl": "https://api.minimaxi.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072,
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"MiniMax-M2.5-lightning": {
			"id": "MiniMax-M2.5-lightning",
			"name": "MiniMax M2.5 Lightning (Coding Plan CN)",
			"api": "openai-completions",
			"provider": "minimax-code-cn",
			"baseUrl": "https://api.minimaxi.com/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"compat": {
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			},
			"contextWindow": 204800,
			"maxTokens": 32000
		}
	},
	"minimax": {
		"MiniMax-M2": {
			"id": "MiniMax-M2",
			"name": "MiniMax-M2",
			"api": "anthropic-messages",
			"provider": "minimax",
			"baseUrl": "https://api.minimax.io/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 128000
		},
		"MiniMax-M2.1": {
			"id": "MiniMax-M2.1",
			"name": "MiniMax-M2.1",
			"api": "anthropic-messages",
			"provider": "minimax",
			"baseUrl": "https://api.minimax.io/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"MiniMax-M2.5": {
			"id": "MiniMax-M2.5",
			"name": "MiniMax-M2.5",
			"api": "anthropic-messages",
			"provider": "minimax",
			"baseUrl": "https://api.minimax.io/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.03,
				"cacheWrite": 0.375
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"MiniMax-M2.5-highspeed": {
			"id": "MiniMax-M2.5-highspeed",
			"name": "MiniMax-M2.5-highspeed",
			"api": "anthropic-messages",
			"provider": "minimax",
			"baseUrl": "https://api.minimax.io/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.4,
				"cacheRead": 0.06,
				"cacheWrite": 0.375
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"MiniMax-M2.5-lightning": {
			"id": "MiniMax-M2.5-lightning",
			"name": "MiniMax M2.5 Lightning",
			"api": "anthropic-messages",
			"provider": "minimax",
			"baseUrl": "https://api.minimax.io/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 2.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 32000
		}
	},
	"minimax-cn": {
		"MiniMax-M2": {
			"id": "MiniMax-M2",
			"name": "MiniMax-M2",
			"api": "anthropic-messages",
			"provider": "minimax-cn",
			"baseUrl": "https://api.minimaxi.com/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 128000
		},
		"MiniMax-M2.1": {
			"id": "MiniMax-M2.1",
			"name": "MiniMax-M2.1",
			"api": "anthropic-messages",
			"provider": "minimax-cn",
			"baseUrl": "https://api.minimaxi.com/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"MiniMax-M2.5": {
			"id": "MiniMax-M2.5",
			"name": "MiniMax-M2.5",
			"api": "anthropic-messages",
			"provider": "minimax-cn",
			"baseUrl": "https://api.minimaxi.com/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.03,
				"cacheWrite": 0.375
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"MiniMax-M2.5-highspeed": {
			"id": "MiniMax-M2.5-highspeed",
			"name": "MiniMax-M2.5-highspeed",
			"api": "anthropic-messages",
			"provider": "minimax-cn",
			"baseUrl": "https://api.minimaxi.com/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.4,
				"cacheRead": 0.06,
				"cacheWrite": 0.375
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"MiniMax-M2.5-lightning": {
			"id": "MiniMax-M2.5-lightning",
			"name": "MiniMax M2.5 Lightning (CN)",
			"api": "anthropic-messages",
			"provider": "minimax-cn",
			"baseUrl": "https://api.minimaxi.com/anthropic",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 2.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 32000
		}
	},
	"nanogpt": {
		"abacusai/Dracarys-72B-Instruct": {
			"id": "abacusai/Dracarys-72B-Instruct",
			"name": "abacusai/Dracarys-72B-Instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-1.0": {
			"id": "aion-labs/aion-1.0",
			"name": "aion-labs/aion-1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-1.0-mini": {
			"id": "aion-labs/aion-1.0-mini",
			"name": "aion-labs/aion-1.0-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-2.0": {
			"id": "aion-labs/aion-2.0",
			"name": "aion-labs/aion-2.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-rp-llama-3.1-8b": {
			"id": "aion-labs/aion-rp-llama-3.1-8b",
			"name": "aion-labs/aion-rp-llama-3.1-8b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Alibaba-NLP/Tongyi-DeepResearch-30B-A3B": {
			"id": "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
			"name": "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/molmo-2-8b": {
			"id": "allenai/molmo-2-8b",
			"name": "allenai/molmo-2-8b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3-32b-think": {
			"id": "allenai/olmo-3-32b-think",
			"name": "allenai/olmo-3-32b-think",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3.1-32b-instruct": {
			"id": "allenai/olmo-3.1-32b-instruct",
			"name": "AllenAI: Olmo 3.1 32B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3.1-32b-think": {
			"id": "allenai/olmo-3.1-32b-think",
			"name": "allenai/olmo-3.1-32b-think",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"amazon/nova-2-lite-v1": {
			"id": "amazon/nova-2-lite-v1",
			"name": "Amazon: Nova 2 Lite",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65535
		},
		"amazon/nova-lite-v1": {
			"id": "amazon/nova-lite-v1",
			"name": "Amazon: Nova Lite 1.0",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.06,
				"output": 0.24,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 300000,
			"maxTokens": 5120,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"amazon/nova-micro-v1": {
			"id": "amazon/nova-micro-v1",
			"name": "Amazon: Nova Micro 1.0",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.035,
				"output": 0.14,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"amazon/nova-pro-v1": {
			"id": "amazon/nova-pro-v1",
			"name": "Amazon: Nova Pro 1.0",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.7999999999999999,
				"output": 3.1999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 300000,
			"maxTokens": 5120,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"anthracite-org/magnum-v2-72b": {
			"id": "anthracite-org/magnum-v2-72b",
			"name": "anthracite-org/magnum-v2-72b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthracite-org/magnum-v4-72b": {
			"id": "anthracite-org/magnum-v4-72b",
			"name": "anthracite-org/magnum-v4-72b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4.6": {
			"id": "anthropic/claude-opus-4.6",
			"name": "Anthropic: Claude Opus 4.6",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"anthropic/claude-opus-4.6:thinking": {
			"id": "anthropic/claude-opus-4.6:thinking",
			"name": "anthropic/claude-opus-4.6:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4.6:thinking:low": {
			"id": "anthropic/claude-opus-4.6:thinking:low",
			"name": "anthropic/claude-opus-4.6:thinking:low",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4.6:thinking:max": {
			"id": "anthropic/claude-opus-4.6:thinking:max",
			"name": "anthropic/claude-opus-4.6:thinking:max",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4.6:thinking:medium": {
			"id": "anthropic/claude-opus-4.6:thinking:medium",
			"name": "anthropic/claude-opus-4.6:thinking:medium",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"anthropic/claude-sonnet-4.6": {
			"id": "anthropic/claude-sonnet-4.6",
			"name": "Anthropic: Claude Sonnet 4.6",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"anthropic/claude-sonnet-4.6:thinking": {
			"id": "anthropic/claude-sonnet-4.6:thinking",
			"name": "anthropic/claude-sonnet-4.6:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"arcee-ai/trinity-large": {
			"id": "arcee-ai/trinity-large",
			"name": "arcee-ai/trinity-large",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"arcee-ai/trinity-mini": {
			"id": "arcee-ai/trinity-mini",
			"name": "Arcee AI: Trinity Mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.045,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"asi1-mini": {
			"id": "asi1-mini",
			"name": "asi1-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"auto-model": {
			"id": "auto-model",
			"name": "auto-model",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"auto-model-basic": {
			"id": "auto-model-basic",
			"name": "auto-model-basic",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"auto-model-premium": {
			"id": "auto-model-premium",
			"name": "auto-model-premium",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"auto-model-standard": {
			"id": "auto-model-standard",
			"name": "auto-model-standard",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"azure-gpt-4-turbo": {
			"id": "azure-gpt-4-turbo",
			"name": "azure-gpt-4-turbo",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"azure-gpt-4o": {
			"id": "azure-gpt-4o",
			"name": "azure-gpt-4o",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"azure-gpt-4o-mini": {
			"id": "azure-gpt-4o-mini",
			"name": "azure-gpt-4o-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"azure-o1": {
			"id": "azure-o1",
			"name": "azure-o1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"azure-o3-mini": {
			"id": "azure-o3-mini",
			"name": "azure-o3-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Baichuan-M2": {
			"id": "Baichuan-M2",
			"name": "Baichuan-M2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Baichuan4-Air": {
			"id": "Baichuan4-Air",
			"name": "Baichuan4-Air",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Baichuan4-Turbo": {
			"id": "Baichuan4-Turbo",
			"name": "Baichuan4-Turbo",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-300b-a47b": {
			"id": "baidu/ernie-4.5-300b-a47b",
			"name": "baidu/ernie-4.5-300b-a47b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-vl-28b-a3b": {
			"id": "baidu/ernie-4.5-vl-28b-a3b",
			"name": "Baidu: ERNIE 4.5 VL 28B A3B",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.14,
				"output": 0.56,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baseten/Kimi-K2-Instruct-FP4": {
			"id": "baseten/Kimi-K2-Instruct-FP4",
			"name": "baseten/Kimi-K2-Instruct-FP4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"brave": {
			"id": "brave",
			"name": "brave",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"brave-pro": {
			"id": "brave-pro",
			"name": "brave-pro",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"brave-research": {
			"id": "brave-research",
			"name": "brave-research",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"chutesai/Mistral-Small-3.2-24B-Instruct-2506": {
			"id": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
			"name": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-3-5-haiku-20241022": {
			"id": "claude-3-5-haiku-20241022",
			"name": "claude-3-5-haiku-20241022",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"claude-3-5-sonnet-20240620": {
			"id": "claude-3-5-sonnet-20240620",
			"name": "Claude Sonnet 3.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"claude-3-5-sonnet-20241022": {
			"id": "claude-3-5-sonnet-20241022",
			"name": "Claude Sonnet 3.5 v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"claude-3-7-sonnet-20250219": {
			"id": "claude-3-7-sonnet-20250219",
			"name": "claude-3-7-sonnet-20250219",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"claude-3-7-sonnet-reasoner": {
			"id": "claude-3-7-sonnet-reasoner",
			"name": "claude-3-7-sonnet-reasoner",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-3-7-sonnet-thinking": {
			"id": "claude-3-7-sonnet-thinking",
			"name": "claude-3-7-sonnet-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-3-7-sonnet-thinking:1024": {
			"id": "claude-3-7-sonnet-thinking:1024",
			"name": "claude-3-7-sonnet-thinking:1024",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-3-7-sonnet-thinking:128000": {
			"id": "claude-3-7-sonnet-thinking:128000",
			"name": "claude-3-7-sonnet-thinking:128000",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-3-7-sonnet-thinking:32768": {
			"id": "claude-3-7-sonnet-thinking:32768",
			"name": "claude-3-7-sonnet-thinking:32768",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-3-7-sonnet-thinking:8192": {
			"id": "claude-3-7-sonnet-thinking:8192",
			"name": "claude-3-7-sonnet-thinking:8192",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-haiku-4-5-20251001": {
			"id": "claude-haiku-4-5-20251001",
			"name": "Claude Haiku 4.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-1-20250805": {
			"id": "claude-opus-4-1-20250805",
			"name": "Claude Opus 4.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-1-thinking": {
			"id": "claude-opus-4-1-thinking",
			"name": "claude-opus-4-1-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-1-thinking:1024": {
			"id": "claude-opus-4-1-thinking:1024",
			"name": "claude-opus-4-1-thinking:1024",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-1-thinking:32000": {
			"id": "claude-opus-4-1-thinking:32000",
			"name": "claude-opus-4-1-thinking:32000",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-1-thinking:32768": {
			"id": "claude-opus-4-1-thinking:32768",
			"name": "claude-opus-4-1-thinking:32768",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-1-thinking:8192": {
			"id": "claude-opus-4-1-thinking:8192",
			"name": "claude-opus-4-1-thinking:8192",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-20250514": {
			"id": "claude-opus-4-20250514",
			"name": "Claude Opus 4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-5-20251101": {
			"id": "claude-opus-4-5-20251101",
			"name": "Claude Opus 4.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-5-20251101:thinking": {
			"id": "claude-opus-4-5-20251101:thinking",
			"name": "claude-opus-4-5-20251101:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-thinking": {
			"id": "claude-opus-4-thinking",
			"name": "claude-opus-4-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-thinking:1024": {
			"id": "claude-opus-4-thinking:1024",
			"name": "claude-opus-4-thinking:1024",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-thinking:32000": {
			"id": "claude-opus-4-thinking:32000",
			"name": "claude-opus-4-thinking:32000",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-thinking:32768": {
			"id": "claude-opus-4-thinking:32768",
			"name": "claude-opus-4-thinking:32768",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-opus-4-thinking:8192": {
			"id": "claude-opus-4-thinking:8192",
			"name": "claude-opus-4-thinking:8192",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-sonnet-4-20250514": {
			"id": "claude-sonnet-4-20250514",
			"name": "Claude Sonnet 4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5-20250929": {
			"id": "claude-sonnet-4-5-20250929",
			"name": "Claude Sonnet 4.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5-20250929-thinking": {
			"id": "claude-sonnet-4-5-20250929-thinking",
			"name": "claude-sonnet-4-5-20250929-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-sonnet-4-thinking": {
			"id": "claude-sonnet-4-thinking",
			"name": "claude-sonnet-4-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-sonnet-4-thinking:1024": {
			"id": "claude-sonnet-4-thinking:1024",
			"name": "claude-sonnet-4-thinking:1024",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-sonnet-4-thinking:32768": {
			"id": "claude-sonnet-4-thinking:32768",
			"name": "claude-sonnet-4-thinking:32768",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-sonnet-4-thinking:64000": {
			"id": "claude-sonnet-4-thinking:64000",
			"name": "claude-sonnet-4-thinking:64000",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"claude-sonnet-4-thinking:8192": {
			"id": "claude-sonnet-4-thinking:8192",
			"name": "claude-sonnet-4-thinking:8192",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cognitivecomputations/dolphin-2.9.2-qwen2-72b": {
			"id": "cognitivecomputations/dolphin-2.9.2-qwen2-72b",
			"name": "cognitivecomputations/dolphin-2.9.2-qwen2-72b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cohere/command-r": {
			"id": "cohere/command-r",
			"name": "cohere/command-r",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cohere/command-r-plus-08-2024": {
			"id": "cohere/command-r-plus-08-2024",
			"name": "Cohere: Command R+ (08-2024)",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"command-a-reasoning-08-2025": {
			"id": "command-a-reasoning-08-2025",
			"name": "command-a-reasoning-08-2025",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"CrucibleLab/L3.3-70B-Loki-V2.0": {
			"id": "CrucibleLab/L3.3-70B-Loki-V2.0",
			"name": "CrucibleLab/L3.3-70B-Loki-V2.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepclaude": {
			"id": "deepclaude",
			"name": "deepclaude",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepcogito/cogito-v1-preview-qwen-32B": {
			"id": "deepcogito/cogito-v1-preview-qwen-32B",
			"name": "deepcogito/cogito-v1-preview-qwen-32B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepcogito/cogito-v2.1-671b": {
			"id": "deepcogito/cogito-v2.1-671b",
			"name": "deepcogito/cogito-v2.1-671b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-ai/DeepSeek-R1-0528": {
			"id": "deepseek-ai/DeepSeek-R1-0528",
			"name": "deepseek-ai/DeepSeek-R1-0528",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-ai/DeepSeek-V3.1": {
			"id": "deepseek-ai/DeepSeek-V3.1",
			"name": "DeepSeek V3.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 1.25,
				"cacheRead": 0.6,
				"cacheWrite": 0.6
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"deepseek-ai/DeepSeek-V3.1-Terminus": {
			"id": "deepseek-ai/DeepSeek-V3.1-Terminus",
			"name": "deepseek-ai/DeepSeek-V3.1-Terminus",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-ai/DeepSeek-V3.1-Terminus:thinking": {
			"id": "deepseek-ai/DeepSeek-V3.1-Terminus:thinking",
			"name": "deepseek-ai/DeepSeek-V3.1-Terminus:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-ai/DeepSeek-V3.1:thinking": {
			"id": "deepseek-ai/DeepSeek-V3.1:thinking",
			"name": "deepseek-ai/DeepSeek-V3.1:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-ai/deepseek-v3.2-exp": {
			"id": "deepseek-ai/deepseek-v3.2-exp",
			"name": "deepseek-ai/deepseek-v3.2-exp",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-ai/deepseek-v3.2-exp-thinking": {
			"id": "deepseek-ai/deepseek-v3.2-exp-thinking",
			"name": "deepseek-ai/deepseek-v3.2-exp-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-chat": {
			"id": "deepseek-chat",
			"name": "deepseek-chat",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-chat-cheaper": {
			"id": "deepseek-chat-cheaper",
			"name": "deepseek-chat-cheaper",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-math-v2": {
			"id": "deepseek-math-v2",
			"name": "deepseek-math-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-r1": {
			"id": "deepseek-r1",
			"name": "deepseek-r1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-r1-sambanova": {
			"id": "deepseek-r1-sambanova",
			"name": "deepseek-r1-sambanova",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-reasoner": {
			"id": "deepseek-reasoner",
			"name": "deepseek-reasoner",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-reasoner-cheaper": {
			"id": "deepseek-reasoner-cheaper",
			"name": "deepseek-reasoner-cheaper",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek-v3-0324": {
			"id": "deepseek-v3-0324",
			"name": "deepseek-v3-0324",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-prover-v2-671b": {
			"id": "deepseek/deepseek-prover-v2-671b",
			"name": "deepseek/deepseek-prover-v2-671b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2": {
			"id": "deepseek/deepseek-v3.2",
			"name": "DeepSeek: DeepSeek V3.2",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.26,
				"output": 0.38,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2-speciale": {
			"id": "deepseek/deepseek-v3.2-speciale",
			"name": "deepseek/deepseek-v3.2-speciale",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2:thinking": {
			"id": "deepseek/deepseek-v3.2:thinking",
			"name": "deepseek/deepseek-v3.2:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"dmind/dmind-1": {
			"id": "dmind/dmind-1",
			"name": "dmind/dmind-1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"dmind/dmind-1-mini": {
			"id": "dmind/dmind-1-mini",
			"name": "dmind/dmind-1-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Doctor-Shotgun/MS3.2-24B-Magnum-Diamond": {
			"id": "Doctor-Shotgun/MS3.2-24B-Magnum-Diamond",
			"name": "Doctor-Shotgun/MS3.2-24B-Magnum-Diamond",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-1-5-thinking-pro-250415": {
			"id": "doubao-1-5-thinking-pro-250415",
			"name": "doubao-1-5-thinking-pro-250415",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-1.5-pro-256k": {
			"id": "doubao-1.5-pro-256k",
			"name": "doubao-1.5-pro-256k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-1.5-pro-32k": {
			"id": "doubao-1.5-pro-32k",
			"name": "doubao-1.5-pro-32k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-1-6-250615": {
			"id": "doubao-seed-1-6-250615",
			"name": "doubao-seed-1-6-250615",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-1-6-flash-250615": {
			"id": "doubao-seed-1-6-flash-250615",
			"name": "doubao-seed-1-6-flash-250615",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-1-6-thinking-250615": {
			"id": "doubao-seed-1-6-thinking-250615",
			"name": "doubao-seed-1-6-thinking-250615",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-1-8-251215": {
			"id": "doubao-seed-1-8-251215",
			"name": "doubao-seed-1-8-251215",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-2-0-code-preview-260215": {
			"id": "doubao-seed-2-0-code-preview-260215",
			"name": "doubao-seed-2-0-code-preview-260215",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-2-0-lite-260215": {
			"id": "doubao-seed-2-0-lite-260215",
			"name": "doubao-seed-2-0-lite-260215",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-2-0-mini-260215": {
			"id": "doubao-seed-2-0-mini-260215",
			"name": "doubao-seed-2-0-mini-260215",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-2-0-pro-260215": {
			"id": "doubao-seed-2-0-pro-260215",
			"name": "doubao-seed-2-0-pro-260215",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"doubao-seed-code-preview-latest": {
			"id": "doubao-seed-code-preview-latest",
			"name": "doubao-seed-code-preview-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Envoid/Llama-3.05-Nemotron-Tenyxchat-Storybreaker-70B": {
			"id": "Envoid/Llama-3.05-Nemotron-Tenyxchat-Storybreaker-70B",
			"name": "Envoid/Llama-3.05-Nemotron-Tenyxchat-Storybreaker-70B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Envoid/Llama-3.05-NT-Storybreaker-Ministral-70B": {
			"id": "Envoid/Llama-3.05-NT-Storybreaker-Ministral-70B",
			"name": "Envoid/Llama-3.05-NT-Storybreaker-Ministral-70B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-4.5-8k-preview": {
			"id": "ernie-4.5-8k-preview",
			"name": "ernie-4.5-8k-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-4.5-turbo-128k": {
			"id": "ernie-4.5-turbo-128k",
			"name": "ernie-4.5-turbo-128k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-4.5-turbo-vl-32k": {
			"id": "ernie-4.5-turbo-vl-32k",
			"name": "ernie-4.5-turbo-vl-32k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-5.0-thinking-latest": {
			"id": "ernie-5.0-thinking-latest",
			"name": "ernie-5.0-thinking-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-5.0-thinking-preview": {
			"id": "ernie-5.0-thinking-preview",
			"name": "ernie-5.0-thinking-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-x1-32k": {
			"id": "ernie-x1-32k",
			"name": "ernie-x1-32k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-x1-32k-preview": {
			"id": "ernie-x1-32k-preview",
			"name": "ernie-x1-32k-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-x1-turbo-32k": {
			"id": "ernie-x1-turbo-32k",
			"name": "ernie-x1-turbo-32k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ernie-x1.1-preview": {
			"id": "ernie-x1.1-preview",
			"name": "ernie-x1.1-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"essentialai/rnj-1-instruct": {
			"id": "essentialai/rnj-1-instruct",
			"name": "essentialai/rnj-1-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.0": {
			"id": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.0",
			"name": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.1": {
			"id": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.1",
			"name": "EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2": {
			"id": "EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2",
			"name": "EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2": {
			"id": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2",
			"name": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"exa-answer": {
			"id": "exa-answer",
			"name": "exa-answer",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"exa-research": {
			"id": "exa-research",
			"name": "exa-research",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"exa-research-pro": {
			"id": "exa-research-pro",
			"name": "exa-research-pro",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5": {
			"id": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5",
			"name": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"fastgpt": {
			"id": "fastgpt",
			"name": "fastgpt",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"featherless-ai/Qwerky-72B": {
			"id": "featherless-ai/Qwerky-72B",
			"name": "featherless-ai/Qwerky-72B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GalrionSoftworks/MN-LooseCannon-12B-v1": {
			"id": "GalrionSoftworks/MN-LooseCannon-12B-v1",
			"name": "GalrionSoftworks/MN-LooseCannon-12B-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.0-flash-001": {
			"id": "gemini-2.0-flash-001",
			"name": "gemini-2.0-flash-001",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.0-flash-lite": {
			"id": "gemini-2.0-flash-lite",
			"name": "Gemini 2.0 Flash Lite",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"gemini-2.0-flash-thinking-exp-01-21": {
			"id": "gemini-2.0-flash-thinking-exp-01-21",
			"name": "gemini-2.0-flash-thinking-exp-01-21",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.0-flash-thinking-exp-1219": {
			"id": "gemini-2.0-flash-thinking-exp-1219",
			"name": "gemini-2.0-flash-thinking-exp-1219",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.0-pro-exp-02-05": {
			"id": "gemini-2.0-pro-exp-02-05",
			"name": "gemini-2.0-pro-exp-02-05",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.0-pro-reasoner": {
			"id": "gemini-2.0-pro-reasoner",
			"name": "gemini-2.0-pro-reasoner",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-flash": {
			"id": "gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite": {
			"id": "gemini-2.5-flash-lite",
			"name": "Gemini 2.5 Flash Lite",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite-preview-06-17": {
			"id": "gemini-2.5-flash-lite-preview-06-17",
			"name": "Gemini 2.5 Flash Lite Preview 06-17",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite-preview-09-2025": {
			"id": "gemini-2.5-flash-lite-preview-09-2025",
			"name": "Gemini 2.5 Flash Lite Preview 09-25",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.025,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite-preview-09-2025-thinking": {
			"id": "gemini-2.5-flash-lite-preview-09-2025-thinking",
			"name": "gemini-2.5-flash-lite-preview-09-2025-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-flash-nothinking": {
			"id": "gemini-2.5-flash-nothinking",
			"name": "gemini-2.5-flash-nothinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-flash-preview-04-17": {
			"id": "gemini-2.5-flash-preview-04-17",
			"name": "Gemini 2.5 Flash Preview 04-17",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.0375,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-preview-04-17:thinking": {
			"id": "gemini-2.5-flash-preview-04-17:thinking",
			"name": "gemini-2.5-flash-preview-04-17:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-flash-preview-05-20": {
			"id": "gemini-2.5-flash-preview-05-20",
			"name": "Gemini 2.5 Flash Preview 05-20",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.0375,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-preview-05-20:thinking": {
			"id": "gemini-2.5-flash-preview-05-20:thinking",
			"name": "gemini-2.5-flash-preview-05-20:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-flash-preview-09-2025": {
			"id": "gemini-2.5-flash-preview-09-2025",
			"name": "Gemini 2.5 Flash Preview 09-25",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-preview-09-2025-thinking": {
			"id": "gemini-2.5-flash-preview-09-2025-thinking",
			"name": "gemini-2.5-flash-preview-09-2025-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.31,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536,
			"headers": {
				"User-Agent": "GitHubCopilotChat/0.35.0",
				"Editor-Version": "vscode/1.107.0",
				"Editor-Plugin-Version": "copilot-chat/0.35.0",
				"Copilot-Integration-Id": "vscode-chat"
			},
			"compat": {
				"supportsStore": false,
				"supportsDeveloperRole": false,
				"supportsReasoningEffort": false
			}
		},
		"gemini-2.5-pro-exp-03-25": {
			"id": "gemini-2.5-pro-exp-03-25",
			"name": "gemini-2.5-pro-exp-03-25",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-pro-preview-03-25": {
			"id": "gemini-2.5-pro-preview-03-25",
			"name": "gemini-2.5-pro-preview-03-25",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-2.5-pro-preview-05-06": {
			"id": "gemini-2.5-pro-preview-05-06",
			"name": "Gemini 2.5 Pro Preview 05-06",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.31,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro-preview-06-05": {
			"id": "gemini-2.5-pro-preview-06-05",
			"name": "Gemini 2.5 Pro Preview 06-05",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.31,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"gemini-3-pro-preview-thinking": {
			"id": "gemini-3-pro-preview-thinking",
			"name": "gemini-3-pro-preview-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"gemini-exp-1206": {
			"id": "gemini-exp-1206",
			"name": "gemini-exp-1206",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-ArliAI-RPMax-v3": {
			"id": "Gemma-3-27B-ArliAI-RPMax-v3",
			"name": "Gemma-3-27B-ArliAI-RPMax-v3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-Big-Tiger-v3": {
			"id": "Gemma-3-27B-Big-Tiger-v3",
			"name": "Gemma-3-27B-Big-Tiger-v3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-CardProjector-v4": {
			"id": "Gemma-3-27B-CardProjector-v4",
			"name": "Gemma-3-27B-CardProjector-v4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-Glitter": {
			"id": "Gemma-3-27B-Glitter",
			"name": "Gemma-3-27B-Glitter",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-it": {
			"id": "Gemma-3-27B-it",
			"name": "Gemma-3-27B-it",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-it-Abliterated": {
			"id": "Gemma-3-27B-it-Abliterated",
			"name": "Gemma-3-27B-it-Abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gemma-3-27B-Nidum-Uncensored": {
			"id": "Gemma-3-27B-Nidum-Uncensored",
			"name": "Gemma-3-27B-Nidum-Uncensored",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4": {
			"id": "glm-4",
			"name": "glm-4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-air": {
			"id": "glm-4-air",
			"name": "glm-4-air",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-air-0111": {
			"id": "glm-4-air-0111",
			"name": "glm-4-air-0111",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-airx": {
			"id": "glm-4-airx",
			"name": "glm-4-airx",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-flash": {
			"id": "glm-4-flash",
			"name": "glm-4-flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-long": {
			"id": "glm-4-long",
			"name": "glm-4-long",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-plus": {
			"id": "glm-4-plus",
			"name": "glm-4-plus",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4-plus-0111": {
			"id": "glm-4-plus-0111",
			"name": "glm-4-plus-0111",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4.1v-thinking-flash": {
			"id": "glm-4.1v-thinking-flash",
			"name": "glm-4.1v-thinking-flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-4.1v-thinking-flashx": {
			"id": "glm-4.1v-thinking-flashx",
			"name": "glm-4.1v-thinking-flashx",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted": {
			"id": "GLM-4.5-Air-Derestricted",
			"name": "GLM-4.5-Air-Derestricted",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted-Iceblink": {
			"id": "GLM-4.5-Air-Derestricted-Iceblink",
			"name": "GLM-4.5-Air-Derestricted-Iceblink",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted-Iceblink-ReExtract": {
			"id": "GLM-4.5-Air-Derestricted-Iceblink-ReExtract",
			"name": "GLM-4.5-Air-Derestricted-Iceblink-ReExtract",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted-Iceblink-v2": {
			"id": "GLM-4.5-Air-Derestricted-Iceblink-v2",
			"name": "GLM-4.5-Air-Derestricted-Iceblink-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted-Iceblink-v2-ReExtract": {
			"id": "GLM-4.5-Air-Derestricted-Iceblink-v2-ReExtract",
			"name": "GLM-4.5-Air-Derestricted-Iceblink-v2-ReExtract",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted-Steam": {
			"id": "GLM-4.5-Air-Derestricted-Steam",
			"name": "GLM-4.5-Air-Derestricted-Steam",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.5-Air-Derestricted-Steam-ReExtract": {
			"id": "GLM-4.5-Air-Derestricted-Steam-ReExtract",
			"name": "GLM-4.5-Air-Derestricted-Steam-ReExtract",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"GLM-4.6-Derestricted-v5": {
			"id": "GLM-4.6-Derestricted-v5",
			"name": "GLM-4.6-Derestricted-v5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-z1-air": {
			"id": "glm-z1-air",
			"name": "glm-z1-air",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-z1-airx": {
			"id": "glm-z1-airx",
			"name": "glm-z1-airx",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"glm-zero-preview": {
			"id": "glm-zero-preview",
			"name": "glm-zero-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3-flash-preview": {
			"id": "google/gemini-3-flash-preview",
			"name": "Google: Gemini 3 Flash Preview",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 3,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"google/gemini-3-flash-preview-thinking": {
			"id": "google/gemini-3-flash-preview-thinking",
			"name": "google/gemini-3-flash-preview-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3.1-pro-preview": {
			"id": "google/gemini-3.1-pro-preview",
			"name": "Google: Gemini 3.1 Pro Preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-3.1-pro-preview-customtools": {
			"id": "google/gemini-3.1-pro-preview-customtools",
			"name": "Google: Gemini 3.1 Pro Preview Custom Tools",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-3.1-pro-preview-high": {
			"id": "google/gemini-3.1-pro-preview-high",
			"name": "google/gemini-3.1-pro-preview-high",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3.1-pro-preview-low": {
			"id": "google/gemini-3.1-pro-preview-low",
			"name": "google/gemini-3.1-pro-preview-low",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-flash-1.5": {
			"id": "google/gemini-flash-1.5",
			"name": "google/gemini-flash-1.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"grok-3-beta": {
			"id": "grok-3-beta",
			"name": "grok-3-beta",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"grok-3-fast-beta": {
			"id": "grok-3-fast-beta",
			"name": "grok-3-fast-beta",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"grok-3-mini-beta": {
			"id": "grok-3-mini-beta",
			"name": "grok-3-mini-beta",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"grok-3-mini-fast-beta": {
			"id": "grok-3-mini-fast-beta",
			"name": "grok-3-mini-fast-beta",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Gryphe/MythoMax-L2-13b": {
			"id": "Gryphe/MythoMax-L2-13b",
			"name": "Gryphe/MythoMax-L2-13b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated": {
			"id": "huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated",
			"name": "huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated": {
			"id": "huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated",
			"name": "huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"huihui-ai/Llama-3.1-Nemotron-70B-Instruct-HF-abliterated": {
			"id": "huihui-ai/Llama-3.1-Nemotron-70B-Instruct-HF-abliterated",
			"name": "huihui-ai/Llama-3.1-Nemotron-70B-Instruct-HF-abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"huihui-ai/Llama-3.3-70B-Instruct-abliterated": {
			"id": "huihui-ai/Llama-3.3-70B-Instruct-abliterated",
			"name": "huihui-ai/Llama-3.3-70B-Instruct-abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"huihui-ai/Qwen2.5-32B-Instruct-abliterated": {
			"id": "huihui-ai/Qwen2.5-32B-Instruct-abliterated",
			"name": "huihui-ai/Qwen2.5-32B-Instruct-abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"hunyuan-t1-latest": {
			"id": "hunyuan-t1-latest",
			"name": "hunyuan-t1-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"hunyuan-turbos-20250226": {
			"id": "hunyuan-turbos-20250226",
			"name": "hunyuan-turbos-20250226",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Infermatic/MN-12B-Inferor-v0.0": {
			"id": "Infermatic/MN-12B-Inferor-v0.0",
			"name": "Infermatic/MN-12B-Inferor-v0.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inflatebot/MN-12B-Mag-Mell-R1": {
			"id": "inflatebot/MN-12B-Mag-Mell-R1",
			"name": "inflatebot/MN-12B-Mag-Mell-R1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inflection/inflection-3-pi": {
			"id": "inflection/inflection-3-pi",
			"name": "inflection/inflection-3-pi",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inflection/inflection-3-productivity": {
			"id": "inflection/inflection-3-productivity",
			"name": "inflection/inflection-3-productivity",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"jamba-large": {
			"id": "jamba-large",
			"name": "jamba-large",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"jamba-large-1.6": {
			"id": "jamba-large-1.6",
			"name": "jamba-large-1.6",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"jamba-large-1.7": {
			"id": "jamba-large-1.7",
			"name": "jamba-large-1.7",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"jamba-mini": {
			"id": "jamba-mini",
			"name": "jamba-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"jamba-mini-1.6": {
			"id": "jamba-mini-1.6",
			"name": "jamba-mini-1.6",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"jamba-mini-1.7": {
			"id": "jamba-mini-1.7",
			"name": "jamba-mini-1.7",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"KAT-Coder-Air-V1": {
			"id": "KAT-Coder-Air-V1",
			"name": "KAT-Coder-Air-V1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"KAT-Coder-Exp-72B-1010": {
			"id": "KAT-Coder-Exp-72B-1010",
			"name": "KAT-Coder-Exp-72B-1010",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"KAT-Coder-Pro-V1": {
			"id": "KAT-Coder-Pro-V1",
			"name": "KAT-Coder-Pro-V1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"kimi-k2-instruct-fast": {
			"id": "kimi-k2-instruct-fast",
			"name": "kimi-k2-instruct-fast",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"kimi-thinking-preview": {
			"id": "kimi-thinking-preview",
			"name": "kimi-thinking-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"LatitudeGames/Wayfarer-Large-70B-Llama-3.3": {
			"id": "LatitudeGames/Wayfarer-Large-70B-Llama-3.3",
			"name": "LatitudeGames/Wayfarer-Large-70B-Llama-3.3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"learnlm-1.5-pro-experimental": {
			"id": "learnlm-1.5-pro-experimental",
			"name": "learnlm-1.5-pro-experimental",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"liquid/lfm-2-24b-a2b": {
			"id": "liquid/lfm-2-24b-a2b",
			"name": "liquid/lfm-2-24b-a2b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Anthrobomination": {
			"id": "Llama-3.3-70B-Anthrobomination",
			"name": "Llama-3.3-70B-Anthrobomination",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Argunaut-1-SFT": {
			"id": "Llama-3.3-70B-Argunaut-1-SFT",
			"name": "Llama-3.3-70B-Argunaut-1-SFT",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-ArliAI-RPMax-v1.4": {
			"id": "Llama-3.3-70B-ArliAI-RPMax-v1.4",
			"name": "Llama-3.3-70B-ArliAI-RPMax-v1.4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-ArliAI-RPMax-v2": {
			"id": "Llama-3.3-70B-ArliAI-RPMax-v2",
			"name": "Llama-3.3-70B-ArliAI-RPMax-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-ArliAI-RPMax-v3": {
			"id": "Llama-3.3-70B-ArliAI-RPMax-v3",
			"name": "Llama-3.3-70B-ArliAI-RPMax-v3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Aurora-Borealis": {
			"id": "Llama-3.3-70B-Aurora-Borealis",
			"name": "Llama-3.3-70B-Aurora-Borealis",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Bigger-Body": {
			"id": "Llama-3.3-70B-Bigger-Body",
			"name": "Llama-3.3-70B-Bigger-Body",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Cirrus-x1": {
			"id": "Llama-3.3-70B-Cirrus-x1",
			"name": "Llama-3.3-70B-Cirrus-x1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Cu-Mai-R1": {
			"id": "Llama-3.3-70B-Cu-Mai-R1",
			"name": "Llama-3.3-70B-Cu-Mai-R1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Damascus-R1": {
			"id": "Llama-3.3-70B-Damascus-R1",
			"name": "Llama-3.3-70B-Damascus-R1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Dark-Ages-v0.1": {
			"id": "Llama-3.3-70B-Dark-Ages-v0.1",
			"name": "Llama-3.3-70B-Dark-Ages-v0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Electra-R1": {
			"id": "Llama-3.3-70B-Electra-R1",
			"name": "Llama-3.3-70B-Electra-R1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Electranova-v1.0": {
			"id": "Llama-3.3-70B-Electranova-v1.0",
			"name": "Llama-3.3-70B-Electranova-v1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Fallen-R1-v1": {
			"id": "Llama-3.3-70B-Fallen-R1-v1",
			"name": "Llama-3.3-70B-Fallen-R1-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Fallen-v1": {
			"id": "Llama-3.3-70B-Fallen-v1",
			"name": "Llama-3.3-70B-Fallen-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Forgotten-Abomination-v5.0": {
			"id": "Llama-3.3-70B-Forgotten-Abomination-v5.0",
			"name": "Llama-3.3-70B-Forgotten-Abomination-v5.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Forgotten-Safeword-3.6": {
			"id": "Llama-3.3-70B-Forgotten-Safeword-3.6",
			"name": "Llama-3.3-70B-Forgotten-Safeword-3.6",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-GeneticLemonade-Opus": {
			"id": "Llama-3.3-70B-GeneticLemonade-Opus",
			"name": "Llama-3.3-70B-GeneticLemonade-Opus",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-GeneticLemonade-Unleashed-v3": {
			"id": "Llama-3.3-70B-GeneticLemonade-Unleashed-v3",
			"name": "Llama-3.3-70B-GeneticLemonade-Unleashed-v3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Ignition-v0.1": {
			"id": "Llama-3.3-70B-Ignition-v0.1",
			"name": "Llama-3.3-70B-Ignition-v0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Incandescent-Malevolence": {
			"id": "Llama-3.3-70B-Incandescent-Malevolence",
			"name": "Llama-3.3-70B-Incandescent-Malevolence",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Legion-V2.1": {
			"id": "Llama-3.3-70B-Legion-V2.1",
			"name": "Llama-3.3-70B-Legion-V2.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Magnum-v4-SE": {
			"id": "Llama-3.3-70B-Magnum-v4-SE",
			"name": "Llama-3.3-70B-Magnum-v4-SE",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Magnum-v4-SE-Cirrus-x1-SLERP": {
			"id": "Llama-3.3-70B-Magnum-v4-SE-Cirrus-x1-SLERP",
			"name": "Llama-3.3-70B-Magnum-v4-SE-Cirrus-x1-SLERP",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Mhnnn-x1": {
			"id": "Llama-3.3-70B-Mhnnn-x1",
			"name": "Llama-3.3-70B-Mhnnn-x1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-MiraiFanfare": {
			"id": "Llama-3.3-70B-MiraiFanfare",
			"name": "Llama-3.3-70B-MiraiFanfare",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Mokume-Gane-R1": {
			"id": "Llama-3.3-70B-Mokume-Gane-R1",
			"name": "Llama-3.3-70B-Mokume-Gane-R1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-MS-Nevoria": {
			"id": "Llama-3.3-70B-MS-Nevoria",
			"name": "Llama-3.3-70B-MS-Nevoria",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Nova": {
			"id": "Llama-3.3-70B-Nova",
			"name": "Llama-3.3-70B-Nova",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Predatorial-Extasy": {
			"id": "Llama-3.3-70B-Predatorial-Extasy",
			"name": "Llama-3.3-70B-Predatorial-Extasy",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Progenitor-V3.3": {
			"id": "Llama-3.3-70B-Progenitor-V3.3",
			"name": "Llama-3.3-70B-Progenitor-V3.3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-RAWMAW": {
			"id": "Llama-3.3-70B-RAWMAW",
			"name": "Llama-3.3-70B-RAWMAW",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Sapphira-0.1": {
			"id": "Llama-3.3-70B-Sapphira-0.1",
			"name": "Llama-3.3-70B-Sapphira-0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Sapphira-0.2": {
			"id": "Llama-3.3-70B-Sapphira-0.2",
			"name": "Llama-3.3-70B-Sapphira-0.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Shakudo": {
			"id": "Llama-3.3-70B-Shakudo",
			"name": "Llama-3.3-70B-Shakudo",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-StrawberryLemonade-v1.0": {
			"id": "Llama-3.3-70B-StrawberryLemonade-v1.0",
			"name": "Llama-3.3-70B-StrawberryLemonade-v1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Strawberrylemonade-v1.2": {
			"id": "Llama-3.3-70B-Strawberrylemonade-v1.2",
			"name": "Llama-3.3-70B-Strawberrylemonade-v1.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-The-Omega-Directive-Unslop-v2.0": {
			"id": "Llama-3.3-70B-The-Omega-Directive-Unslop-v2.0",
			"name": "Llama-3.3-70B-The-Omega-Directive-Unslop-v2.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-The-Omega-Directive-Unslop-v2.1": {
			"id": "Llama-3.3-70B-The-Omega-Directive-Unslop-v2.1",
			"name": "Llama-3.3-70B-The-Omega-Directive-Unslop-v2.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3-70B-Vulpecula-R1": {
			"id": "Llama-3.3-70B-Vulpecula-R1",
			"name": "Llama-3.3-70B-Vulpecula-R1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3+(3.1v3.3)-70B-Hanami-x1": {
			"id": "Llama-3.3+(3.1v3.3)-70B-Hanami-x1",
			"name": "Llama-3.3+(3.1v3.3)-70B-Hanami-x1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3+(3.1v3.3)-70B-New-Dawn-v1.1": {
			"id": "Llama-3.3+(3.1v3.3)-70B-New-Dawn-v1.1",
			"name": "Llama-3.3+(3.1v3.3)-70B-New-Dawn-v1.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Llama-3.3+(3v3.3)-70B-TenyxChat-DaybreakStorywriter": {
			"id": "Llama-3.3+(3v3.3)-70B-TenyxChat-DaybreakStorywriter",
			"name": "Llama-3.3+(3v3.3)-70B-TenyxChat-DaybreakStorywriter",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"LLM360/K2-Think": {
			"id": "LLM360/K2-Think",
			"name": "LLM360/K2-Think",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Magistral-Small-2506": {
			"id": "Magistral-Small-2506",
			"name": "Magistral-Small-2506",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"MarinaraSpaghetti/NemoMix-Unleashed-12B": {
			"id": "MarinaraSpaghetti/NemoMix-Unleashed-12B",
			"name": "MarinaraSpaghetti/NemoMix-Unleashed-12B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meganova-ai/manta-flash-1.0": {
			"id": "meganova-ai/manta-flash-1.0",
			"name": "meganova-ai/manta-flash-1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meganova-ai/manta-mini-1.0": {
			"id": "meganova-ai/manta-mini-1.0",
			"name": "meganova-ai/manta-mini-1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meganova-ai/manta-pro-1.0": {
			"id": "meganova-ai/manta-pro-1.0",
			"name": "meganova-ai/manta-pro-1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meituan-longcat/LongCat-Flash-Chat-FP8": {
			"id": "meituan-longcat/LongCat-Flash-Chat-FP8",
			"name": "meituan-longcat/LongCat-Flash-Chat-FP8",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mercury-2": {
			"id": "mercury-2",
			"name": "mercury-2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mercury-coder-small": {
			"id": "mercury-coder-small",
			"name": "mercury-coder-small",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Meta-Llama-3-1-8B-Instruct-FP8": {
			"id": "Meta-Llama-3-1-8B-Instruct-FP8",
			"name": "Meta-Llama-3-1-8B-Instruct-FP8",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-8b-instruct": {
			"id": "meta-llama/llama-3.1-8b-instruct",
			"name": "Meta: Llama 3.1 8B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.02,
				"output": 0.049999999999999996,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.2-3b-instruct": {
			"id": "meta-llama/llama-3.2-3b-instruct",
			"name": "meta-llama/llama-3.2-3b-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.3-70b-instruct": {
			"id": "meta-llama/llama-3.3-70b-instruct",
			"name": "Meta: Llama 3.3 70B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.32,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-4-maverick": {
			"id": "meta-llama/llama-4-maverick",
			"name": "Meta: Llama 4 Maverick",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 16384
		},
		"meta-llama/llama-4-scout": {
			"id": "meta-llama/llama-4-scout",
			"name": "Meta: Llama 4 Scout",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.08,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 327680,
			"maxTokens": 16384
		},
		"microsoft/MAI-DS-R1-FP8": {
			"id": "microsoft/MAI-DS-R1-FP8",
			"name": "microsoft/MAI-DS-R1-FP8",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"microsoft/wizardlm-2-8x22b": {
			"id": "microsoft/wizardlm-2-8x22b",
			"name": "microsoft/wizardlm-2-8x22b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"MiniMax-M1": {
			"id": "MiniMax-M1",
			"name": "MiniMax-M1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"MiniMax-M2": {
			"id": "MiniMax-M2",
			"name": "MiniMax-M2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 128000,
			"compat": {
				"supportsDeveloperRole": false,
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content"
			}
		},
		"minimax/minimax-01": {
			"id": "minimax/minimax-01",
			"name": "minimax/minimax-01",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2-her": {
			"id": "minimax/minimax-m2-her",
			"name": "minimax/minimax-m2-her",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2.1": {
			"id": "minimax/minimax-m2.1",
			"name": "MiniMax: MiniMax M2.1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2.5": {
			"id": "minimax/minimax-m2.5",
			"name": "MiniMax: MiniMax M2.5",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.03,
				"cacheWrite": 0.375
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"MiniMaxAI/MiniMax-M1-80k": {
			"id": "MiniMaxAI/MiniMax-M1-80k",
			"name": "MiniMaxAI/MiniMax-M1-80k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"miromind-ai/mirothinker-v1.5-235b": {
			"id": "miromind-ai/mirothinker-v1.5-235b",
			"name": "miromind-ai/mirothinker-v1.5-235b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Mistral-Nemo-12B-Instruct-2407": {
			"id": "Mistral-Nemo-12B-Instruct-2407",
			"name": "Mistral-Nemo-12B-Instruct-2407",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistral-small-31-24b-instruct": {
			"id": "mistral-small-31-24b-instruct",
			"name": "mistral-small-31-24b-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/codestral-2508": {
			"id": "mistralai/codestral-2508",
			"name": "Mistral: Codestral 2508",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.8999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 4096
		},
		"mistralai/devstral-2-123b-instruct-2512": {
			"id": "mistralai/devstral-2-123b-instruct-2512",
			"name": "Devstral-2-123B-Instruct-2512",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistralai/Devstral-Small-2505": {
			"id": "mistralai/Devstral-Small-2505",
			"name": "mistralai/Devstral-Small-2505",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/ministral-14b-2512": {
			"id": "mistralai/ministral-14b-2512",
			"name": "Mistral: Ministral 3 14B 2512",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.19999999999999998,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 4096
		},
		"mistralai/ministral-14b-instruct-2512": {
			"id": "mistralai/ministral-14b-instruct-2512",
			"name": "Ministral 3 14B Instruct 2512",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistralai/ministral-3b-2512": {
			"id": "mistralai/ministral-3b-2512",
			"name": "Mistral: Ministral 3 3B 2512",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.09999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/ministral-8b-2512": {
			"id": "mistralai/ministral-8b-2512",
			"name": "Mistral: Ministral 3 8B 2512",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 4096
		},
		"mistralai/mistral-7b-instruct": {
			"id": "mistralai/mistral-7b-instruct",
			"name": "mistralai/mistral-7b-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-large": {
			"id": "mistralai/mistral-large",
			"name": "Mistral Large",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-3-675b-instruct-2512": {
			"id": "mistralai/mistral-large-3-675b-instruct-2512",
			"name": "Mistral Large 3 675B Instruct 2512",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"mistralai/mistral-medium-3": {
			"id": "mistralai/mistral-medium-3",
			"name": "Mistral: Mistral Medium 3",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-medium-3.1": {
			"id": "mistralai/mistral-medium-3.1",
			"name": "Mistral: Mistral Medium 3.1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/Mistral-Nemo-Instruct-2407": {
			"id": "mistralai/Mistral-Nemo-Instruct-2407",
			"name": "mistralai/Mistral-Nemo-Instruct-2407",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-saba": {
			"id": "mistralai/mistral-saba",
			"name": "Mistral: Saba",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-creative": {
			"id": "mistralai/mistral-small-creative",
			"name": "Mistral: Mistral Small Creative",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-tiny": {
			"id": "mistralai/mistral-tiny",
			"name": "mistralai/mistral-tiny",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mixtral-8x22b-instruct-v0.1": {
			"id": "mistralai/mixtral-8x22b-instruct-v0.1",
			"name": "mistralai/mixtral-8x22b-instruct-v0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mixtral-8x7b-instruct-v0.1": {
			"id": "mistralai/mixtral-8x7b-instruct-v0.1",
			"name": "mistralai/mixtral-8x7b-instruct-v0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mlabonne/NeuralDaredevil-8B-abliterated": {
			"id": "mlabonne/NeuralDaredevil-8B-abliterated",
			"name": "mlabonne/NeuralDaredevil-8B-abliterated",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/Kimi-Dev-72B": {
			"id": "moonshotai/Kimi-Dev-72B",
			"name": "moonshotai/Kimi-Dev-72B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-instruct": {
			"id": "moonshotai/kimi-k2-instruct",
			"name": "Kimi K2 Instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"moonshotai/kimi-k2-instruct-0711": {
			"id": "moonshotai/kimi-k2-instruct-0711",
			"name": "moonshotai/kimi-k2-instruct-0711",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/Kimi-K2-Instruct-0905": {
			"id": "moonshotai/Kimi-K2-Instruct-0905",
			"name": "Kimi K2-Instruct 0905",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3,
				"cacheRead": 1,
				"cacheWrite": 3
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"moonshotai/kimi-k2-thinking": {
			"id": "moonshotai/kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2-thinking-original": {
			"id": "moonshotai/kimi-k2-thinking-original",
			"name": "moonshotai/kimi-k2-thinking-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-thinking-turbo-original": {
			"id": "moonshotai/kimi-k2-thinking-turbo-original",
			"name": "moonshotai/kimi-k2-thinking-turbo-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2.5": {
			"id": "moonshotai/kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2.5:thinking": {
			"id": "moonshotai/kimi-k2.5:thinking",
			"name": "moonshotai/kimi-k2.5:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"NeverSleep/Llama-3-Lumimaid-70B-v0.1": {
			"id": "NeverSleep/Llama-3-Lumimaid-70B-v0.1",
			"name": "NeverSleep/Llama-3-Lumimaid-70B-v0.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"NeverSleep/Lumimaid-v0.2-70B": {
			"id": "NeverSleep/Lumimaid-v0.2-70B",
			"name": "NeverSleep/Lumimaid-v0.2-70B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nex-agi/deepseek-v3.1-nex-n1": {
			"id": "nex-agi/deepseek-v3.1-nex-n1",
			"name": "Nex AGI: DeepSeek V3.1 Nex N1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.27,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nothingiisreal/L3.1-70B-Celeste-V0.1-BF16": {
			"id": "nothingiisreal/L3.1-70B-Celeste-V0.1-BF16",
			"name": "nothingiisreal/L3.1-70B-Celeste-V0.1-BF16",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"NousResearch/DeepHermes-3-Mistral-24B-Preview": {
			"id": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
			"name": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-3-llama-3.1-70b": {
			"id": "nousresearch/hermes-3-llama-3.1-70b",
			"name": "nousresearch/hermes-3-llama-3.1-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-4-405b": {
			"id": "nousresearch/hermes-4-405b",
			"name": "nousresearch/hermes-4-405b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-4-405b:thinking": {
			"id": "nousresearch/hermes-4-405b:thinking",
			"name": "nousresearch/hermes-4-405b:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-4-70b": {
			"id": "nousresearch/hermes-4-70b",
			"name": "Nous: Hermes 4 70B",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.11,
				"output": 0.38,
				"cacheRead": 0.055,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"NousResearch/Hermes-4-70B:thinking": {
			"id": "NousResearch/Hermes-4-70B:thinking",
			"name": "NousResearch/Hermes-4-70B:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/Llama-3_3-Nemotron-Super-49B-v1_5": {
			"id": "nvidia/Llama-3_3-Nemotron-Super-49B-v1_5",
			"name": "nvidia/Llama-3_3-Nemotron-Super-49B-v1_5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
			"id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
			"name": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/Llama-3.1-Nemotron-Ultra-253B-v1": {
			"id": "nvidia/Llama-3.1-Nemotron-Ultra-253B-v1",
			"name": "nvidia/Llama-3.1-Nemotron-Ultra-253B-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/Llama-3.3-Nemotron-Super-49B-v1": {
			"id": "nvidia/Llama-3.3-Nemotron-Super-49B-v1",
			"name": "nvidia/Llama-3.3-Nemotron-Super-49B-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/nemotron-3-nano-30b-a3b": {
			"id": "nvidia/nemotron-3-nano-30b-a3b",
			"name": "nemotron-3-nano-30b-a3b",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.19999999999999998,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"nvidia/nvidia-nemotron-nano-9b-v2": {
			"id": "nvidia/nvidia-nemotron-nano-9b-v2",
			"name": "nvidia-nemotron-nano-9b-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"openai/chatgpt-4o-latest": {
			"id": "openai/chatgpt-4o-latest",
			"name": "openai/chatgpt-4o-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-3.5-turbo": {
			"id": "openai/gpt-3.5-turbo",
			"name": "OpenAI: GPT-3.5 Turbo",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4-turbo": {
			"id": "openai/gpt-4-turbo",
			"name": "GPT-4 Turbo",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4-turbo-preview": {
			"id": "openai/gpt-4-turbo-preview",
			"name": "OpenAI: GPT-4 Turbo Preview",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4.1": {
			"id": "openai/gpt-4.1",
			"name": "OpenAI: GPT-4.1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4.1-mini": {
			"id": "openai/gpt-4.1-mini",
			"name": "OpenAI: GPT-4.1 Mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.5999999999999999,
				"cacheRead": 0.09999999999999999,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4.1-nano": {
			"id": "openai/gpt-4.1-nano",
			"name": "OpenAI: GPT-4.1 Nano",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4o": {
			"id": "openai/gpt-4o",
			"name": "GPT-4o",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-2024-08-06": {
			"id": "openai/gpt-4o-2024-08-06",
			"name": "OpenAI: GPT-4o (2024-08-06)",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-2024-11-20": {
			"id": "openai/gpt-4o-2024-11-20",
			"name": "OpenAI: GPT-4o (2024-11-20)",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-mini": {
			"id": "openai/gpt-4o-mini",
			"name": "GPT-4o mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-mini-search-preview": {
			"id": "openai/gpt-4o-mini-search-preview",
			"name": "openai/gpt-4o-mini-search-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-search-preview": {
			"id": "openai/gpt-4o-search-preview",
			"name": "openai/gpt-4o-search-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5": {
			"id": "openai/gpt-5",
			"name": "OpenAI: GPT-5",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-chat-latest": {
			"id": "openai/gpt-5-chat-latest",
			"name": "openai/gpt-5-chat-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-codex": {
			"id": "openai/gpt-5-codex",
			"name": "OpenAI: GPT-5 Codex",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5-mini": {
			"id": "openai/gpt-5-mini",
			"name": "OpenAI: GPT-5 Mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-nano": {
			"id": "openai/gpt-5-nano",
			"name": "OpenAI: GPT-5 Nano",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.39999999999999997,
				"cacheRead": 0.005,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-pro": {
			"id": "openai/gpt-5-pro",
			"name": "OpenAI: GPT-5 Pro",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 120,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1": {
			"id": "openai/gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-2025-11-13": {
			"id": "openai/gpt-5.1-2025-11-13",
			"name": "openai/gpt-5.1-2025-11-13",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.1-chat": {
			"id": "openai/gpt-5.1-chat",
			"name": "OpenAI: GPT-5.1 Chat",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.1-chat-latest": {
			"id": "openai/gpt-5.1-chat-latest",
			"name": "openai/gpt-5.1-chat-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.1-codex": {
			"id": "openai/gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-max": {
			"id": "openai/gpt-5.1-codex-max",
			"name": "OpenAI: GPT-5.1-Codex-Max",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-mini": {
			"id": "openai/gpt-5.1-codex-mini",
			"name": "OpenAI: GPT-5.1-Codex-Mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 100000
		},
		"openai/gpt-5.2": {
			"id": "openai/gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-chat": {
			"id": "openai/gpt-5.2-chat",
			"name": "OpenAI: GPT-5.2 Chat",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.2-codex": {
			"id": "openai/gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-pro": {
			"id": "openai/gpt-5.2-pro",
			"name": "OpenAI: GPT-5.2 Pro",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 21,
				"output": 168,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.3-codex": {
			"id": "openai/gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-oss-120b": {
			"id": "openai/gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-20b": {
			"id": "openai/gpt-oss-20b",
			"name": "GPT OSS 20B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-safeguard-20b": {
			"id": "openai/gpt-oss-safeguard-20b",
			"name": "OpenAI: gpt-oss-safeguard-20b",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0.037,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o1": {
			"id": "openai/o1",
			"name": "o1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 60,
				"cacheRead": 7.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o1-preview": {
			"id": "openai/o1-preview",
			"name": "openai/o1-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o1-pro": {
			"id": "openai/o1-pro",
			"name": "openai/o1-pro",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3": {
			"id": "openai/o3",
			"name": "o3",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-deep-research": {
			"id": "openai/o3-deep-research",
			"name": "OpenAI: o3 Deep Research",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 40,
				"cacheRead": 2.5,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3-mini": {
			"id": "openai/o3-mini",
			"name": "o3-mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-mini-high": {
			"id": "openai/o3-mini-high",
			"name": "OpenAI: o3 Mini High",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3-mini-low": {
			"id": "openai/o3-mini-low",
			"name": "openai/o3-mini-low",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3-pro-2025-06-10": {
			"id": "openai/o3-pro-2025-06-10",
			"name": "openai/o3-pro-2025-06-10",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o4-mini": {
			"id": "openai/o4-mini",
			"name": "o4-mini",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.275,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini-deep-research": {
			"id": "openai/o4-mini-deep-research",
			"name": "OpenAI: o4 Mini Deep Research",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o4-mini-high": {
			"id": "openai/o4-mini-high",
			"name": "OpenAI: o4 Mini High",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.275,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"pamanseau/OpenReasoning-Nemotron-32B": {
			"id": "pamanseau/OpenReasoning-Nemotron-32B",
			"name": "pamanseau/OpenReasoning-Nemotron-32B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"phi-4-mini-instruct": {
			"id": "phi-4-mini-instruct",
			"name": "phi-4-mini-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"phi-4-multimodal-instruct": {
			"id": "phi-4-multimodal-instruct",
			"name": "phi-4-multimodal-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qvq-max": {
			"id": "qvq-max",
			"name": "qvq-max",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen-long": {
			"id": "qwen-long",
			"name": "qwen-long",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen-max": {
			"id": "qwen-max",
			"name": "qwen-max",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen-plus": {
			"id": "qwen-plus",
			"name": "qwen-plus",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen-turbo": {
			"id": "qwen-turbo",
			"name": "qwen-turbo",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-2.5-72b-instruct": {
			"id": "qwen/qwen-2.5-72b-instruct",
			"name": "Qwen2.5 72B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.12,
				"output": 0.39,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Qwen/Qwen2.5-Coder-32B-Instruct": {
			"id": "Qwen/Qwen2.5-Coder-32B-Instruct",
			"name": "Qwen/Qwen2.5-Coder-32B-Instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-14b": {
			"id": "qwen/qwen3-14b",
			"name": "Qwen: Qwen3 14B",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.06,
				"output": 0.24,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Qwen/Qwen3-235B-A22B": {
			"id": "Qwen/Qwen3-235B-A22B",
			"name": "Qwen/Qwen3-235B-A22B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Qwen/Qwen3-235B-A22B-Instruct-2507-TEE": {
			"id": "Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
			"name": "Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Qwen/Qwen3-235B-A22B-Thinking-2507": {
			"id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
			"name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-30b-a3b": {
			"id": "qwen/qwen3-30b-a3b",
			"name": "Qwen: Qwen3 30B A3B",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.08,
				"output": 0.28,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-32b": {
			"id": "qwen/qwen3-32b",
			"name": "Qwen3 32B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.29,
				"output": 0.59,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"Qwen/Qwen3-8B": {
			"id": "Qwen/Qwen3-8B",
			"name": "Qwen/Qwen3-8B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder": {
			"id": "qwen/qwen3-coder",
			"name": "Qwen: Qwen3 Coder 480B A35B",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.22,
				"output": 1,
				"cacheRead": 0.022,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 4096
		},
		"qwen/qwen3-coder-flash": {
			"id": "qwen/qwen3-coder-flash",
			"name": "Qwen: Qwen3 Coder Flash",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.5,
				"cacheRead": 0.06,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"qwen/qwen3-coder-next": {
			"id": "qwen/qwen3-coder-next",
			"name": "Qwen: Qwen3 Coder Next",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.12,
				"output": 0.75,
				"cacheRead": 0.06,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3-coder-plus": {
			"id": "qwen/qwen3-coder-plus",
			"name": "Qwen: Qwen3 Coder Plus",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"qwen/qwen3-max": {
			"id": "qwen/qwen3-max",
			"name": "Qwen: Qwen3 Max",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.2,
				"output": 6,
				"cacheRead": 0.24,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"Qwen/Qwen3-Next-80B-A3B-Instruct": {
			"id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
			"name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-next-80b-a3b-thinking": {
			"id": "qwen/qwen3-next-80b-a3b-thinking",
			"name": "Qwen3-Next-80B-A3B-Thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"Qwen/Qwen3-VL-235B-A22B-Instruct": {
			"id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
			"name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-397b-a17b": {
			"id": "qwen/qwen3.5-397b-a17b",
			"name": "Qwen: Qwen3.5 397B A17B",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 1,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3.5-397b-a17b-thinking": {
			"id": "qwen/qwen3.5-397b-a17b-thinking",
			"name": "qwen/qwen3.5-397b-a17b-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-plus": {
			"id": "qwen/qwen3.5-plus",
			"name": "qwen/qwen3.5-plus",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-plus-thinking": {
			"id": "qwen/qwen3.5-plus-thinking",
			"name": "qwen/qwen3.5-plus-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwq-32b-preview": {
			"id": "qwen/qwq-32b-preview",
			"name": "qwen/qwq-32b-preview",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Qwen2.5-32B-EVA-v0.2": {
			"id": "Qwen2.5-32B-EVA-v0.2",
			"name": "Qwen2.5-32B-EVA-v0.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen25-vl-72b-instruct": {
			"id": "qwen25-vl-72b-instruct",
			"name": "qwen25-vl-72b-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3-30b-a3b-instruct-2507": {
			"id": "qwen3-30b-a3b-instruct-2507",
			"name": "qwen3-30b-a3b-instruct-2507",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3-coder-30b-a3b-instruct": {
			"id": "qwen3-coder-30b-a3b-instruct",
			"name": "qwen3-coder-30b-a3b-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3-max-2026-01-23": {
			"id": "qwen3-max-2026-01-23",
			"name": "qwen3-max-2026-01-23",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3-vl-235b-a22b-instruct-original": {
			"id": "qwen3-vl-235b-a22b-instruct-original",
			"name": "qwen3-vl-235b-a22b-instruct-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3-vl-235b-a22b-thinking": {
			"id": "qwen3-vl-235b-a22b-thinking",
			"name": "qwen3-vl-235b-a22b-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-122b-a10b": {
			"id": "qwen3.5-122b-a10b",
			"name": "qwen3.5-122b-a10b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-122b-a10b:thinking": {
			"id": "qwen3.5-122b-a10b:thinking",
			"name": "qwen3.5-122b-a10b:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-27b": {
			"id": "qwen3.5-27b",
			"name": "qwen3.5-27b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-27b:thinking": {
			"id": "qwen3.5-27b:thinking",
			"name": "qwen3.5-27b:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-35b-a3b": {
			"id": "qwen3.5-35b-a3b",
			"name": "qwen3.5-35b-a3b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-35b-a3b:thinking": {
			"id": "qwen3.5-35b-a3b:thinking",
			"name": "qwen3.5-35b-a3b:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-flash": {
			"id": "qwen3.5-flash",
			"name": "qwen3.5-flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen3.5-flash:thinking": {
			"id": "qwen3.5-flash:thinking",
			"name": "qwen3.5-flash:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwq-32b": {
			"id": "qwq-32b",
			"name": "qwq-32b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"QwQ-32B-ArliAI-RpR-v1": {
			"id": "QwQ-32B-ArliAI-RpR-v1",
			"name": "QwQ-32B-ArliAI-RpR-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"raifle/sorcererlm-8x22b": {
			"id": "raifle/sorcererlm-8x22b",
			"name": "raifle/sorcererlm-8x22b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ReadyArt/MS3.2-The-Omega-Directive-24B-Unslop-v2.0": {
			"id": "ReadyArt/MS3.2-The-Omega-Directive-24B-Unslop-v2.0",
			"name": "ReadyArt/MS3.2-The-Omega-Directive-24B-Unslop-v2.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ReadyArt/The-Omega-Abomination-L-70B-v1.0": {
			"id": "ReadyArt/The-Omega-Abomination-L-70B-v1.0",
			"name": "ReadyArt/The-Omega-Abomination-L-70B-v1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Salesforce/Llama-xLAM-2-70b-fc-r": {
			"id": "Salesforce/Llama-xLAM-2-70b-fc-r",
			"name": "Salesforce/Llama-xLAM-2-70b-fc-r",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Sao10K/L3-8B-Stheno-v3.2": {
			"id": "Sao10K/L3-8B-Stheno-v3.2",
			"name": "Sao10K/L3-8B-Stheno-v3.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Sao10K/L3.1-70B-Euryale-v2.2": {
			"id": "Sao10K/L3.1-70B-Euryale-v2.2",
			"name": "Sao10K/L3.1-70B-Euryale-v2.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Sao10K/L3.1-70B-Hanami-x1": {
			"id": "Sao10K/L3.1-70B-Hanami-x1",
			"name": "Sao10K/L3.1-70B-Hanami-x1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Sao10K/L3.3-70B-Euryale-v2.3": {
			"id": "Sao10K/L3.3-70B-Euryale-v2.3",
			"name": "Sao10K/L3.3-70B-Euryale-v2.3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sarvan-medium": {
			"id": "sarvan-medium",
			"name": "sarvan-medium",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"shisa-ai/shisa-v2-llama3.3-70b": {
			"id": "shisa-ai/shisa-v2-llama3.3-70b",
			"name": "shisa-ai/shisa-v2-llama3.3-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"shisa-ai/shisa-v2.1-llama3.3-70b": {
			"id": "shisa-ai/shisa-v2.1-llama3.3-70b",
			"name": "shisa-ai/shisa-v2.1-llama3.3-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sonar": {
			"id": "sonar",
			"name": "sonar",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sonar-deep-research": {
			"id": "sonar-deep-research",
			"name": "sonar-deep-research",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sonar-pro": {
			"id": "sonar-pro",
			"name": "sonar-pro",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sonar-reasoning-pro": {
			"id": "sonar-reasoning-pro",
			"name": "sonar-reasoning-pro",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"soob3123/amoral-gemma3-27B-v2": {
			"id": "soob3123/amoral-gemma3-27B-v2",
			"name": "soob3123/amoral-gemma3-27B-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"soob3123/GrayLine-Qwen3-8B": {
			"id": "soob3123/GrayLine-Qwen3-8B",
			"name": "soob3123/GrayLine-Qwen3-8B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"soob3123/Veiled-Calla-12B": {
			"id": "soob3123/Veiled-Calla-12B",
			"name": "soob3123/Veiled-Calla-12B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Steelskull/L3.3-Cu-Mai-R1-70b": {
			"id": "Steelskull/L3.3-Cu-Mai-R1-70b",
			"name": "Steelskull/L3.3-Cu-Mai-R1-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Steelskull/L3.3-Electra-R1-70b": {
			"id": "Steelskull/L3.3-Electra-R1-70b",
			"name": "Steelskull/L3.3-Electra-R1-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Steelskull/L3.3-MS-Evalebis-70b": {
			"id": "Steelskull/L3.3-MS-Evalebis-70b",
			"name": "Steelskull/L3.3-MS-Evalebis-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Steelskull/L3.3-MS-Evayale-70B": {
			"id": "Steelskull/L3.3-MS-Evayale-70B",
			"name": "Steelskull/L3.3-MS-Evayale-70B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Steelskull/L3.3-MS-Nevoria-70b": {
			"id": "Steelskull/L3.3-MS-Nevoria-70b",
			"name": "Steelskull/L3.3-MS-Nevoria-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"Steelskull/L3.3-Nevoria-R1-70b": {
			"id": "Steelskull/L3.3-Nevoria-R1-70b",
			"name": "Steelskull/L3.3-Nevoria-R1-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"step-2-16k-exp": {
			"id": "step-2-16k-exp",
			"name": "step-2-16k-exp",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"step-2-mini": {
			"id": "step-2-mini",
			"name": "step-2-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"step-3": {
			"id": "step-3",
			"name": "step-3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"step-r1-v-mini": {
			"id": "step-r1-v-mini",
			"name": "step-r1-v-mini",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"stepfun-ai/step-3.5-flash": {
			"id": "stepfun-ai/step-3.5-flash",
			"name": "stepfun-ai/step-3.5-flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"stepfun-ai/step-3.5-flash:thinking": {
			"id": "stepfun-ai/step-3.5-flash:thinking",
			"name": "stepfun-ai/step-3.5-flash:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"study_gpt-chatgpt-4o-latest": {
			"id": "study_gpt-chatgpt-4o-latest",
			"name": "study_gpt-chatgpt-4o-latest",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/deepseek-r1-0528": {
			"id": "TEE/deepseek-r1-0528",
			"name": "TEE/deepseek-r1-0528",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/deepseek-v3.1": {
			"id": "TEE/deepseek-v3.1",
			"name": "TEE/deepseek-v3.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/deepseek-v3.2": {
			"id": "TEE/deepseek-v3.2",
			"name": "TEE/deepseek-v3.2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/gemma-3-27b-it": {
			"id": "TEE/gemma-3-27b-it",
			"name": "TEE/gemma-3-27b-it",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/glm-4.6": {
			"id": "TEE/glm-4.6",
			"name": "TEE/glm-4.6",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/glm-4.7": {
			"id": "TEE/glm-4.7",
			"name": "TEE/glm-4.7",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/glm-4.7-flash": {
			"id": "TEE/glm-4.7-flash",
			"name": "TEE/glm-4.7-flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/glm-5": {
			"id": "TEE/glm-5",
			"name": "TEE/glm-5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/gpt-oss-120b": {
			"id": "TEE/gpt-oss-120b",
			"name": "TEE/gpt-oss-120b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/gpt-oss-20b": {
			"id": "TEE/gpt-oss-20b",
			"name": "TEE/gpt-oss-20b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/kimi-k2-thinking": {
			"id": "TEE/kimi-k2-thinking",
			"name": "TEE/kimi-k2-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/kimi-k2.5": {
			"id": "TEE/kimi-k2.5",
			"name": "TEE/kimi-k2.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/kimi-k2.5-thinking": {
			"id": "TEE/kimi-k2.5-thinking",
			"name": "TEE/kimi-k2.5-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/llama3-3-70b": {
			"id": "TEE/llama3-3-70b",
			"name": "TEE/llama3-3-70b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/minimax-m2.1": {
			"id": "TEE/minimax-m2.1",
			"name": "TEE/minimax-m2.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/qwen2.5-vl-72b-instruct": {
			"id": "TEE/qwen2.5-vl-72b-instruct",
			"name": "TEE/qwen2.5-vl-72b-instruct",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/qwen3-30b-a3b-instruct-2507": {
			"id": "TEE/qwen3-30b-a3b-instruct-2507",
			"name": "TEE/qwen3-30b-a3b-instruct-2507",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/qwen3-coder": {
			"id": "TEE/qwen3-coder",
			"name": "TEE/qwen3-coder",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TEE/qwen3.5-397b-a17b": {
			"id": "TEE/qwen3.5-397b-a17b",
			"name": "TEE/qwen3.5-397b-a17b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"tencent/Hunyuan-MT-7B": {
			"id": "tencent/Hunyuan-MT-7B",
			"name": "tencent/Hunyuan-MT-7B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Anubis-70B-v1": {
			"id": "TheDrummer/Anubis-70B-v1",
			"name": "TheDrummer/Anubis-70B-v1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Anubis-70B-v1.1": {
			"id": "TheDrummer/Anubis-70B-v1.1",
			"name": "TheDrummer/Anubis-70B-v1.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Cydonia-24B-v2": {
			"id": "TheDrummer/Cydonia-24B-v2",
			"name": "TheDrummer/Cydonia-24B-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Cydonia-24B-v4": {
			"id": "TheDrummer/Cydonia-24B-v4",
			"name": "TheDrummer/Cydonia-24B-v4",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Cydonia-24B-v4.1": {
			"id": "TheDrummer/Cydonia-24B-v4.1",
			"name": "TheDrummer/Cydonia-24B-v4.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Cydonia-24B-v4.3": {
			"id": "TheDrummer/Cydonia-24B-v4.3",
			"name": "TheDrummer/Cydonia-24B-v4.3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Magidonia-24B-v4.3": {
			"id": "TheDrummer/Magidonia-24B-v4.3",
			"name": "TheDrummer/Magidonia-24B-v4.3",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/Rocinante-12B-v1.1": {
			"id": "TheDrummer/Rocinante-12B-v1.1",
			"name": "TheDrummer/Rocinante-12B-v1.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"thedrummer/skyfall-36b-v2": {
			"id": "thedrummer/skyfall-36b-v2",
			"name": "thedrummer/skyfall-36b-v2",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"TheDrummer/UnslopNemo-12B-v4.1": {
			"id": "TheDrummer/UnslopNemo-12B-v4.1",
			"name": "TheDrummer/UnslopNemo-12B-v4.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"THUDM/GLM-4-32B-0414": {
			"id": "THUDM/GLM-4-32B-0414",
			"name": "THUDM/GLM-4-32B-0414",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"THUDM/GLM-4-9B-0414": {
			"id": "THUDM/GLM-4-9B-0414",
			"name": "THUDM/GLM-4-9B-0414",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"THUDM/GLM-Z1-32B-0414": {
			"id": "THUDM/GLM-Z1-32B-0414",
			"name": "THUDM/GLM-Z1-32B-0414",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"THUDM/GLM-Z1-9B-0414": {
			"id": "THUDM/GLM-Z1-9B-0414",
			"name": "THUDM/GLM-Z1-9B-0414",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"THUDM/GLM-Z1-Rumination-32B-0414": {
			"id": "THUDM/GLM-Z1-Rumination-32B-0414",
			"name": "THUDM/GLM-Z1-Rumination-32B-0414",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"tngtech/DeepSeek-TNG-R1T2-Chimera": {
			"id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
			"name": "tngtech/DeepSeek-TNG-R1T2-Chimera",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"tngtech/tng-r1t-chimera": {
			"id": "tngtech/tng-r1t-chimera",
			"name": "TNG: R1T Chimera",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 0.85,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 65536
		},
		"Tongyi-Zhiwen/QwenLong-L1-32B": {
			"id": "Tongyi-Zhiwen/QwenLong-L1-32B",
			"name": "Tongyi-Zhiwen/QwenLong-L1-32B",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"undi95/remm-slerp-l2-13b": {
			"id": "undi95/remm-slerp-l2-13b",
			"name": "undi95/remm-slerp-l2-13b",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"universal-summarizer": {
			"id": "universal-summarizer",
			"name": "universal-summarizer",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"unsloth/gemma-3-12b-it": {
			"id": "unsloth/gemma-3-12b-it",
			"name": "unsloth/gemma-3-12b-it",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"unsloth/gemma-3-1b-it": {
			"id": "unsloth/gemma-3-1b-it",
			"name": "unsloth/gemma-3-1b-it",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"unsloth/gemma-3-27b-it": {
			"id": "unsloth/gemma-3-27b-it",
			"name": "unsloth/gemma-3-27b-it",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"unsloth/gemma-3-4b-it": {
			"id": "unsloth/gemma-3-4b-it",
			"name": "unsloth/gemma-3-4b-it",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"v0-1.0-md": {
			"id": "v0-1.0-md",
			"name": "v0-1.0-md",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"v0-1.5-lg": {
			"id": "v0-1.5-lg",
			"name": "v0-1.5-lg",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"v0-1.5-md": {
			"id": "v0-1.5-md",
			"name": "v0-1.5-md",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"venice-uncensored": {
			"id": "venice-uncensored",
			"name": "Venice Uncensored 1.1",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"venice-uncensored:web": {
			"id": "venice-uncensored:web",
			"name": "venice-uncensored:web",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"VongolaChouko/Starcannon-Unleashed-12B-v1.0": {
			"id": "VongolaChouko/Starcannon-Unleashed-12B-v1.0",
			"name": "VongolaChouko/Starcannon-Unleashed-12B-v1.0",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-4-07-09": {
			"id": "x-ai/grok-4-07-09",
			"name": "x-ai/grok-4-07-09",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-4-fast": {
			"id": "x-ai/grok-4-fast",
			"name": "xAI: Grok 4 Fast",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"x-ai/grok-4-fast:thinking": {
			"id": "x-ai/grok-4-fast:thinking",
			"name": "x-ai/grok-4-fast:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-4.1-fast": {
			"id": "x-ai/grok-4.1-fast",
			"name": "xAI: Grok 4.1 Fast",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"x-ai/grok-4.1-fast-reasoning": {
			"id": "x-ai/grok-4.1-fast-reasoning",
			"name": "x-ai/grok-4.1-fast-reasoning",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-code-fast-1": {
			"id": "x-ai/grok-code-fast-1",
			"name": "xAI: Grok Code Fast 1",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 1.5,
				"cacheRead": 0.02,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 10000
		},
		"xiaomi/mimo-v2-flash": {
			"id": "xiaomi/mimo-v2-flash",
			"name": "Xiaomi: MiMo-V2-Flash",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09,
				"output": 0.29,
				"cacheRead": 0.045,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 4096
		},
		"xiaomi/mimo-v2-flash-original": {
			"id": "xiaomi/mimo-v2-flash-original",
			"name": "xiaomi/mimo-v2-flash-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"xiaomi/mimo-v2-flash-thinking": {
			"id": "xiaomi/mimo-v2-flash-thinking",
			"name": "xiaomi/mimo-v2-flash-thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"xiaomi/mimo-v2-flash-thinking-original": {
			"id": "xiaomi/mimo-v2-flash-thinking-original",
			"name": "xiaomi/mimo-v2-flash-thinking-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"yi-large": {
			"id": "yi-large",
			"name": "yi-large",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"yi-lightning": {
			"id": "yi-lightning",
			"name": "yi-lightning",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"yi-medium-200k": {
			"id": "yi-medium-200k",
			"name": "yi-medium-200k",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.5v": {
			"id": "z-ai/glm-4.5v",
			"name": "Z.ai: GLM 4.5V",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.6,
				"output": 1.7999999999999998,
				"cacheRead": 0.11,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.5v:thinking": {
			"id": "z-ai/glm-4.5v:thinking",
			"name": "z-ai/glm-4.5v:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.6": {
			"id": "z-ai/glm-4.6",
			"name": "Z.ai: GLM 4.6",
			"api": "openai-completions",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"provider": "nanogpt",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.35,
				"output": 1.71,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.6:thinking": {
			"id": "z-ai/glm-4.6:thinking",
			"name": "z-ai/glm-4.6:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.5": {
			"id": "zai-org/glm-4.5",
			"name": "zai-org/glm-4.5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/GLM-4.5-Air": {
			"id": "zai-org/GLM-4.5-Air",
			"name": "zai-org/GLM-4.5-Air",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/GLM-4.5-Air:thinking": {
			"id": "zai-org/GLM-4.5-Air:thinking",
			"name": "zai-org/GLM-4.5-Air:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/GLM-4.5:thinking": {
			"id": "zai-org/GLM-4.5:thinking",
			"name": "zai-org/GLM-4.5:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.6-original": {
			"id": "zai-org/glm-4.6-original",
			"name": "zai-org/glm-4.6-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/GLM-4.6-turbo": {
			"id": "zai-org/GLM-4.6-turbo",
			"name": "zai-org/GLM-4.6-turbo",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/GLM-4.6-turbo:thinking": {
			"id": "zai-org/GLM-4.6-turbo:thinking",
			"name": "zai-org/GLM-4.6-turbo:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.6v": {
			"id": "zai-org/glm-4.6v",
			"name": "zai-org/glm-4.6v",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.6v-flash-original": {
			"id": "zai-org/glm-4.6v-flash-original",
			"name": "zai-org/glm-4.6v-flash-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.6v-original": {
			"id": "zai-org/glm-4.6v-original",
			"name": "zai-org/glm-4.6v-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7": {
			"id": "zai-org/glm-4.7",
			"name": "zai-org/glm-4.7",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7-flash": {
			"id": "zai-org/glm-4.7-flash",
			"name": "zai-org/glm-4.7-flash",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7-flash-original": {
			"id": "zai-org/glm-4.7-flash-original",
			"name": "zai-org/glm-4.7-flash-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7-flash-original:thinking": {
			"id": "zai-org/glm-4.7-flash-original:thinking",
			"name": "zai-org/glm-4.7-flash-original:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7-flash:thinking": {
			"id": "zai-org/glm-4.7-flash:thinking",
			"name": "zai-org/glm-4.7-flash:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7-original": {
			"id": "zai-org/glm-4.7-original",
			"name": "zai-org/glm-4.7-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7-original:thinking": {
			"id": "zai-org/glm-4.7-original:thinking",
			"name": "zai-org/glm-4.7-original:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-4.7:thinking": {
			"id": "zai-org/glm-4.7:thinking",
			"name": "zai-org/glm-4.7:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-5": {
			"id": "zai-org/glm-5",
			"name": "zai-org/glm-5",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-5-original": {
			"id": "zai-org/glm-5-original",
			"name": "zai-org/glm-5-original",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-5-original:thinking": {
			"id": "zai-org/glm-5-original:thinking",
			"name": "zai-org/glm-5-original:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"zai-org/glm-5:thinking": {
			"id": "zai-org/glm-5:thinking",
			"name": "zai-org/glm-5:thinking",
			"api": "openai-completions",
			"provider": "nanogpt",
			"baseUrl": "https://nano-gpt.com/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		}
	},
	"openrouter": {
		"ai21/jamba-large-1.7": {
			"id": "ai21/jamba-large-1.7",
			"name": "AI21: Jamba Large 1.7",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 4096
		},
		"alibaba/tongyi-deepresearch-30b-a3b": {
			"id": "alibaba/tongyi-deepresearch-30b-a3b",
			"name": "Tongyi DeepResearch 30B A3B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09,
				"output": 0.44999999999999996,
				"cacheRead": 0.09,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"allenai/olmo-3.1-32b-instruct": {
			"id": "allenai/olmo-3.1-32b-instruct",
			"name": "AllenAI: Olmo 3.1 32B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 65536,
			"maxTokens": 8888
		},
		"amazon/nova-2-lite-v1": {
			"id": "amazon/nova-2-lite-v1",
			"name": "Amazon: Nova 2 Lite",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65535
		},
		"amazon/nova-lite-v1": {
			"id": "amazon/nova-lite-v1",
			"name": "Amazon: Nova Lite 1.0",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.06,
				"output": 0.24,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 300000,
			"maxTokens": 5120,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"amazon/nova-micro-v1": {
			"id": "amazon/nova-micro-v1",
			"name": "Amazon: Nova Micro 1.0",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.035,
				"output": 0.14,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 5120,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"amazon/nova-premier-v1": {
			"id": "amazon/nova-premier-v1",
			"name": "Amazon: Nova Premier 1.0",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 12.5,
				"cacheRead": 0.625,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 32000,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"amazon/nova-pro-v1": {
			"id": "amazon/nova-pro-v1",
			"name": "Amazon: Nova Pro 1.0",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.7999999999999999,
				"output": 3.1999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 300000,
			"maxTokens": 5120,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"anthropic/claude-3-haiku": {
			"id": "anthropic/claude-3-haiku",
			"name": "Claude Haiku 3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 1.25,
				"cacheRead": 0.03,
				"cacheWrite": 0.3
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic/claude-3.5-haiku": {
			"id": "anthropic/claude-3.5-haiku",
			"name": "Claude Haiku 3.5 (latest)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.7999999999999999,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.5-sonnet": {
			"id": "anthropic/claude-3.5-sonnet",
			"name": "Claude Sonnet 3.5 v2",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 6,
				"output": 30,
				"cacheRead": 0.6,
				"cacheWrite": 7.5
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.7-sonnet": {
			"id": "anthropic/claude-3.7-sonnet",
			"name": "Anthropic: Claude 3.7 Sonnet",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-3.7-sonnet:thinking": {
			"id": "anthropic/claude-3.7-sonnet:thinking",
			"name": "Anthropic: Claude 3.7 Sonnet (thinking)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-haiku-4.5": {
			"id": "anthropic/claude-haiku-4.5",
			"name": "Anthropic: Claude Haiku 4.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.09999999999999999,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-opus-4": {
			"id": "anthropic/claude-opus-4",
			"name": "Claude Opus 4 (latest)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4.1": {
			"id": "anthropic/claude-opus-4.1",
			"name": "Anthropic: Claude Opus 4.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4.5": {
			"id": "anthropic/claude-opus-4.5",
			"name": "Anthropic: Claude Opus 4.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-opus-4.6": {
			"id": "anthropic/claude-opus-4.6",
			"name": "Anthropic: Claude Opus 4.6",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"anthropic/claude-sonnet-4": {
			"id": "anthropic/claude-sonnet-4",
			"name": "Claude Sonnet 4 (latest)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4.5": {
			"id": "anthropic/claude-sonnet-4.5",
			"name": "Anthropic: Claude Sonnet 4.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4.6": {
			"id": "anthropic/claude-sonnet-4.6",
			"name": "Anthropic: Claude Sonnet 4.6",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"arcee-ai/trinity-large-preview:free": {
			"id": "arcee-ai/trinity-large-preview:free",
			"name": "Arcee AI: Trinity Large Preview (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 8888,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"arcee-ai/trinity-mini": {
			"id": "arcee-ai/trinity-mini",
			"name": "Arcee AI: Trinity Mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.045,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"arcee-ai/trinity-mini:free": {
			"id": "arcee-ai/trinity-mini:free",
			"name": "Arcee AI: Trinity Mini (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"arcee-ai/virtuoso-large": {
			"id": "arcee-ai/virtuoso-large",
			"name": "Arcee AI: Virtuoso Large",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.75,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 64000
		},
		"auto": {
			"id": "auto",
			"name": "Auto",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"baidu/ernie-4.5-21b-a3b": {
			"id": "baidu/ernie-4.5-21b-a3b",
			"name": "Baidu: ERNIE 4.5 21B A3B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.28,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 120000,
			"maxTokens": 8000
		},
		"baidu/ernie-4.5-vl-28b-a3b": {
			"id": "baidu/ernie-4.5-vl-28b-a3b",
			"name": "Baidu: ERNIE 4.5 VL 28B A3B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.14,
				"output": 0.56,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 30000,
			"maxTokens": 8000
		},
		"bytedance-seed/seed-1.6": {
			"id": "bytedance-seed/seed-1.6",
			"name": "ByteDance Seed: Seed 1.6",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32768
		},
		"bytedance-seed/seed-1.6-flash": {
			"id": "bytedance-seed/seed-1.6-flash",
			"name": "ByteDance Seed: Seed 1.6 Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32768
		},
		"bytedance-seed/seed-2.0-mini": {
			"id": "bytedance-seed/seed-2.0-mini",
			"name": "ByteDance Seed: Seed-2.0-Mini",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 131072
		},
		"cohere/command-r-08-2024": {
			"id": "cohere/command-r-08-2024",
			"name": "Cohere: Command R (08-2024)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"cohere/command-r-plus-08-2024": {
			"id": "cohere/command-r-plus-08-2024",
			"name": "Cohere: Command R+ (08-2024)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"deepseek/deepseek-chat": {
			"id": "deepseek/deepseek-chat",
			"name": "DeepSeek: DeepSeek V3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.32,
				"output": 0.8899999999999999,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 163840
		},
		"deepseek/deepseek-chat-v3-0324": {
			"id": "deepseek/deepseek-chat-v3-0324",
			"name": "DeepSeek: DeepSeek V3 0324",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.77,
				"cacheRead": 0.135,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 8888
		},
		"deepseek/deepseek-chat-v3.1": {
			"id": "deepseek/deepseek-chat-v3.1",
			"name": "DeepSeek: DeepSeek V3.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.75,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 7168
		},
		"deepseek/deepseek-r1": {
			"id": "deepseek/deepseek-r1",
			"name": "DeepSeek: R1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.7,
				"output": 2.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 64000,
			"maxTokens": 16000
		},
		"deepseek/deepseek-r1-0528": {
			"id": "deepseek/deepseek-r1-0528",
			"name": "DeepSeek: R1 0528",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.44999999999999996,
				"output": 2.1500000000000004,
				"cacheRead": 0.22499999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 65536
		},
		"deepseek/deepseek-v3.1-terminus": {
			"id": "deepseek/deepseek-v3.1-terminus",
			"name": "DeepSeek: DeepSeek V3.1 Terminus",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.21,
				"output": 0.7899999999999999,
				"cacheRead": 0.1300000002,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.1-terminus:exacto": {
			"id": "deepseek/deepseek-v3.1-terminus:exacto",
			"name": "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.21,
				"output": 0.7899999999999999,
				"cacheRead": 0.16799999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2": {
			"id": "deepseek/deepseek-v3.2",
			"name": "DeepSeek: DeepSeek V3.2",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 0.39999999999999997,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 163840
		},
		"deepseek/deepseek-v3.2-exp": {
			"id": "deepseek/deepseek-v3.2-exp",
			"name": "DeepSeek: DeepSeek V3.2 Exp",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.27,
				"output": 0.41,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 65536
		},
		"google/gemini-2.0-flash-001": {
			"id": "google/gemini-2.0-flash-001",
			"name": "Google: Gemini 2.0 Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"google/gemini-2.0-flash-lite-001": {
			"id": "google/gemini-2.0-flash-lite-001",
			"name": "Google: Gemini 2.0 Flash Lite",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"google/gemini-2.5-flash": {
			"id": "google/gemini-2.5-flash",
			"name": "Google: Gemini 2.5 Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.03,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"google/gemini-2.5-flash-lite": {
			"id": "google/gemini-2.5-flash-lite",
			"name": "Google: Gemini 2.5 Flash Lite",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.01,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"google/gemini-2.5-flash-lite-preview-09-2025": {
			"id": "google/gemini-2.5-flash-lite-preview-09-2025",
			"name": "Google: Gemini 2.5 Flash Lite Preview 09-2025",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.01,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"google/gemini-2.5-flash-preview-09-2025": {
			"id": "google/gemini-2.5-flash-preview-09-2025",
			"name": "Google: Gemini 2.5 Flash Preview 09-2025",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.03,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-2.5-pro": {
			"id": "google/gemini-2.5-pro",
			"name": "Google: Gemini 2.5 Pro",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-2.5-pro-preview": {
			"id": "google/gemini-2.5-pro-preview",
			"name": "Google: Gemini 2.5 Pro Preview 06-05",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-2.5-pro-preview-05-06": {
			"id": "google/gemini-2.5-pro-preview-05-06",
			"name": "Google: Gemini 2.5 Pro Preview 05-06",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"google/gemini-3-flash-preview": {
			"id": "google/gemini-3-flash-preview",
			"name": "Google: Gemini 3 Flash Preview",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 3,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0.08333333333333334
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"google/gemini-3-pro-preview": {
			"id": "google/gemini-3-pro-preview",
			"name": "Google: Gemini 3 Pro Preview",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-3.1-pro-preview": {
			"id": "google/gemini-3.1-pro-preview",
			"name": "Google: Gemini 3.1 Pro Preview",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-3.1-pro-preview-customtools": {
			"id": "google/gemini-3.1-pro-preview-customtools",
			"name": "Google: Gemini 3.1 Pro Preview Custom Tools",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0.375
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemma-3-27b-it": {
			"id": "google/gemma-3-27b-it",
			"name": "Gemma-3-27B-IT",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.04,
				"output": 0.15,
				"cacheRead": 0.02,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"google/gemma-3-27b-it:free": {
			"id": "google/gemma-3-27b-it:free",
			"name": "Google: Gemma 3 27B (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"inception/mercury": {
			"id": "inception/mercury",
			"name": "Inception: Mercury",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"inception/mercury-coder": {
			"id": "inception/mercury-coder",
			"name": "Inception: Mercury Coder",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"kwaipilot/kat-coder-pro": {
			"id": "kwaipilot/kat-coder-pro",
			"name": "Kwaipilot: KAT-Coder-Pro V1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.207,
				"output": 0.828,
				"cacheRead": 0.0414,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 128000
		},
		"meituan/longcat-flash-chat": {
			"id": "meituan/longcat-flash-chat",
			"name": "Meituan: LongCat Flash Chat",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.7999999999999999,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"meta-llama/llama-3-8b-instruct": {
			"id": "meta-llama/llama-3-8b-instruct",
			"name": "Meta: Llama 3 8B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.03,
				"output": 0.04,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 16384
		},
		"meta-llama/llama-3.1-405b-instruct": {
			"id": "meta-llama/llama-3.1-405b-instruct",
			"name": "Meta: Llama 3.1 405B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 4,
				"output": 4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-70b-instruct": {
			"id": "meta-llama/llama-3.1-70b-instruct",
			"name": "Meta: Llama 3.1 70B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-8b-instruct": {
			"id": "meta-llama/llama-3.1-8b-instruct",
			"name": "Meta: Llama 3.1 8B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.02,
				"output": 0.049999999999999996,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 16384,
			"maxTokens": 16384
		},
		"meta-llama/llama-3.3-70b-instruct": {
			"id": "meta-llama/llama-3.3-70b-instruct",
			"name": "Meta: Llama 3.3 70B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.32,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"meta-llama/llama-3.3-70b-instruct:free": {
			"id": "meta-llama/llama-3.3-70b-instruct:free",
			"name": "Meta: Llama 3.3 70B Instruct (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"meta-llama/llama-4-maverick": {
			"id": "meta-llama/llama-4-maverick",
			"name": "Meta: Llama 4 Maverick",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 16384
		},
		"meta-llama/llama-4-scout": {
			"id": "meta-llama/llama-4-scout",
			"name": "Meta: Llama 4 Scout",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.08,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 327680,
			"maxTokens": 16384
		},
		"minimax/minimax-m1": {
			"id": "minimax/minimax-m1",
			"name": "MiniMax: MiniMax M1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 40000
		},
		"minimax/minimax-m2": {
			"id": "minimax/minimax-m2",
			"name": "MiniMax: MiniMax M2",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.255,
				"output": 1,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 65536
		},
		"minimax/minimax-m2.1": {
			"id": "minimax/minimax-m2.1",
			"name": "MiniMax: MiniMax M2.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.27,
				"output": 0.95,
				"cacheRead": 0.0299999997,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 8888
		},
		"minimax/minimax-m2.5": {
			"id": "minimax/minimax-m2.5",
			"name": "MiniMax: MiniMax M2.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.295,
				"output": 1.2,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 196608
		},
		"mistralai/codestral-2508": {
			"id": "mistralai/codestral-2508",
			"name": "Mistral: Codestral 2508",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.8999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8888
		},
		"mistralai/devstral-2512": {
			"id": "mistralai/devstral-2512",
			"name": "Mistral: Devstral 2 2512",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"mistralai/devstral-medium": {
			"id": "mistralai/devstral-medium",
			"name": "Mistral: Devstral Medium",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/devstral-small": {
			"id": "mistralai/devstral-small",
			"name": "Mistral: Devstral Small 1.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/ministral-14b-2512": {
			"id": "mistralai/ministral-14b-2512",
			"name": "Mistral: Ministral 3 14B 2512",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.19999999999999998,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"mistralai/ministral-3b-2512": {
			"id": "mistralai/ministral-3b-2512",
			"name": "Mistral: Ministral 3 3B 2512",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.09999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/ministral-8b-2512": {
			"id": "mistralai/ministral-8b-2512",
			"name": "Mistral: Ministral 3 8B 2512",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"mistralai/mistral-large": {
			"id": "mistralai/mistral-large",
			"name": "Mistral Large",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-2407": {
			"id": "mistralai/mistral-large-2407",
			"name": "Mistral Large 2407",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-2411": {
			"id": "mistralai/mistral-large-2411",
			"name": "Mistral Large 2411",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-2512": {
			"id": "mistralai/mistral-large-2512",
			"name": "Mistral: Mistral Large 3 2512",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"mistralai/mistral-medium-3": {
			"id": "mistralai/mistral-medium-3",
			"name": "Mistral: Mistral Medium 3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/mistral-medium-3.1": {
			"id": "mistralai/mistral-medium-3.1",
			"name": "Mistral: Mistral Medium 3.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/mistral-nemo": {
			"id": "mistralai/mistral-nemo",
			"name": "Mistral: Mistral Nemo",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.02,
				"output": 0.04,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"mistralai/mistral-saba": {
			"id": "mistralai/mistral-saba",
			"name": "Mistral: Saba",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-24b-instruct-2501": {
			"id": "mistralai/mistral-small-24b-instruct-2501",
			"name": "Mistral: Mistral Small 3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.08,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 16384
		},
		"mistralai/mistral-small-3.1-24b-instruct": {
			"id": "mistralai/mistral-small-3.1-24b-instruct",
			"name": "Mistral: Mistral Small 3.1 24B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.03,
				"output": 0.11,
				"cacheRead": 0.015,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"mistralai/mistral-small-3.1-24b-instruct:free": {
			"id": "mistralai/mistral-small-3.1-24b-instruct:free",
			"name": "Mistral: Mistral Small 3.1 24B (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-3.2-24b-instruct": {
			"id": "mistralai/mistral-small-3.2-24b-instruct",
			"name": "Mistral: Mistral Small 3.2 24B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.06,
				"output": 0.18,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"mistralai/mistral-small-creative": {
			"id": "mistralai/mistral-small-creative",
			"name": "Mistral: Mistral Small Creative",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 8888
		},
		"mistralai/mixtral-8x22b-instruct": {
			"id": "mistralai/mixtral-8x22b-instruct",
			"name": "Mistral: Mixtral 8x22B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 65536,
			"maxTokens": 8888
		},
		"mistralai/mixtral-8x7b-instruct": {
			"id": "mistralai/mixtral-8x7b-instruct",
			"name": "Mistral: Mixtral 8x7B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.54,
				"output": 0.54,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 16384
		},
		"mistralai/pixtral-large-2411": {
			"id": "mistralai/pixtral-large-2411",
			"name": "Mistral: Pixtral Large 2411",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"mistralai/voxtral-small-24b-2507": {
			"id": "mistralai/voxtral-small-24b-2507",
			"name": "Mistral: Voxtral Small 24B 2507",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2": {
			"id": "moonshotai/kimi-k2",
			"name": "MoonshotAI: Kimi K2 0711",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.55,
				"output": 2.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-0905": {
			"id": "moonshotai/kimi-k2-0905",
			"name": "MoonshotAI: Kimi K2 0905",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-0905:exacto": {
			"id": "moonshotai/kimi-k2-0905:exacto",
			"name": "MoonshotAI: Kimi K2 0905 (exacto)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-thinking": {
			"id": "moonshotai/kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.47,
				"output": 2,
				"cacheRead": 0.14100000000000001,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2.5": {
			"id": "moonshotai/kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.44999999999999996,
				"output": 2.2,
				"cacheRead": 0.22499999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"nex-agi/deepseek-v3.1-nex-n1": {
			"id": "nex-agi/deepseek-v3.1-nex-n1",
			"name": "Nex AGI: DeepSeek V3.1 Nex N1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.27,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 163840
		},
		"nousresearch/deephermes-3-mistral-24b-preview": {
			"id": "nousresearch/deephermes-3-mistral-24b-preview",
			"name": "Nous: DeepHermes 3 Mistral 24B Preview",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.02,
				"output": 0.09999999999999999,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"nousresearch/hermes-4-70b": {
			"id": "nousresearch/hermes-4-70b",
			"name": "Nous: Hermes 4 70B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.11,
				"output": 0.38,
				"cacheRead": 0.055,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"nvidia/llama-3.1-nemotron-70b-instruct": {
			"id": "nvidia/llama-3.1-nemotron-70b-instruct",
			"name": "Llama 3.1 Nemotron 70b Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.2,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia/llama-3.3-nemotron-super-49b-v1.5": {
			"id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
			"name": "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"nvidia/nemotron-3-nano-30b-a3b": {
			"id": "nvidia/nemotron-3-nano-30b-a3b",
			"name": "nemotron-3-nano-30b-a3b",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.19999999999999998,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"nvidia/nemotron-3-nano-30b-a3b:free": {
			"id": "nvidia/nemotron-3-nano-30b-a3b:free",
			"name": "NVIDIA: Nemotron 3 Nano 30B A3B (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8888
		},
		"nvidia/nemotron-nano-12b-v2-vl:free": {
			"id": "nvidia/nemotron-nano-12b-v2-vl:free",
			"name": "NVIDIA: Nemotron Nano 12B 2 VL (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 128000
		},
		"nvidia/nemotron-nano-9b-v2": {
			"id": "nvidia/nemotron-nano-9b-v2",
			"name": "NVIDIA: Nemotron Nano 9B V2",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.04,
				"output": 0.16,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"nvidia/nemotron-nano-9b-v2:free": {
			"id": "nvidia/nemotron-nano-9b-v2:free",
			"name": "NVIDIA: Nemotron Nano 9B V2 (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8888
		},
		"openai/gpt-3.5-turbo": {
			"id": "openai/gpt-3.5-turbo",
			"name": "OpenAI: GPT-3.5 Turbo",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 16385,
			"maxTokens": 4096
		},
		"openai/gpt-3.5-turbo-0613": {
			"id": "openai/gpt-3.5-turbo-0613",
			"name": "OpenAI: GPT-3.5 Turbo (older v0613)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4095,
			"maxTokens": 4096
		},
		"openai/gpt-3.5-turbo-16k": {
			"id": "openai/gpt-3.5-turbo-16k",
			"name": "OpenAI: GPT-3.5 Turbo 16k",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 16385,
			"maxTokens": 4096
		},
		"openai/gpt-4": {
			"id": "openai/gpt-4",
			"name": "GPT-4",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 30,
				"output": 60,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"openai/gpt-4-0314": {
			"id": "openai/gpt-4-0314",
			"name": "OpenAI: GPT-4 (older v0314)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 30,
				"output": 60,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8191,
			"maxTokens": 4096
		},
		"openai/gpt-4-1106-preview": {
			"id": "openai/gpt-4-1106-preview",
			"name": "OpenAI: GPT-4 Turbo (older v1106)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4-turbo": {
			"id": "openai/gpt-4-turbo",
			"name": "GPT-4 Turbo",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4-turbo-preview": {
			"id": "openai/gpt-4-turbo-preview",
			"name": "OpenAI: GPT-4 Turbo Preview",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4.1": {
			"id": "openai/gpt-4.1",
			"name": "OpenAI: GPT-4.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4.1-mini": {
			"id": "openai/gpt-4.1-mini",
			"name": "OpenAI: GPT-4.1 Mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.5999999999999999,
				"cacheRead": 0.09999999999999999,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4.1-nano": {
			"id": "openai/gpt-4.1-nano",
			"name": "OpenAI: GPT-4.1 Nano",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4o": {
			"id": "openai/gpt-4o",
			"name": "GPT-4o",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-2024-05-13": {
			"id": "openai/gpt-4o-2024-05-13",
			"name": "OpenAI: GPT-4o (2024-05-13)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4o-2024-08-06": {
			"id": "openai/gpt-4o-2024-08-06",
			"name": "OpenAI: GPT-4o (2024-08-06)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-2024-11-20": {
			"id": "openai/gpt-4o-2024-11-20",
			"name": "OpenAI: GPT-4o (2024-11-20)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-audio-preview": {
			"id": "openai/gpt-4o-audio-preview",
			"name": "OpenAI: GPT-4o Audio",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-mini": {
			"id": "openai/gpt-4o-mini",
			"name": "GPT-4o mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-mini-2024-07-18": {
			"id": "openai/gpt-4o-mini-2024-07-18",
			"name": "OpenAI: GPT-4o-mini (2024-07-18)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o:extended": {
			"id": "openai/gpt-4o:extended",
			"name": "OpenAI: GPT-4o (extended)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 6,
				"output": 18,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000
		},
		"openai/gpt-5": {
			"id": "openai/gpt-5",
			"name": "OpenAI: GPT-5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-codex": {
			"id": "openai/gpt-5-codex",
			"name": "OpenAI: GPT-5 Codex",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5-image": {
			"id": "openai/gpt-5-image",
			"name": "OpenAI: GPT-5 Image",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-image-mini": {
			"id": "openai/gpt-5-image-mini",
			"name": "OpenAI: GPT-5 Image Mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 2,
				"cacheRead": 0.25,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-mini": {
			"id": "openai/gpt-5-mini",
			"name": "OpenAI: GPT-5 Mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-nano": {
			"id": "openai/gpt-5-nano",
			"name": "OpenAI: GPT-5 Nano",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.39999999999999997,
				"cacheRead": 0.005,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-pro": {
			"id": "openai/gpt-5-pro",
			"name": "OpenAI: GPT-5 Pro",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 120,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1": {
			"id": "openai/gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-chat": {
			"id": "openai/gpt-5.1-chat",
			"name": "OpenAI: GPT-5.1 Chat",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5.1-codex": {
			"id": "openai/gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-max": {
			"id": "openai/gpt-5.1-codex-max",
			"name": "OpenAI: GPT-5.1-Codex-Max",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-mini": {
			"id": "openai/gpt-5.1-codex-mini",
			"name": "OpenAI: GPT-5.1-Codex-Mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 100000
		},
		"openai/gpt-5.2": {
			"id": "openai/gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-chat": {
			"id": "openai/gpt-5.2-chat",
			"name": "OpenAI: GPT-5.2 Chat",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5.2-codex": {
			"id": "openai/gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-pro": {
			"id": "openai/gpt-5.2-pro",
			"name": "OpenAI: GPT-5.2 Pro",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 21,
				"output": 168,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.3-codex": {
			"id": "openai/gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-oss-120b": {
			"id": "openai/gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.039,
				"output": 0.19,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-120b:exacto": {
			"id": "openai/gpt-oss-120b:exacto",
			"name": "OpenAI: gpt-oss-120b (exacto)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.039,
				"output": 0.19,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"openai/gpt-oss-120b:free": {
			"id": "openai/gpt-oss-120b:free",
			"name": "OpenAI: gpt-oss-120b (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"openai/gpt-oss-20b": {
			"id": "openai/gpt-oss-20b",
			"name": "GPT OSS 20B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.03,
				"output": 0.14,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-20b:free": {
			"id": "openai/gpt-oss-20b:free",
			"name": "OpenAI: gpt-oss-20b (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"openai/gpt-oss-safeguard-20b": {
			"id": "openai/gpt-oss-safeguard-20b",
			"name": "OpenAI: gpt-oss-safeguard-20b",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0.037,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/o1": {
			"id": "openai/o1",
			"name": "o1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 60,
				"cacheRead": 7.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3": {
			"id": "openai/o3",
			"name": "o3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-deep-research": {
			"id": "openai/o3-deep-research",
			"name": "OpenAI: o3 Deep Research",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 40,
				"cacheRead": 2.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-mini": {
			"id": "openai/o3-mini",
			"name": "o3-mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-mini-high": {
			"id": "openai/o3-mini-high",
			"name": "OpenAI: o3 Mini High",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-pro": {
			"id": "openai/o3-pro",
			"name": "o3-pro",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 20,
				"output": 80,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini": {
			"id": "openai/o4-mini",
			"name": "o4-mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.275,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini-deep-research": {
			"id": "openai/o4-mini-deep-research",
			"name": "OpenAI: o4 Mini Deep Research",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini-high": {
			"id": "openai/o4-mini-high",
			"name": "OpenAI: o4 Mini High",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.275,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openrouter/aurora-alpha": {
			"id": "openrouter/aurora-alpha",
			"name": "Aurora Alpha",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 50000
		},
		"openrouter/auto": {
			"id": "openrouter/auto",
			"name": "Auto Router",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": -1000000,
				"output": -1000000,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 8888
		},
		"openrouter/free": {
			"id": "openrouter/free",
			"name": "Free Models Router",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"prime-intellect/intellect-3": {
			"id": "prime-intellect/intellect-3",
			"name": "Prime Intellect: INTELLECT-3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 1.1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"qwen/qwen-2.5-72b-instruct": {
			"id": "qwen/qwen-2.5-72b-instruct",
			"name": "Qwen2.5 72B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.12,
				"output": 0.39,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 16384
		},
		"qwen/qwen-2.5-7b-instruct": {
			"id": "qwen/qwen-2.5-7b-instruct",
			"name": "Qwen: Qwen2.5 7B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.04,
				"output": 0.09999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 8888
		},
		"qwen/qwen-max": {
			"id": "qwen/qwen-max",
			"name": "Qwen: Qwen-Max",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.5999999999999999,
				"output": 6.3999999999999995,
				"cacheRead": 0.32,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 8192
		},
		"qwen/qwen-plus": {
			"id": "qwen/qwen-plus",
			"name": "Qwen: Qwen-Plus",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.2,
				"cacheRead": 0.08,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 32768
		},
		"qwen/qwen-plus-2025-07-28": {
			"id": "qwen/qwen-plus-2025-07-28",
			"name": "Qwen: Qwen Plus 0728",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 32768
		},
		"qwen/qwen-plus-2025-07-28:thinking": {
			"id": "qwen/qwen-plus-2025-07-28:thinking",
			"name": "Qwen: Qwen Plus 0728 (thinking)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 32768
		},
		"qwen/qwen-turbo": {
			"id": "qwen/qwen-turbo",
			"name": "Qwen: Qwen-Turbo",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.19999999999999998,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"qwen/qwen-vl-max": {
			"id": "qwen/qwen-vl-max",
			"name": "Qwen: Qwen VL Max",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.7999999999999999,
				"output": 3.1999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3-14b": {
			"id": "qwen/qwen3-14b",
			"name": "Qwen: Qwen3 14B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.06,
				"output": 0.24,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 40960
		},
		"qwen/qwen3-235b-a22b": {
			"id": "qwen/qwen3-235b-a22b",
			"name": "Qwen3-235B-A22B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.45499999999999996,
				"output": 1.8199999999999998,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"qwen/qwen3-235b-a22b-2507": {
			"id": "qwen/qwen3-235b-a22b-2507",
			"name": "Qwen: Qwen3 235B A22B Instruct 2507",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.071,
				"output": 0.09999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"qwen/qwen3-235b-a22b-thinking-2507": {
			"id": "qwen/qwen3-235b-a22b-thinking-2507",
			"name": "Qwen: Qwen3 235B A22B Thinking 2507",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"qwen/qwen3-30b-a3b": {
			"id": "qwen/qwen3-30b-a3b",
			"name": "Qwen: Qwen3 30B A3B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.08,
				"output": 0.28,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 40960
		},
		"qwen/qwen3-30b-a3b-instruct-2507": {
			"id": "qwen/qwen3-30b-a3b-instruct-2507",
			"name": "Qwen: Qwen3 30B A3B Instruct 2507",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"qwen/qwen3-30b-a3b-thinking-2507": {
			"id": "qwen/qwen3-30b-a3b-thinking-2507",
			"name": "Qwen: Qwen3 30B A3B Thinking 2507",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.051,
				"output": 0.33999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 8888
		},
		"qwen/qwen3-32b": {
			"id": "qwen/qwen3-32b",
			"name": "Qwen3 32B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.08,
				"output": 0.24,
				"cacheRead": 0.04,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"qwen/qwen3-4b": {
			"id": "qwen/qwen3-4b",
			"name": "Qwen: Qwen3 4B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.0715,
				"output": 0.273,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"qwen/qwen3-4b:free": {
			"id": "qwen/qwen3-4b:free",
			"name": "Qwen: Qwen3 4B (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 8888
		},
		"qwen/qwen3-8b": {
			"id": "qwen/qwen3-8b",
			"name": "Qwen: Qwen3 8B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.39999999999999997,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 8192
		},
		"qwen/qwen3-coder": {
			"id": "qwen/qwen3-coder",
			"name": "Qwen: Qwen3 Coder 480B A35B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.22,
				"output": 1,
				"cacheRead": 0.022,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder-30b-a3b-instruct": {
			"id": "qwen/qwen3-coder-30b-a3b-instruct",
			"name": "Qwen: Qwen3 Coder 30B A3B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.27,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 160000,
			"maxTokens": 32768
		},
		"qwen/qwen3-coder-flash": {
			"id": "qwen/qwen3-coder-flash",
			"name": "Qwen: Qwen3 Coder Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.5,
				"cacheRead": 0.06,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"qwen/qwen3-coder-next": {
			"id": "qwen/qwen3-coder-next",
			"name": "Qwen: Qwen3 Coder Next",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.12,
				"output": 0.75,
				"cacheRead": 0.06,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3-coder-plus": {
			"id": "qwen/qwen3-coder-plus",
			"name": "Qwen: Qwen3 Coder Plus",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"qwen/qwen3-coder:exacto": {
			"id": "qwen/qwen3-coder:exacto",
			"name": "Qwen: Qwen3 Coder 480B A35B (exacto)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.22,
				"output": 1.7999999999999998,
				"cacheRead": 0.022,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3-coder:free": {
			"id": "qwen/qwen3-coder:free",
			"name": "Qwen: Qwen3 Coder 480B A35B (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262000,
			"maxTokens": 262000
		},
		"qwen/qwen3-max": {
			"id": "qwen/qwen3-max",
			"name": "Qwen: Qwen3 Max",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.2,
				"output": 6,
				"cacheRead": 0.24,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32768
		},
		"qwen/qwen3-max-thinking": {
			"id": "qwen/qwen3-max-thinking",
			"name": "Qwen: Qwen3 Max Thinking",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32768
		},
		"qwen/qwen3-next-80b-a3b-instruct": {
			"id": "qwen/qwen3-next-80b-a3b-instruct",
			"name": "Qwen3-Next-80B-A3B-Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09,
				"output": 1.1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"qwen/qwen3-next-80b-a3b-instruct:free": {
			"id": "qwen/qwen3-next-80b-a3b-instruct:free",
			"name": "Qwen: Qwen3 Next 80B A3B Instruct (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"qwen/qwen3-next-80b-a3b-thinking": {
			"id": "qwen/qwen3-next-80b-a3b-thinking",
			"name": "Qwen3-Next-80B-A3B-Thinking",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"qwen/qwen3-vl-235b-a22b-instruct": {
			"id": "qwen/qwen3-vl-235b-a22b-instruct",
			"name": "Qwen: Qwen3 VL 235B A22B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.88,
				"cacheRead": 0.11,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-235b-a22b-thinking": {
			"id": "qwen/qwen3-vl-235b-a22b-thinking",
			"name": "Qwen: Qwen3 VL 235B A22B Thinking",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3-vl-30b-a3b-instruct": {
			"id": "qwen/qwen3-vl-30b-a3b-instruct",
			"name": "Qwen: Qwen3 VL 30B A3B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.13,
				"output": 0.52,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3-vl-30b-a3b-thinking": {
			"id": "qwen/qwen3-vl-30b-a3b-thinking",
			"name": "Qwen: Qwen3 VL 30B A3B Thinking",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3-vl-32b-instruct": {
			"id": "qwen/qwen3-vl-32b-instruct",
			"name": "Qwen: Qwen3 VL 32B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.10400000000000001,
				"output": 0.41600000000000004,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3-vl-8b-instruct": {
			"id": "qwen/qwen3-vl-8b-instruct",
			"name": "Qwen: Qwen3 VL 8B Instruct",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.08,
				"output": 0.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3-vl-8b-thinking": {
			"id": "qwen/qwen3-vl-8b-thinking",
			"name": "Qwen: Qwen3 VL 8B Thinking",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.117,
				"output": 1.365,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 32768
		},
		"qwen/qwen3.5-122b-a10b": {
			"id": "qwen/qwen3.5-122b-a10b",
			"name": "Qwen: Qwen3.5-122B-A10B",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 3.1999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3.5-27b": {
			"id": "qwen/qwen3.5-27b",
			"name": "Qwen: Qwen3.5-27B",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3.5-35b-a3b": {
			"id": "qwen/qwen3.5-35b-a3b",
			"name": "Qwen: Qwen3.5-35B-A3B",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3.5-397b-a17b": {
			"id": "qwen/qwen3.5-397b-a17b",
			"name": "Qwen: Qwen3.5 397B A17B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.55,
				"output": 3.5,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"qwen/qwen3.5-flash-02-23": {
			"id": "qwen/qwen3.5-flash-02-23",
			"name": "Qwen: Qwen3.5-Flash",
			"api": "openai-completions",
			"provider": "openrouter",
			"baseUrl": "https://openrouter.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"qwen/qwen3.5-plus-02-15": {
			"id": "qwen/qwen3.5-plus-02-15",
			"name": "Qwen: Qwen3.5 Plus 2026-02-15",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2.4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"qwen/qwq-32b": {
			"id": "qwen/qwq-32b",
			"name": "Qwen: QwQ 32B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"relace/relace-search": {
			"id": "relace/relace-search",
			"name": "Relace: Relace Search",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 128000
		},
		"sao10k/l3-euryale-70b": {
			"id": "sao10k/l3-euryale-70b",
			"name": "Sao10k: Llama 3 Euryale 70B v2.1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.48,
				"output": 1.48,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"sao10k/l3.1-euryale-70b": {
			"id": "sao10k/l3.1-euryale-70b",
			"name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.65,
				"output": 0.75,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"stepfun/step-3.5-flash": {
			"id": "stepfun/step-3.5-flash",
			"name": "StepFun: Step 3.5 Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0.02,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"stepfun/step-3.5-flash:free": {
			"id": "stepfun/step-3.5-flash:free",
			"name": "StepFun: Step 3.5 Flash (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000,
			"compat": {
				"supportsToolChoice": false
			}
		},
		"thedrummer/rocinante-12b": {
			"id": "thedrummer/rocinante-12b",
			"name": "TheDrummer: Rocinante 12B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.16999999999999998,
				"output": 0.43,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"thedrummer/unslopnemo-12b": {
			"id": "thedrummer/unslopnemo-12b",
			"name": "TheDrummer: UnslopNemo 12B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"tngtech/deepseek-r1t2-chimera": {
			"id": "tngtech/deepseek-r1t2-chimera",
			"name": "TNG: DeepSeek R1T2 Chimera",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 0.85,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 163840
		},
		"tngtech/tng-r1t-chimera": {
			"id": "tngtech/tng-r1t-chimera",
			"name": "TNG: R1T Chimera",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 0.85,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 65536
		},
		"upstage/solar-pro-3:free": {
			"id": "upstage/solar-pro-3:free",
			"name": "Upstage: Solar Pro 3 (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8888
		},
		"x-ai/grok-3": {
			"id": "x-ai/grok-3",
			"name": "xAI: Grok 3",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.75,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"x-ai/grok-3-beta": {
			"id": "x-ai/grok-3-beta",
			"name": "xAI: Grok 3 Beta",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.75,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"x-ai/grok-3-mini": {
			"id": "x-ai/grok-3-mini",
			"name": "xAI: Grok 3 Mini",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"x-ai/grok-3-mini-beta": {
			"id": "x-ai/grok-3-mini-beta",
			"name": "xAI: Grok 3 Mini Beta",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.5,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8888
		},
		"x-ai/grok-4": {
			"id": "x-ai/grok-4",
			"name": "xAI: Grok 4",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.75,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8888
		},
		"x-ai/grok-4-fast": {
			"id": "x-ai/grok-4-fast",
			"name": "xAI: Grok 4 Fast",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"x-ai/grok-4.1-fast": {
			"id": "x-ai/grok-4.1-fast",
			"name": "xAI: Grok 4.1 Fast",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"x-ai/grok-code-fast-1": {
			"id": "x-ai/grok-code-fast-1",
			"name": "xAI: Grok Code Fast 1",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 1.5,
				"cacheRead": 0.02,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 10000
		},
		"xiaomi/mimo-v2-flash": {
			"id": "xiaomi/mimo-v2-flash",
			"name": "Xiaomi: MiMo-V2-Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09,
				"output": 0.29,
				"cacheRead": 0.045,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"z-ai/glm-4-32b": {
			"id": "z-ai/glm-4-32b",
			"name": "Z.ai: GLM 4 32B",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.09999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8888
		},
		"z-ai/glm-4.5": {
			"id": "z-ai/glm-4.5",
			"name": "Z.ai: GLM 4.5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.55,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 131000
		},
		"z-ai/glm-4.5-air": {
			"id": "z-ai/glm-4.5-air",
			"name": "Z.ai: GLM 4.5 Air",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.13,
				"output": 0.85,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 98304
		},
		"z-ai/glm-4.5-air:free": {
			"id": "z-ai/glm-4.5-air:free",
			"name": "Z.ai: GLM 4.5 Air (free)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 96000
		},
		"z-ai/glm-4.5v": {
			"id": "z-ai/glm-4.5v",
			"name": "Z.ai: GLM 4.5V",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.6,
				"output": 1.7999999999999998,
				"cacheRead": 0.11,
				"cacheWrite": 0
			},
			"contextWindow": 65536,
			"maxTokens": 16384
		},
		"z-ai/glm-4.6": {
			"id": "z-ai/glm-4.6",
			"name": "Z.ai: GLM 4.6",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.35,
				"output": 1.71,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 131072
		},
		"z-ai/glm-4.6:exacto": {
			"id": "z-ai/glm-4.6:exacto",
			"name": "Z.ai: GLM 4.6 (exacto)",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.44,
				"output": 1.76,
				"cacheRead": 0.11,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"z-ai/glm-4.6v": {
			"id": "z-ai/glm-4.6v",
			"name": "Z.ai: GLM 4.6V",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 0.8999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"z-ai/glm-4.7": {
			"id": "z-ai/glm-4.7",
			"name": "Z.ai: GLM 4.7",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.4,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 8888
		},
		"z-ai/glm-4.7-flash": {
			"id": "z-ai/glm-4.7-flash",
			"name": "Z.ai: GLM 4.7 Flash",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.06,
				"output": 0.39999999999999997,
				"cacheRead": 0.0100000002,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 8888
		},
		"z-ai/glm-5": {
			"id": "z-ai/glm-5",
			"name": "Z.ai: GLM 5",
			"api": "openai-completions",
			"baseUrl": "https://openrouter.ai/api/v1",
			"provider": "openrouter",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.95,
				"output": 2.5500000000000003,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		}
	},
	"kilo": {
		"ai21/jamba-large-1.7": {
			"id": "ai21/jamba-large-1.7",
			"name": "AI21: Jamba Large 1.7",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-1.0": {
			"id": "aion-labs/aion-1.0",
			"name": "AionLabs: Aion-1.0",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-1.0-mini": {
			"id": "aion-labs/aion-1.0-mini",
			"name": "AionLabs: Aion-1.0-Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-2.0": {
			"id": "aion-labs/aion-2.0",
			"name": "AionLabs: Aion-2.0",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"aion-labs/aion-rp-llama-3.1-8b": {
			"id": "aion-labs/aion-rp-llama-3.1-8b",
			"name": "AionLabs: Aion-RP 1.0 (8B)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"alfredpros/codellama-7b-instruct-solidity": {
			"id": "alfredpros/codellama-7b-instruct-solidity",
			"name": "AlfredPros: CodeLLaMa 7B Instruct Solidity",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"alibaba/tongyi-deepresearch-30b-a3b": {
			"id": "alibaba/tongyi-deepresearch-30b-a3b",
			"name": "Tongyi DeepResearch 30B A3B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/molmo-2-8b": {
			"id": "allenai/molmo-2-8b",
			"name": "AllenAI: Molmo2 8B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-2-0325-32b-instruct": {
			"id": "allenai/olmo-2-0325-32b-instruct",
			"name": "AllenAI: Olmo 2 32B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3-32b-think": {
			"id": "allenai/olmo-3-32b-think",
			"name": "AllenAI: Olmo 3 32B Think",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3-7b-instruct": {
			"id": "allenai/olmo-3-7b-instruct",
			"name": "AllenAI: Olmo 3 7B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3-7b-think": {
			"id": "allenai/olmo-3-7b-think",
			"name": "AllenAI: Olmo 3 7B Think",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3.1-32b-instruct": {
			"id": "allenai/olmo-3.1-32b-instruct",
			"name": "AllenAI: Olmo 3.1 32B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"allenai/olmo-3.1-32b-think": {
			"id": "allenai/olmo-3.1-32b-think",
			"name": "AllenAI: Olmo 3.1 32B Think",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"alpindale/goliath-120b": {
			"id": "alpindale/goliath-120b",
			"name": "Goliath 120B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"amazon/nova-2-lite-v1": {
			"id": "amazon/nova-2-lite-v1",
			"name": "Amazon: Nova 2 Lite",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"amazon/nova-lite-v1": {
			"id": "amazon/nova-lite-v1",
			"name": "Amazon: Nova Lite 1.0",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"amazon/nova-micro-v1": {
			"id": "amazon/nova-micro-v1",
			"name": "Amazon: Nova Micro 1.0",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"amazon/nova-premier-v1": {
			"id": "amazon/nova-premier-v1",
			"name": "Amazon: Nova Premier 1.0",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"amazon/nova-pro-v1": {
			"id": "amazon/nova-pro-v1",
			"name": "Amazon: Nova Pro 1.0",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthracite-org/magnum-v4-72b": {
			"id": "anthracite-org/magnum-v4-72b",
			"name": "Magnum v4 72B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-3-haiku": {
			"id": "anthropic/claude-3-haiku",
			"name": "Claude Haiku 3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic/claude-3.5-haiku": {
			"id": "anthropic/claude-3.5-haiku",
			"name": "Claude Haiku 3.5 (latest)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.5-sonnet": {
			"id": "anthropic/claude-3.5-sonnet",
			"name": "Claude Sonnet 3.5 v2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.7-sonnet": {
			"id": "anthropic/claude-3.7-sonnet",
			"name": "Anthropic: Claude 3.7 Sonnet",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-3.7-sonnet:thinking": {
			"id": "anthropic/claude-3.7-sonnet:thinking",
			"name": "Anthropic: Claude 3.7 Sonnet (thinking)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-haiku-4.5": {
			"id": "anthropic/claude-haiku-4.5",
			"name": "Anthropic: Claude Haiku 4.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4": {
			"id": "anthropic/claude-opus-4",
			"name": "Claude Opus 4 (latest)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4.1": {
			"id": "anthropic/claude-opus-4.1",
			"name": "Anthropic: Claude Opus 4.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4.5": {
			"id": "anthropic/claude-opus-4.5",
			"name": "Anthropic: Claude Opus 4.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-opus-4.6": {
			"id": "anthropic/claude-opus-4.6",
			"name": "Anthropic: Claude Opus 4.6",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"anthropic/claude-sonnet-4": {
			"id": "anthropic/claude-sonnet-4",
			"name": "Claude Sonnet 4 (latest)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4.5": {
			"id": "anthropic/claude-sonnet-4.5",
			"name": "Anthropic: Claude Sonnet 4.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"anthropic/claude-sonnet-4.6": {
			"id": "anthropic/claude-sonnet-4.6",
			"name": "Anthropic: Claude Sonnet 4.6",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8888
		},
		"arcee-ai/coder-large": {
			"id": "arcee-ai/coder-large",
			"name": "Arcee AI: Coder Large",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"arcee-ai/maestro-reasoning": {
			"id": "arcee-ai/maestro-reasoning",
			"name": "Arcee AI: Maestro Reasoning",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"arcee-ai/spotlight": {
			"id": "arcee-ai/spotlight",
			"name": "Arcee AI: Spotlight",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"arcee-ai/trinity-large-preview:free": {
			"id": "arcee-ai/trinity-large-preview:free",
			"name": "Arcee AI: Trinity Large Preview (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"arcee-ai/trinity-mini": {
			"id": "arcee-ai/trinity-mini",
			"name": "Arcee AI: Trinity Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"arcee-ai/virtuoso-large": {
			"id": "arcee-ai/virtuoso-large",
			"name": "Arcee AI: Virtuoso Large",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-21b-a3b": {
			"id": "baidu/ernie-4.5-21b-a3b",
			"name": "Baidu: ERNIE 4.5 21B A3B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-21b-a3b-thinking": {
			"id": "baidu/ernie-4.5-21b-a3b-thinking",
			"name": "Baidu: ERNIE 4.5 21B A3B Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-300b-a47b": {
			"id": "baidu/ernie-4.5-300b-a47b",
			"name": "Baidu: ERNIE 4.5 300B A47B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-vl-28b-a3b": {
			"id": "baidu/ernie-4.5-vl-28b-a3b",
			"name": "Baidu: ERNIE 4.5 VL 28B A3B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"baidu/ernie-4.5-vl-424b-a47b": {
			"id": "baidu/ernie-4.5-vl-424b-a47b",
			"name": "Baidu: ERNIE 4.5 VL 424B A47B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"bytedance-seed/seed-1.6": {
			"id": "bytedance-seed/seed-1.6",
			"name": "ByteDance Seed: Seed 1.6",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"bytedance-seed/seed-1.6-flash": {
			"id": "bytedance-seed/seed-1.6-flash",
			"name": "ByteDance Seed: Seed 1.6 Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"bytedance-seed/seed-2.0-mini": {
			"id": "bytedance-seed/seed-2.0-mini",
			"name": "ByteDance Seed: Seed-2.0-Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"bytedance/ui-tars-1.5-7b": {
			"id": "bytedance/ui-tars-1.5-7b",
			"name": "ByteDance: UI-TARS 7B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cohere/command-a": {
			"id": "cohere/command-a",
			"name": "Cohere: Command A",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cohere/command-r-08-2024": {
			"id": "cohere/command-r-08-2024",
			"name": "Cohere: Command R (08-2024)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cohere/command-r-plus-08-2024": {
			"id": "cohere/command-r-plus-08-2024",
			"name": "Cohere: Command R+ (08-2024)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"cohere/command-r7b-12-2024": {
			"id": "cohere/command-r7b-12-2024",
			"name": "Cohere: Command R7B (12-2024)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"corethink:free": {
			"id": "corethink:free",
			"name": "CoreThink (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepcogito/cogito-v2.1-671b": {
			"id": "deepcogito/cogito-v2.1-671b",
			"name": "Deep Cogito: Cogito v2.1 671B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-chat": {
			"id": "deepseek/deepseek-chat",
			"name": "DeepSeek: DeepSeek V3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-chat-v3-0324": {
			"id": "deepseek/deepseek-chat-v3-0324",
			"name": "DeepSeek: DeepSeek V3 0324",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-chat-v3.1": {
			"id": "deepseek/deepseek-chat-v3.1",
			"name": "DeepSeek: DeepSeek V3.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-r1": {
			"id": "deepseek/deepseek-r1",
			"name": "DeepSeek: R1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-r1-0528": {
			"id": "deepseek/deepseek-r1-0528",
			"name": "DeepSeek: R1 0528",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-r1-distill-llama-70b": {
			"id": "deepseek/deepseek-r1-distill-llama-70b",
			"name": "DeepSeek: R1 Distill Llama 70B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-r1-distill-qwen-32b": {
			"id": "deepseek/deepseek-r1-distill-qwen-32b",
			"name": "DeepSeek: R1 Distill Qwen 32B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.1-terminus": {
			"id": "deepseek/deepseek-v3.1-terminus",
			"name": "DeepSeek: DeepSeek V3.1 Terminus",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.1-terminus:exacto": {
			"id": "deepseek/deepseek-v3.1-terminus:exacto",
			"name": "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2": {
			"id": "deepseek/deepseek-v3.2",
			"name": "DeepSeek: DeepSeek V3.2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2-exp": {
			"id": "deepseek/deepseek-v3.2-exp",
			"name": "DeepSeek: DeepSeek V3.2 Exp",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"deepseek/deepseek-v3.2-speciale": {
			"id": "deepseek/deepseek-v3.2-speciale",
			"name": "DeepSeek: DeepSeek V3.2 Speciale",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"eleutherai/llemma_7b": {
			"id": "eleutherai/llemma_7b",
			"name": "EleutherAI: Llemma 7b",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"essentialai/rnj-1-instruct": {
			"id": "essentialai/rnj-1-instruct",
			"name": "EssentialAI: Rnj 1 Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"giga-potato": {
			"id": "giga-potato",
			"name": "Giga Potato (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"giga-potato-thinking": {
			"id": "giga-potato-thinking",
			"name": "Giga Potato Thinking (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.0-flash-001": {
			"id": "google/gemini-2.0-flash-001",
			"name": "Google: Gemini 2.0 Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.0-flash-lite-001": {
			"id": "google/gemini-2.0-flash-lite-001",
			"name": "Google: Gemini 2.0 Flash Lite",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-flash": {
			"id": "google/gemini-2.5-flash",
			"name": "Google: Gemini 2.5 Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-flash-image": {
			"id": "google/gemini-2.5-flash-image",
			"name": "Google: Nano Banana (Gemini 2.5 Flash Image)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-flash-lite": {
			"id": "google/gemini-2.5-flash-lite",
			"name": "Google: Gemini 2.5 Flash Lite",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-flash-lite-preview-09-2025": {
			"id": "google/gemini-2.5-flash-lite-preview-09-2025",
			"name": "Google: Gemini 2.5 Flash Lite Preview 09-2025",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-pro": {
			"id": "google/gemini-2.5-pro",
			"name": "Google: Gemini 2.5 Pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-pro-preview": {
			"id": "google/gemini-2.5-pro-preview",
			"name": "Google: Gemini 2.5 Pro Preview 06-05",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-2.5-pro-preview-05-06": {
			"id": "google/gemini-2.5-pro-preview-05-06",
			"name": "Google: Gemini 2.5 Pro Preview 05-06",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3-flash-preview": {
			"id": "google/gemini-3-flash-preview",
			"name": "Google: Gemini 3 Flash Preview",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3-pro-image-preview": {
			"id": "google/gemini-3-pro-image-preview",
			"name": "Google: Nano Banana Pro (Gemini 3 Pro Image Preview)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3-pro-preview": {
			"id": "google/gemini-3-pro-preview",
			"name": "Google: Gemini 3 Pro Preview",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3.1-flash-image-preview": {
			"id": "google/gemini-3.1-flash-image-preview",
			"name": "Google: Nano Banana 2 (Gemini 3.1 Flash Image Preview)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3.1-pro-preview": {
			"id": "google/gemini-3.1-pro-preview",
			"name": "Google: Gemini 3.1 Pro Preview",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemini-3.1-pro-preview-customtools": {
			"id": "google/gemini-3.1-pro-preview-customtools",
			"name": "Google: Gemini 3.1 Pro Preview Custom Tools",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemma-2-27b-it": {
			"id": "google/gemma-2-27b-it",
			"name": "Gemma 2 27b It",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-2-9b-it": {
			"id": "google/gemma-2-9b-it",
			"name": "Google: Gemma 2 9B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemma-3-12b-it": {
			"id": "google/gemma-3-12b-it",
			"name": "Gemma 3 12b It",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"google/gemma-3-27b-it": {
			"id": "google/gemma-3-27b-it",
			"name": "Gemma-3-27B-IT",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"google/gemma-3-4b-it": {
			"id": "google/gemma-3-4b-it",
			"name": "Google: Gemma 3 4B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"google/gemma-3n-e4b-it": {
			"id": "google/gemma-3n-e4b-it",
			"name": "Gemma 3n E4b It",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"gryphe/mythomax-l2-13b": {
			"id": "gryphe/mythomax-l2-13b",
			"name": "MythoMax 13B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"ibm-granite/granite-4.0-h-micro": {
			"id": "ibm-granite/granite-4.0-h-micro",
			"name": "IBM: Granite 4.0 Micro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inception/mercury": {
			"id": "inception/mercury",
			"name": "Inception: Mercury",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inception/mercury-coder": {
			"id": "inception/mercury-coder",
			"name": "Inception: Mercury Coder",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inflection/inflection-3-pi": {
			"id": "inflection/inflection-3-pi",
			"name": "Inflection: Inflection 3 Pi",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"inflection/inflection-3-productivity": {
			"id": "inflection/inflection-3-productivity",
			"name": "Inflection: Inflection 3 Productivity",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"kilo/auto": {
			"id": "kilo/auto",
			"name": "Kilo: Auto",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"kilo/auto-free": {
			"id": "kilo/auto-free",
			"name": "Kilo: Auto Free",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"kilo/auto-small": {
			"id": "kilo/auto-small",
			"name": "Kilo: Auto Small",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"kwaipilot/kat-coder-pro": {
			"id": "kwaipilot/kat-coder-pro",
			"name": "Kwaipilot: KAT-Coder-Pro V1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"liquid/lfm-2-24b-a2b": {
			"id": "liquid/lfm-2-24b-a2b",
			"name": "LiquidAI: LFM2-24B-A2B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"liquid/lfm-2.2-6b": {
			"id": "liquid/lfm-2.2-6b",
			"name": "LiquidAI: LFM2-2.6B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"liquid/lfm2-8b-a1b": {
			"id": "liquid/lfm2-8b-a1b",
			"name": "LiquidAI: LFM2-8B-A1B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mancer/weaver": {
			"id": "mancer/weaver",
			"name": "Mancer: Weaver (alpha)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meituan/longcat-flash-chat": {
			"id": "meituan/longcat-flash-chat",
			"name": "Meituan: LongCat Flash Chat",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3-70b-instruct": {
			"id": "meta-llama/llama-3-70b-instruct",
			"name": "Meta: Llama 3 70B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3-8b-instruct": {
			"id": "meta-llama/llama-3-8b-instruct",
			"name": "Meta: Llama 3 8B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-405b": {
			"id": "meta-llama/llama-3.1-405b",
			"name": "Meta: Llama 3.1 405B (base)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-405b-instruct": {
			"id": "meta-llama/llama-3.1-405b-instruct",
			"name": "Meta: Llama 3.1 405B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-70b-instruct": {
			"id": "meta-llama/llama-3.1-70b-instruct",
			"name": "Meta: Llama 3.1 70B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.1-8b-instruct": {
			"id": "meta-llama/llama-3.1-8b-instruct",
			"name": "Meta: Llama 3.1 8B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.2-11b-vision-instruct": {
			"id": "meta-llama/llama-3.2-11b-vision-instruct",
			"name": "Meta: Llama 3.2 11B Vision Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.2-1b-instruct": {
			"id": "meta-llama/llama-3.2-1b-instruct",
			"name": "Meta: Llama 3.2 1B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.2-3b-instruct": {
			"id": "meta-llama/llama-3.2-3b-instruct",
			"name": "Meta: Llama 3.2 3B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-3.3-70b-instruct": {
			"id": "meta-llama/llama-3.3-70b-instruct",
			"name": "Meta: Llama 3.3 70B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-4-maverick": {
			"id": "meta-llama/llama-4-maverick",
			"name": "Meta: Llama 4 Maverick",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-4-scout": {
			"id": "meta-llama/llama-4-scout",
			"name": "Meta: Llama 4 Scout",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-guard-2-8b": {
			"id": "meta-llama/llama-guard-2-8b",
			"name": "Meta: LlamaGuard 2 8B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-guard-3-8b": {
			"id": "meta-llama/llama-guard-3-8b",
			"name": "Llama Guard 3 8B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"meta-llama/llama-guard-4-12b": {
			"id": "meta-llama/llama-guard-4-12b",
			"name": "Meta: Llama Guard 4 12B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"microsoft/phi-4": {
			"id": "microsoft/phi-4",
			"name": "Microsoft: Phi 4",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"microsoft/wizardlm-2-8x22b": {
			"id": "microsoft/wizardlm-2-8x22b",
			"name": "WizardLM-2 8x22B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-01": {
			"id": "minimax/minimax-01",
			"name": "MiniMax: MiniMax-01",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m1": {
			"id": "minimax/minimax-m1",
			"name": "MiniMax: MiniMax M1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2": {
			"id": "minimax/minimax-m2",
			"name": "MiniMax: MiniMax M2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2-her": {
			"id": "minimax/minimax-m2-her",
			"name": "MiniMax: MiniMax M2-her",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2.1": {
			"id": "minimax/minimax-m2.1",
			"name": "MiniMax: MiniMax M2.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2.5": {
			"id": "minimax/minimax-m2.5",
			"name": "MiniMax: MiniMax M2.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"minimax/minimax-m2.5:free": {
			"id": "minimax/minimax-m2.5:free",
			"name": "MiniMax: MiniMax M2.5 (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/codestral-2508": {
			"id": "mistralai/codestral-2508",
			"name": "Mistral: Codestral 2508",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/devstral-2512": {
			"id": "mistralai/devstral-2512",
			"name": "Mistral: Devstral 2 2512",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/devstral-medium": {
			"id": "mistralai/devstral-medium",
			"name": "Mistral: Devstral Medium",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/devstral-small": {
			"id": "mistralai/devstral-small",
			"name": "Mistral: Devstral Small 1.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/ministral-14b-2512": {
			"id": "mistralai/ministral-14b-2512",
			"name": "Mistral: Ministral 3 14B 2512",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/ministral-3b-2512": {
			"id": "mistralai/ministral-3b-2512",
			"name": "Mistral: Ministral 3 3B 2512",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/ministral-8b-2512": {
			"id": "mistralai/ministral-8b-2512",
			"name": "Mistral: Ministral 3 8B 2512",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-7b-instruct": {
			"id": "mistralai/mistral-7b-instruct",
			"name": "Mistral: Mistral 7B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-7b-instruct-v0.1": {
			"id": "mistralai/mistral-7b-instruct-v0.1",
			"name": "Mistral: Mistral 7B Instruct v0.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-7b-instruct-v0.3": {
			"id": "mistralai/mistral-7b-instruct-v0.3",
			"name": "Mistral: Mistral 7B Instruct v0.3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-large": {
			"id": "mistralai/mistral-large",
			"name": "Mistral Large",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-2407": {
			"id": "mistralai/mistral-large-2407",
			"name": "Mistral Large 2407",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-2411": {
			"id": "mistralai/mistral-large-2411",
			"name": "Mistral Large 2411",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-large-2512": {
			"id": "mistralai/mistral-large-2512",
			"name": "Mistral: Mistral Large 3 2512",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-medium-3": {
			"id": "mistralai/mistral-medium-3",
			"name": "Mistral: Mistral Medium 3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-medium-3.1": {
			"id": "mistralai/mistral-medium-3.1",
			"name": "Mistral: Mistral Medium 3.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-nemo": {
			"id": "mistralai/mistral-nemo",
			"name": "Mistral: Mistral Nemo",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-saba": {
			"id": "mistralai/mistral-saba",
			"name": "Mistral: Saba",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-24b-instruct-2501": {
			"id": "mistralai/mistral-small-24b-instruct-2501",
			"name": "Mistral: Mistral Small 3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-3.1-24b-instruct": {
			"id": "mistralai/mistral-small-3.1-24b-instruct",
			"name": "Mistral: Mistral Small 3.1 24B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-3.2-24b-instruct": {
			"id": "mistralai/mistral-small-3.2-24b-instruct",
			"name": "Mistral: Mistral Small 3.2 24B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mistral-small-creative": {
			"id": "mistralai/mistral-small-creative",
			"name": "Mistral: Mistral Small Creative",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mixtral-8x22b-instruct": {
			"id": "mistralai/mixtral-8x22b-instruct",
			"name": "Mistral: Mixtral 8x22B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/mixtral-8x7b-instruct": {
			"id": "mistralai/mixtral-8x7b-instruct",
			"name": "Mistral: Mixtral 8x7B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/pixtral-large-2411": {
			"id": "mistralai/pixtral-large-2411",
			"name": "Mistral: Pixtral Large 2411",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"mistralai/voxtral-small-24b-2507": {
			"id": "mistralai/voxtral-small-24b-2507",
			"name": "Mistral: Voxtral Small 24B 2507",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2": {
			"id": "moonshotai/kimi-k2",
			"name": "MoonshotAI: Kimi K2 0711",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-0905": {
			"id": "moonshotai/kimi-k2-0905",
			"name": "MoonshotAI: Kimi K2 0905",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-0905:exacto": {
			"id": "moonshotai/kimi-k2-0905:exacto",
			"name": "MoonshotAI: Kimi K2 0905 (exacto)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"moonshotai/kimi-k2-thinking": {
			"id": "moonshotai/kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2.5": {
			"id": "moonshotai/kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2.5:free": {
			"id": "moonshotai/kimi-k2.5:free",
			"name": "MoonshotAI: Kimi K2.5 (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"morph/morph-v3-fast": {
			"id": "morph/morph-v3-fast",
			"name": "Morph: Morph V3 Fast",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"morph/morph-v3-large": {
			"id": "morph/morph-v3-large",
			"name": "Morph: Morph V3 Large",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"neversleep/llama-3.1-lumimaid-8b": {
			"id": "neversleep/llama-3.1-lumimaid-8b",
			"name": "NeverSleep: Lumimaid v0.2 8B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"neversleep/noromaid-20b": {
			"id": "neversleep/noromaid-20b",
			"name": "Noromaid 20B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nex-agi/deepseek-v3.1-nex-n1": {
			"id": "nex-agi/deepseek-v3.1-nex-n1",
			"name": "Nex AGI: DeepSeek V3.1 Nex N1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-2-pro-llama-3-8b": {
			"id": "nousresearch/hermes-2-pro-llama-3-8b",
			"name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-3-llama-3.1-405b": {
			"id": "nousresearch/hermes-3-llama-3.1-405b",
			"name": "Nous: Hermes 3 405B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-3-llama-3.1-70b": {
			"id": "nousresearch/hermes-3-llama-3.1-70b",
			"name": "Nous: Hermes 3 70B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-4-405b": {
			"id": "nousresearch/hermes-4-405b",
			"name": "Nous: Hermes 4 405B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nousresearch/hermes-4-70b": {
			"id": "nousresearch/hermes-4-70b",
			"name": "Nous: Hermes 4 70B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/llama-3.1-nemotron-70b-instruct": {
			"id": "nvidia/llama-3.1-nemotron-70b-instruct",
			"name": "Llama 3.1 Nemotron 70b Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"nvidia/llama-3.3-nemotron-super-49b-v1.5": {
			"id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
			"name": "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/nemotron-3-nano-30b-a3b": {
			"id": "nvidia/nemotron-3-nano-30b-a3b",
			"name": "nemotron-3-nano-30b-a3b",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"nvidia/nemotron-nano-12b-v2-vl": {
			"id": "nvidia/nemotron-nano-12b-v2-vl",
			"name": "NVIDIA: Nemotron Nano 12B 2 VL",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"nvidia/nemotron-nano-9b-v2": {
			"id": "nvidia/nemotron-nano-9b-v2",
			"name": "NVIDIA: Nemotron Nano 9B V2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-3.5-turbo": {
			"id": "openai/gpt-3.5-turbo",
			"name": "OpenAI: GPT-3.5 Turbo",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-3.5-turbo-0613": {
			"id": "openai/gpt-3.5-turbo-0613",
			"name": "OpenAI: GPT-3.5 Turbo (older v0613)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-3.5-turbo-16k": {
			"id": "openai/gpt-3.5-turbo-16k",
			"name": "OpenAI: GPT-3.5 Turbo 16k",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-3.5-turbo-instruct": {
			"id": "openai/gpt-3.5-turbo-instruct",
			"name": "OpenAI: GPT-3.5 Turbo Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4": {
			"id": "openai/gpt-4",
			"name": "GPT-4",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 8192,
			"maxTokens": 8192
		},
		"openai/gpt-4-0314": {
			"id": "openai/gpt-4-0314",
			"name": "OpenAI: GPT-4 (older v0314)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4-1106-preview": {
			"id": "openai/gpt-4-1106-preview",
			"name": "OpenAI: GPT-4 Turbo (older v1106)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4-turbo": {
			"id": "openai/gpt-4-turbo",
			"name": "GPT-4 Turbo",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4-turbo-preview": {
			"id": "openai/gpt-4-turbo-preview",
			"name": "OpenAI: GPT-4 Turbo Preview",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4.1": {
			"id": "openai/gpt-4.1",
			"name": "OpenAI: GPT-4.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4.1-mini": {
			"id": "openai/gpt-4.1-mini",
			"name": "OpenAI: GPT-4.1 Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4.1-nano": {
			"id": "openai/gpt-4.1-nano",
			"name": "OpenAI: GPT-4.1 Nano",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o": {
			"id": "openai/gpt-4o",
			"name": "GPT-4o",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-2024-05-13": {
			"id": "openai/gpt-4o-2024-05-13",
			"name": "OpenAI: GPT-4o (2024-05-13)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-2024-08-06": {
			"id": "openai/gpt-4o-2024-08-06",
			"name": "OpenAI: GPT-4o (2024-08-06)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-2024-11-20": {
			"id": "openai/gpt-4o-2024-11-20",
			"name": "OpenAI: GPT-4o (2024-11-20)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-audio-preview": {
			"id": "openai/gpt-4o-audio-preview",
			"name": "OpenAI: GPT-4o Audio",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-mini": {
			"id": "openai/gpt-4o-mini",
			"name": "GPT-4o mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-mini-2024-07-18": {
			"id": "openai/gpt-4o-mini-2024-07-18",
			"name": "OpenAI: GPT-4o-mini (2024-07-18)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-mini-search-preview": {
			"id": "openai/gpt-4o-mini-search-preview",
			"name": "OpenAI: GPT-4o-mini Search Preview",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o-search-preview": {
			"id": "openai/gpt-4o-search-preview",
			"name": "OpenAI: GPT-4o Search Preview",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-4o:extended": {
			"id": "openai/gpt-4o:extended",
			"name": "OpenAI: GPT-4o (extended)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5": {
			"id": "openai/gpt-5",
			"name": "OpenAI: GPT-5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-chat": {
			"id": "openai/gpt-5-chat",
			"name": "OpenAI: GPT-5 Chat",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-codex": {
			"id": "openai/gpt-5-codex",
			"name": "OpenAI: GPT-5 Codex",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 8888
		},
		"openai/gpt-5-image": {
			"id": "openai/gpt-5-image",
			"name": "OpenAI: GPT-5 Image",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-image-mini": {
			"id": "openai/gpt-5-image-mini",
			"name": "OpenAI: GPT-5 Image Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-mini": {
			"id": "openai/gpt-5-mini",
			"name": "OpenAI: GPT-5 Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-nano": {
			"id": "openai/gpt-5-nano",
			"name": "OpenAI: GPT-5 Nano",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5-pro": {
			"id": "openai/gpt-5-pro",
			"name": "OpenAI: GPT-5 Pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.1": {
			"id": "openai/gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-chat": {
			"id": "openai/gpt-5.1-chat",
			"name": "OpenAI: GPT-5.1 Chat",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.1-codex": {
			"id": "openai/gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-max": {
			"id": "openai/gpt-5.1-codex-max",
			"name": "OpenAI: GPT-5.1-Codex-Max",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 8888
		},
		"openai/gpt-5.1-codex-mini": {
			"id": "openai/gpt-5.1-codex-mini",
			"name": "OpenAI: GPT-5.1-Codex-Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 8888
		},
		"openai/gpt-5.2": {
			"id": "openai/gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-chat": {
			"id": "openai/gpt-5.2-chat",
			"name": "OpenAI: GPT-5.2 Chat",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.2-codex": {
			"id": "openai/gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-pro": {
			"id": "openai/gpt-5.2-pro",
			"name": "OpenAI: GPT-5.2 Pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-5.3-codex": {
			"id": "openai/gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-audio": {
			"id": "openai/gpt-audio",
			"name": "OpenAI: GPT Audio",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-audio-mini": {
			"id": "openai/gpt-audio-mini",
			"name": "OpenAI: GPT Audio Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-oss-120b": {
			"id": "openai/gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-120b:exacto": {
			"id": "openai/gpt-oss-120b:exacto",
			"name": "OpenAI: gpt-oss-120b (exacto)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/gpt-oss-20b": {
			"id": "openai/gpt-oss-20b",
			"name": "GPT OSS 20B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-safeguard-20b": {
			"id": "openai/gpt-oss-safeguard-20b",
			"name": "OpenAI: gpt-oss-safeguard-20b",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o1": {
			"id": "openai/o1",
			"name": "o1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o1-pro": {
			"id": "openai/o1-pro",
			"name": "OpenAI: o1-pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3": {
			"id": "openai/o3",
			"name": "o3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-deep-research": {
			"id": "openai/o3-deep-research",
			"name": "OpenAI: o3 Deep Research",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3-mini": {
			"id": "openai/o3-mini",
			"name": "o3-mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-mini-high": {
			"id": "openai/o3-mini-high",
			"name": "OpenAI: o3 Mini High",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o3-pro": {
			"id": "openai/o3-pro",
			"name": "o3-pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini": {
			"id": "openai/o4-mini",
			"name": "o4-mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini-deep-research": {
			"id": "openai/o4-mini-deep-research",
			"name": "OpenAI: o4 Mini Deep Research",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openai/o4-mini-high": {
			"id": "openai/o4-mini-high",
			"name": "OpenAI: o4 Mini High",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"opengvlab/internvl3-78b": {
			"id": "opengvlab/internvl3-78b",
			"name": "OpenGVLab: InternVL3 78B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openrouter/auto": {
			"id": "openrouter/auto",
			"name": "Auto Router",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openrouter/bodybuilder": {
			"id": "openrouter/bodybuilder",
			"name": "Body Builder (beta)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"openrouter/free": {
			"id": "openrouter/free",
			"name": "Free Models Router (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"perplexity/sonar": {
			"id": "perplexity/sonar",
			"name": "Perplexity: Sonar",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"perplexity/sonar-deep-research": {
			"id": "perplexity/sonar-deep-research",
			"name": "Perplexity: Sonar Deep Research",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"perplexity/sonar-pro": {
			"id": "perplexity/sonar-pro",
			"name": "Perplexity: Sonar Pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"perplexity/sonar-pro-search": {
			"id": "perplexity/sonar-pro-search",
			"name": "Perplexity: Sonar Pro Search",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"perplexity/sonar-reasoning-pro": {
			"id": "perplexity/sonar-reasoning-pro",
			"name": "Perplexity: Sonar Reasoning Pro",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"prime-intellect/intellect-3": {
			"id": "prime-intellect/intellect-3",
			"name": "Prime Intellect: INTELLECT-3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-2.5-72b-instruct": {
			"id": "qwen/qwen-2.5-72b-instruct",
			"name": "Qwen2.5 72B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-2.5-7b-instruct": {
			"id": "qwen/qwen-2.5-7b-instruct",
			"name": "Qwen: Qwen2.5 7B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-2.5-coder-32b-instruct": {
			"id": "qwen/qwen-2.5-coder-32b-instruct",
			"name": "Qwen2.5 Coder 32B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-2.5-vl-7b-instruct": {
			"id": "qwen/qwen-2.5-vl-7b-instruct",
			"name": "Qwen: Qwen2.5-VL 7B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-max": {
			"id": "qwen/qwen-max",
			"name": "Qwen: Qwen-Max",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-plus": {
			"id": "qwen/qwen-plus",
			"name": "Qwen: Qwen-Plus",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-plus-2025-07-28": {
			"id": "qwen/qwen-plus-2025-07-28",
			"name": "Qwen: Qwen Plus 0728",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-plus-2025-07-28:thinking": {
			"id": "qwen/qwen-plus-2025-07-28:thinking",
			"name": "Qwen: Qwen Plus 0728 (thinking)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-turbo": {
			"id": "qwen/qwen-turbo",
			"name": "Qwen: Qwen-Turbo",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-vl-max": {
			"id": "qwen/qwen-vl-max",
			"name": "Qwen: Qwen VL Max",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen-vl-plus": {
			"id": "qwen/qwen-vl-plus",
			"name": "Qwen: Qwen VL Plus",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen2.5-coder-7b-instruct": {
			"id": "qwen/qwen2.5-coder-7b-instruct",
			"name": "Qwen2.5 Coder 7b Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"qwen/qwen2.5-vl-32b-instruct": {
			"id": "qwen/qwen2.5-vl-32b-instruct",
			"name": "Qwen: Qwen2.5 VL 32B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen2.5-vl-72b-instruct": {
			"id": "qwen/qwen2.5-vl-72b-instruct",
			"name": "Qwen: Qwen2.5 VL 72B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-14b": {
			"id": "qwen/qwen3-14b",
			"name": "Qwen: Qwen3 14B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-235b-a22b": {
			"id": "qwen/qwen3-235b-a22b",
			"name": "Qwen3-235B-A22B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"qwen/qwen3-235b-a22b-2507": {
			"id": "qwen/qwen3-235b-a22b-2507",
			"name": "Qwen: Qwen3 235B A22B Instruct 2507",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-235b-a22b-thinking-2507": {
			"id": "qwen/qwen3-235b-a22b-thinking-2507",
			"name": "Qwen: Qwen3 235B A22B Thinking 2507",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-30b-a3b": {
			"id": "qwen/qwen3-30b-a3b",
			"name": "Qwen: Qwen3 30B A3B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-30b-a3b-instruct-2507": {
			"id": "qwen/qwen3-30b-a3b-instruct-2507",
			"name": "Qwen: Qwen3 30B A3B Instruct 2507",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-30b-a3b-thinking-2507": {
			"id": "qwen/qwen3-30b-a3b-thinking-2507",
			"name": "Qwen: Qwen3 30B A3B Thinking 2507",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-32b": {
			"id": "qwen/qwen3-32b",
			"name": "Qwen3 32B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"qwen/qwen3-8b": {
			"id": "qwen/qwen3-8b",
			"name": "Qwen: Qwen3 8B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder": {
			"id": "qwen/qwen3-coder",
			"name": "Qwen: Qwen3 Coder 480B A35B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder-30b-a3b-instruct": {
			"id": "qwen/qwen3-coder-30b-a3b-instruct",
			"name": "Qwen: Qwen3 Coder 30B A3B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder-flash": {
			"id": "qwen/qwen3-coder-flash",
			"name": "Qwen: Qwen3 Coder Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder-next": {
			"id": "qwen/qwen3-coder-next",
			"name": "Qwen: Qwen3 Coder Next",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder-plus": {
			"id": "qwen/qwen3-coder-plus",
			"name": "Qwen: Qwen3 Coder Plus",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-coder:exacto": {
			"id": "qwen/qwen3-coder:exacto",
			"name": "Qwen: Qwen3 Coder 480B A35B (exacto)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-max": {
			"id": "qwen/qwen3-max",
			"name": "Qwen: Qwen3 Max",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-max-thinking": {
			"id": "qwen/qwen3-max-thinking",
			"name": "Qwen: Qwen3 Max Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-next-80b-a3b-instruct": {
			"id": "qwen/qwen3-next-80b-a3b-instruct",
			"name": "Qwen3-Next-80B-A3B-Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"qwen/qwen3-next-80b-a3b-thinking": {
			"id": "qwen/qwen3-next-80b-a3b-thinking",
			"name": "Qwen3-Next-80B-A3B-Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 16384
		},
		"qwen/qwen3-vl-235b-a22b-instruct": {
			"id": "qwen/qwen3-vl-235b-a22b-instruct",
			"name": "Qwen: Qwen3 VL 235B A22B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-235b-a22b-thinking": {
			"id": "qwen/qwen3-vl-235b-a22b-thinking",
			"name": "Qwen: Qwen3 VL 235B A22B Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-30b-a3b-instruct": {
			"id": "qwen/qwen3-vl-30b-a3b-instruct",
			"name": "Qwen: Qwen3 VL 30B A3B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-30b-a3b-thinking": {
			"id": "qwen/qwen3-vl-30b-a3b-thinking",
			"name": "Qwen: Qwen3 VL 30B A3B Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-32b-instruct": {
			"id": "qwen/qwen3-vl-32b-instruct",
			"name": "Qwen: Qwen3 VL 32B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-8b-instruct": {
			"id": "qwen/qwen3-vl-8b-instruct",
			"name": "Qwen: Qwen3 VL 8B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3-vl-8b-thinking": {
			"id": "qwen/qwen3-vl-8b-thinking",
			"name": "Qwen: Qwen3 VL 8B Thinking",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-122b-a10b": {
			"id": "qwen/qwen3.5-122b-a10b",
			"name": "Qwen: Qwen3.5-122B-A10B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-27b": {
			"id": "qwen/qwen3.5-27b",
			"name": "Qwen: Qwen3.5-27B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-35b-a3b": {
			"id": "qwen/qwen3.5-35b-a3b",
			"name": "Qwen: Qwen3.5-35B-A3B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-397b-a17b": {
			"id": "qwen/qwen3.5-397b-a17b",
			"name": "Qwen: Qwen3.5 397B A17B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-flash-02-23": {
			"id": "qwen/qwen3.5-flash-02-23",
			"name": "Qwen: Qwen3.5-Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwen3.5-plus-02-15": {
			"id": "qwen/qwen3.5-plus-02-15",
			"name": "Qwen: Qwen3.5 Plus 2026-02-15",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"qwen/qwq-32b": {
			"id": "qwen/qwq-32b",
			"name": "Qwen: QwQ 32B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"raifle/sorcererlm-8x22b": {
			"id": "raifle/sorcererlm-8x22b",
			"name": "SorcererLM 8x22B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"relace/relace-apply-3": {
			"id": "relace/relace-apply-3",
			"name": "Relace: Relace Apply 3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"relace/relace-search": {
			"id": "relace/relace-search",
			"name": "Relace: Relace Search",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sao10k/l3-euryale-70b": {
			"id": "sao10k/l3-euryale-70b",
			"name": "Sao10k: Llama 3 Euryale 70B v2.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sao10k/l3-lunaris-8b": {
			"id": "sao10k/l3-lunaris-8b",
			"name": "Sao10K: Llama 3 8B Lunaris",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sao10k/l3.1-70b-hanami-x1": {
			"id": "sao10k/l3.1-70b-hanami-x1",
			"name": "Sao10K: Llama 3.1 70B Hanami x1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sao10k/l3.1-euryale-70b": {
			"id": "sao10k/l3.1-euryale-70b",
			"name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"sao10k/l3.3-euryale-70b": {
			"id": "sao10k/l3.3-euryale-70b",
			"name": "Sao10K: Llama 3.3 Euryale 70B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"stepfun/step-3.5-flash": {
			"id": "stepfun/step-3.5-flash",
			"name": "StepFun: Step 3.5 Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"stepfun/step-3.5-flash:free": {
			"id": "stepfun/step-3.5-flash:free",
			"name": "StepFun: Step 3.5 Flash (free)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"switchpoint/router": {
			"id": "switchpoint/router",
			"name": "Switchpoint Router",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"tencent/hunyuan-a13b-instruct": {
			"id": "tencent/hunyuan-a13b-instruct",
			"name": "Tencent: Hunyuan A13B Instruct",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"thedrummer/cydonia-24b-v4.1": {
			"id": "thedrummer/cydonia-24b-v4.1",
			"name": "TheDrummer: Cydonia 24B V4.1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"thedrummer/rocinante-12b": {
			"id": "thedrummer/rocinante-12b",
			"name": "TheDrummer: Rocinante 12B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"thedrummer/skyfall-36b-v2": {
			"id": "thedrummer/skyfall-36b-v2",
			"name": "TheDrummer: Skyfall 36B V2",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"thedrummer/unslopnemo-12b": {
			"id": "thedrummer/unslopnemo-12b",
			"name": "TheDrummer: UnslopNemo 12B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"tngtech/deepseek-r1t2-chimera": {
			"id": "tngtech/deepseek-r1t2-chimera",
			"name": "TNG: DeepSeek R1T2 Chimera",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"undi95/remm-slerp-l2-13b": {
			"id": "undi95/remm-slerp-l2-13b",
			"name": "ReMM SLERP 13B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"writer/palmyra-x5": {
			"id": "writer/palmyra-x5",
			"name": "Writer: Palmyra X5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-3": {
			"id": "x-ai/grok-3",
			"name": "xAI: Grok 3",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-3-beta": {
			"id": "x-ai/grok-3-beta",
			"name": "xAI: Grok 3 Beta",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-3-mini": {
			"id": "x-ai/grok-3-mini",
			"name": "xAI: Grok 3 Mini",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-3-mini-beta": {
			"id": "x-ai/grok-3-mini-beta",
			"name": "xAI: Grok 3 Mini Beta",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-4": {
			"id": "x-ai/grok-4",
			"name": "xAI: Grok 4",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-4-fast": {
			"id": "x-ai/grok-4-fast",
			"name": "xAI: Grok 4 Fast",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-4.1-fast": {
			"id": "x-ai/grok-4.1-fast",
			"name": "xAI: Grok 4.1 Fast",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"x-ai/grok-code-fast-1": {
			"id": "x-ai/grok-code-fast-1",
			"name": "xAI: Grok Code Fast 1",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"xiaomi/mimo-v2-flash": {
			"id": "xiaomi/mimo-v2-flash",
			"name": "Xiaomi: MiMo-V2-Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4-32b": {
			"id": "z-ai/glm-4-32b",
			"name": "Z.ai: GLM 4 32B",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.5": {
			"id": "z-ai/glm-4.5",
			"name": "Z.ai: GLM 4.5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.5-air": {
			"id": "z-ai/glm-4.5-air",
			"name": "Z.ai: GLM 4.5 Air",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.5v": {
			"id": "z-ai/glm-4.5v",
			"name": "Z.ai: GLM 4.5V",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.6": {
			"id": "z-ai/glm-4.6",
			"name": "Z.ai: GLM 4.6",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.6:exacto": {
			"id": "z-ai/glm-4.6:exacto",
			"name": "Z.ai: GLM 4.6 (exacto)",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.6v": {
			"id": "z-ai/glm-4.6v",
			"name": "Z.ai: GLM 4.6V",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.7": {
			"id": "z-ai/glm-4.7",
			"name": "Z.ai: GLM 4.7",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-4.7-flash": {
			"id": "z-ai/glm-4.7-flash",
			"name": "Z.ai: GLM 4.7 Flash",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		},
		"z-ai/glm-5": {
			"id": "z-ai/glm-5",
			"name": "Z.ai: GLM 5",
			"api": "openai-completions",
			"provider": "kilo",
			"baseUrl": "https://api.kilo.ai/api/gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888
		}
	},
	"vercel-ai-gateway": {
		"alibaba/qwen-3-14b": {
			"id": "alibaba/qwen-3-14b",
			"name": "Qwen3-14B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.06,
				"output": 0.24,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 16384
		},
		"alibaba/qwen-3-235b": {
			"id": "alibaba/qwen-3-235b",
			"name": "Qwen3-235B-A22B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.071,
				"output": 0.463,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 16384
		},
		"alibaba/qwen-3-30b": {
			"id": "alibaba/qwen-3-30b",
			"name": "Qwen3-30B-A3B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.08,
				"output": 0.29,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 16384
		},
		"alibaba/qwen-3-32b": {
			"id": "alibaba/qwen-3-32b",
			"name": "Qwen 3 32B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 40960,
			"maxTokens": 16384
		},
		"alibaba/qwen3-235b-a22b-thinking": {
			"id": "alibaba/qwen3-235b-a22b-thinking",
			"name": "Qwen3 235B A22B Thinking 2507",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.9000000000000004,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262114,
			"maxTokens": 262114
		},
		"alibaba/qwen3-coder": {
			"id": "alibaba/qwen3-coder",
			"name": "Qwen3 Coder 480B A35B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.5999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 66536
		},
		"alibaba/qwen3-coder-30b-a3b": {
			"id": "alibaba/qwen3-coder-30b-a3b",
			"name": "Qwen 3 Coder 30B A3B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.27,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 160000,
			"maxTokens": 32768
		},
		"alibaba/qwen3-coder-next": {
			"id": "alibaba/qwen3-coder-next",
			"name": "Qwen3 Coder Next",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 1.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"alibaba/qwen3-coder-plus": {
			"id": "alibaba/qwen3-coder-plus",
			"name": "Qwen3 Coder Plus",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"alibaba/qwen3-max-preview": {
			"id": "alibaba/qwen3-max-preview",
			"name": "Qwen3 Max Preview",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.2,
				"output": 6,
				"cacheRead": 0.24,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32768
		},
		"alibaba/qwen3-max-thinking": {
			"id": "alibaba/qwen3-max-thinking",
			"name": "Qwen 3 Max Thinking",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.2,
				"output": 6,
				"cacheRead": 0.24,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 65536
		},
		"alibaba/qwen3-vl-thinking": {
			"id": "alibaba/qwen3-vl-thinking",
			"name": "Qwen3 VL 235B A22B Thinking",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.22,
				"output": 0.88,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"alibaba/qwen3.5-plus": {
			"id": "alibaba/qwen3.5-plus",
			"name": "Qwen 3.5 Plus",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2.4,
				"cacheRead": 0.04,
				"cacheWrite": 0.5
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"anthropic/claude-3-haiku": {
			"id": "anthropic/claude-3-haiku",
			"name": "Claude Haiku 3",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 1.25,
				"cacheRead": 0.03,
				"cacheWrite": 0.3
			},
			"contextWindow": 200000,
			"maxTokens": 4096
		},
		"anthropic/claude-3.5-haiku": {
			"id": "anthropic/claude-3.5-haiku",
			"name": "Claude Haiku 3.5 (latest)",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.7999999999999999,
				"output": 4,
				"cacheRead": 0.08,
				"cacheWrite": 1
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.5-sonnet": {
			"id": "anthropic/claude-3.5-sonnet",
			"name": "Claude Sonnet 3.5 v2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.5-sonnet-20240620": {
			"id": "anthropic/claude-3.5-sonnet-20240620",
			"name": "Claude 3.5 Sonnet (2024-06-20)",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"anthropic/claude-3.7-sonnet": {
			"id": "anthropic/claude-3.7-sonnet",
			"name": "Claude 3.7 Sonnet",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-haiku-4.5": {
			"id": "anthropic/claude-haiku-4.5",
			"name": "Claude Haiku 4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.09999999999999999,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-opus-4": {
			"id": "anthropic/claude-opus-4",
			"name": "Claude Opus 4 (latest)",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4.1": {
			"id": "anthropic/claude-opus-4.1",
			"name": "Claude Opus 4.1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"anthropic/claude-opus-4.5": {
			"id": "anthropic/claude-opus-4.5",
			"name": "Claude Opus 4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-opus-4.6": {
			"id": "anthropic/claude-opus-4.6",
			"name": "Claude Opus 4.6",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0.5,
				"cacheWrite": 6.25
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"anthropic/claude-sonnet-4": {
			"id": "anthropic/claude-sonnet-4",
			"name": "Claude Sonnet 4 (latest)",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4.5": {
			"id": "anthropic/claude-sonnet-4.5",
			"name": "Claude Sonnet 4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"anthropic/claude-sonnet-4.6": {
			"id": "anthropic/claude-sonnet-4.6",
			"name": "Claude Sonnet 4.6",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"arcee-ai/trinity-large-preview": {
			"id": "arcee-ai/trinity-large-preview",
			"name": "Trinity Large Preview",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131000,
			"maxTokens": 131000
		},
		"bytedance/seed-1.6": {
			"id": "bytedance/seed-1.6",
			"name": "Seed 1.6",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 32000
		},
		"cohere/command-a": {
			"id": "cohere/command-a",
			"name": "Command A",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8000
		},
		"deepseek/deepseek-v3": {
			"id": "deepseek/deepseek-v3",
			"name": "DeepSeek V3 0324",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.77,
				"output": 0.77,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 16384
		},
		"deepseek/deepseek-v3.1": {
			"id": "deepseek/deepseek-v3.1",
			"name": "DeepSeek-V3.1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.21,
				"output": 0.7899999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 163840,
			"maxTokens": 128000
		},
		"deepseek/deepseek-v3.1-terminus": {
			"id": "deepseek/deepseek-v3.1-terminus",
			"name": "DeepSeek V3.1 Terminus",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.27,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"deepseek/deepseek-v3.2": {
			"id": "deepseek/deepseek-v3.2",
			"name": "DeepSeek V3.2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.26,
				"output": 0.38,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8000
		},
		"deepseek/deepseek-v3.2-thinking": {
			"id": "deepseek/deepseek-v3.2-thinking",
			"name": "DeepSeek V3.2 Thinking",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.28,
				"output": 0.42,
				"cacheRead": 0.028,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000
		},
		"google/gemini-2.5-flash": {
			"id": "google/gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"google/gemini-2.5-flash-lite": {
			"id": "google/gemini-2.5-flash-lite",
			"name": "Gemini 2.5 Flash Lite",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-2.5-flash-lite-preview-09-2025": {
			"id": "google/gemini-2.5-flash-lite-preview-09-2025",
			"name": "Gemini 2.5 Flash Lite Preview 09-2025",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-2.5-flash-preview-09-2025": {
			"id": "google/gemini-2.5-flash-preview-09-2025",
			"name": "Gemini 2.5 Flash Preview 09-2025",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 65536
		},
		"google/gemini-2.5-pro": {
			"id": "google/gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"google/gemini-3-flash": {
			"id": "google/gemini-3-flash",
			"name": "Gemini 3 Flash",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 3,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"google/gemini-3-pro-preview": {
			"id": "google/gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"inception/mercury-coder-small": {
			"id": "inception/mercury-coder-small",
			"name": "Mercury Coder Small Beta",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.25,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 16384
		},
		"meituan/longcat-flash-chat": {
			"id": "meituan/longcat-flash-chat",
			"name": "LongCat Flash Chat",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"meituan/longcat-flash-thinking": {
			"id": "meituan/longcat-flash-thinking",
			"name": "LongCat Flash Thinking",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.15,
				"output": 1.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"meta/llama-3.1-70b": {
			"id": "meta/llama-3.1-70b",
			"name": "Llama 3.1 70B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 0.39999999999999997,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"meta/llama-3.1-8b": {
			"id": "meta/llama-3.1-8b",
			"name": "Llama 3.1 8B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.03,
				"output": 0.049999999999999996,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"meta/llama-3.2-11b": {
			"id": "meta/llama-3.2-11b",
			"name": "Llama 3.2 11B Vision Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.16,
				"output": 0.16,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"meta/llama-3.2-90b": {
			"id": "meta/llama-3.2-90b",
			"name": "Llama 3.2 90B Vision Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.72,
				"output": 0.72,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"meta/llama-3.3-70b": {
			"id": "meta/llama-3.3-70b",
			"name": "Llama 3.3 70B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.72,
				"output": 0.72,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"meta/llama-4-maverick": {
			"id": "meta/llama-4-maverick",
			"name": "Llama 4 Maverick 17B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"meta/llama-4-scout": {
			"id": "meta/llama-4-scout",
			"name": "Llama 4 Scout 17B Instruct",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.08,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"minimax/minimax-m2": {
			"id": "minimax/minimax-m2",
			"name": "MiniMax M2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.03,
				"cacheWrite": 0.375
			},
			"contextWindow": 205000,
			"maxTokens": 205000
		},
		"minimax/minimax-m2.1": {
			"id": "minimax/minimax-m2.1",
			"name": "MiniMax M2.1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"minimax/minimax-m2.1-lightning": {
			"id": "minimax/minimax-m2.1-lightning",
			"name": "MiniMax M2.1 Lightning",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 2.4,
				"cacheRead": 0.03,
				"cacheWrite": 0.375
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"minimax/minimax-m2.5": {
			"id": "minimax/minimax-m2.5",
			"name": "MiniMax M2.5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 1.2,
				"cacheRead": 0.03,
				"cacheWrite": 0.375
			},
			"contextWindow": 204800,
			"maxTokens": 131000
		},
		"mistral/codestral": {
			"id": "mistral/codestral",
			"name": "Mistral Codestral",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.8999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"mistral/devstral-2": {
			"id": "mistral/devstral-2",
			"name": "Devstral 2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"mistral/devstral-small": {
			"id": "mistral/devstral-small",
			"name": "Devstral Small 1.1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000
		},
		"mistral/devstral-small-2": {
			"id": "mistral/devstral-small-2",
			"name": "Devstral Small 2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"mistral/ministral-3b": {
			"id": "mistral/ministral-3b",
			"name": "Ministral 3B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.04,
				"output": 0.04,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"mistral/ministral-8b": {
			"id": "mistral/ministral-8b",
			"name": "Ministral 8B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.09999999999999999,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"mistral/mistral-medium": {
			"id": "mistral/mistral-medium",
			"name": "Mistral Medium 3.1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 64000
		},
		"mistral/mistral-small": {
			"id": "mistral/mistral-small",
			"name": "Mistral Small",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 4000
		},
		"mistral/pixtral-12b": {
			"id": "mistral/pixtral-12b",
			"name": "Pixtral 12B 2409",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"mistral/pixtral-large": {
			"id": "mistral/pixtral-large",
			"name": "Pixtral Large",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4000
		},
		"moonshotai/kimi-k2": {
			"id": "moonshotai/kimi-k2",
			"name": "Kimi K2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.5,
				"output": 2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 16384
		},
		"moonshotai/kimi-k2-thinking": {
			"id": "moonshotai/kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.47,
				"output": 2,
				"cacheRead": 0.14100000000000001,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"moonshotai/kimi-k2-thinking-turbo": {
			"id": "moonshotai/kimi-k2-thinking-turbo",
			"name": "Kimi K2 Thinking Turbo",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.15,
				"output": 8,
				"cacheRead": 0.15,
				"cacheWrite": 0
			},
			"contextWindow": 262114,
			"maxTokens": 262114
		},
		"moonshotai/kimi-k2-turbo": {
			"id": "moonshotai/kimi-k2-turbo",
			"name": "Kimi K2 Turbo",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 2.4,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 16384
		},
		"moonshotai/kimi-k2.5": {
			"id": "moonshotai/kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 2.8,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"nvidia/nemotron-nano-12b-v2-vl": {
			"id": "nvidia/nemotron-nano-12b-v2-vl",
			"name": "Nvidia Nemotron Nano 12B V2 VL",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"nvidia/nemotron-nano-9b-v2": {
			"id": "nvidia/nemotron-nano-9b-v2",
			"name": "Nvidia Nemotron Nano 9B V2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.04,
				"output": 0.16,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"openai/codex-mini": {
			"id": "openai/codex-mini",
			"name": "Codex Mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.5,
				"output": 6,
				"cacheRead": 0.375,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 100000
		},
		"openai/gpt-4-turbo": {
			"id": "openai/gpt-4-turbo",
			"name": "GPT-4 Turbo",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 30,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 4096
		},
		"openai/gpt-4.1": {
			"id": "openai/gpt-4.1",
			"name": "GPT-4.1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4.1-mini": {
			"id": "openai/gpt-4.1-mini",
			"name": "GPT-4.1 mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.39999999999999997,
				"output": 1.5999999999999999,
				"cacheRead": 0.09999999999999999,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4.1-nano": {
			"id": "openai/gpt-4.1-nano",
			"name": "GPT-4.1 nano",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.39999999999999997,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 1047576,
			"maxTokens": 32768
		},
		"openai/gpt-4o": {
			"id": "openai/gpt-4o",
			"name": "GPT-4o",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 1.25,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-4o-mini": {
			"id": "openai/gpt-4o-mini",
			"name": "GPT-4o mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.075,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5": {
			"id": "openai/gpt-5",
			"name": "GPT-5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-chat": {
			"id": "openai/gpt-5-chat",
			"name": "GPT-5 Chat",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5-codex": {
			"id": "openai/gpt-5-codex",
			"name": "GPT-5-Codex",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5-mini": {
			"id": "openai/gpt-5-mini",
			"name": "GPT-5 mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-nano": {
			"id": "openai/gpt-5-nano",
			"name": "GPT-5 nano",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.049999999999999996,
				"output": 0.39999999999999997,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5-pro": {
			"id": "openai/gpt-5-pro",
			"name": "GPT-5 pro",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 120,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 272000
		},
		"openai/gpt-5.1-codex": {
			"id": "openai/gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-max": {
			"id": "openai/gpt-5.1-codex-max",
			"name": "GPT 5.1 Codex Max",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-codex-mini": {
			"id": "openai/gpt-5.1-codex-mini",
			"name": "GPT-5.1 Codex mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.25,
				"output": 2,
				"cacheRead": 0.024999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.1-instant": {
			"id": "openai/gpt-5.1-instant",
			"name": "GPT-5.1 Instant",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5.1-thinking": {
			"id": "openai/gpt-5.1-thinking",
			"name": "GPT 5.1 Thinking",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.13,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2": {
			"id": "openai/gpt-5.2",
			"name": "GPT-5.2",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.18,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-chat": {
			"id": "openai/gpt-5.2-chat",
			"name": "GPT-5.2 Chat",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"openai/gpt-5.2-codex": {
			"id": "openai/gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"openai/gpt-5.2-pro": {
			"id": "openai/gpt-5.2-pro",
			"name": "GPT 5.2 ",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 21,
				"output": 168,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"openai/gpt-oss-120b": {
			"id": "openai/gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09999999999999999,
				"output": 0.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-20b": {
			"id": "openai/gpt-oss-20b",
			"name": "GPT OSS 20B",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.07,
				"output": 0.3,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/gpt-oss-safeguard-20b": {
			"id": "openai/gpt-oss-safeguard-20b",
			"name": "gpt-oss-safeguard-20b",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0.037,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		},
		"openai/o1": {
			"id": "openai/o1",
			"name": "o1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 60,
				"cacheRead": 7.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3": {
			"id": "openai/o3",
			"name": "o3",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 8,
				"cacheRead": 0.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-deep-research": {
			"id": "openai/o3-deep-research",
			"name": "o3-deep-research",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 10,
				"output": 40,
				"cacheRead": 2.5,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-mini": {
			"id": "openai/o3-mini",
			"name": "o3-mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.55,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o3-pro": {
			"id": "openai/o3-pro",
			"name": "o3-pro",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 20,
				"output": 80,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"openai/o4-mini": {
			"id": "openai/o4-mini",
			"name": "o4-mini",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.1,
				"output": 4.4,
				"cacheRead": 0.275,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 100000
		},
		"perplexity/sonar": {
			"id": "perplexity/sonar",
			"name": "Sonar",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 127000,
			"maxTokens": 8000
		},
		"perplexity/sonar-pro": {
			"id": "perplexity/sonar-pro",
			"name": "Sonar Pro",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8000
		},
		"prime-intellect/intellect-3": {
			"id": "prime-intellect/intellect-3",
			"name": "INTELLECT 3",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 1.1,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"vercel/v0-1.0-md": {
			"id": "vercel/v0-1.0-md",
			"name": "v0-1.0-md",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000
		},
		"vercel/v0-1.5-md": {
			"id": "vercel/v0-1.5-md",
			"name": "v0-1.5-md",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32768
		},
		"xai/grok-2-vision": {
			"id": "xai/grok-2-vision",
			"name": "Grok 2 Vision",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32768,
			"maxTokens": 32768
		},
		"xai/grok-3": {
			"id": "xai/grok-3",
			"name": "Grok 3 Beta",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"xai/grok-3-fast": {
			"id": "xai/grok-3-fast",
			"name": "Grok 3 Fast Beta",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 5,
				"output": 25,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"xai/grok-3-mini": {
			"id": "xai/grok-3-mini",
			"name": "Grok 3 Mini Beta",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.3,
				"output": 0.5,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"xai/grok-3-mini-fast": {
			"id": "xai/grok-3-mini-fast",
			"name": "Grok 3 Mini Fast Beta",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 4,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"xai/grok-4": {
			"id": "xai/grok-4",
			"name": "Grok 4",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"xai/grok-4-fast-non-reasoning": {
			"id": "xai/grok-4-fast-non-reasoning",
			"name": "Grok 4 Fast Non-Reasoning",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 256000
		},
		"xai/grok-4-fast-reasoning": {
			"id": "xai/grok-4-fast-reasoning",
			"name": "Grok 4 Fast Reasoning",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 256000
		},
		"xai/grok-4.1-fast-non-reasoning": {
			"id": "xai/grok-4.1-fast-non-reasoning",
			"name": "Grok 4.1 Fast Non-Reasoning",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"xai/grok-4.1-fast-reasoning": {
			"id": "xai/grok-4.1-fast-reasoning",
			"name": "Grok 4.1 Fast Reasoning",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 0.5,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"xai/grok-code-fast-1": {
			"id": "xai/grok-code-fast-1",
			"name": "Grok Code Fast 1",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 1.5,
				"cacheRead": 0.02,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 256000
		},
		"xiaomi/mimo-v2-flash": {
			"id": "xiaomi/mimo-v2-flash",
			"name": "MiMo V2 Flash",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.09,
				"output": 0.29,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32000
		},
		"zai/glm-4.5": {
			"id": "zai/glm-4.5",
			"name": "GLM-4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 2.2,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 131072
		},
		"zai/glm-4.5-air": {
			"id": "zai/glm-4.5-air",
			"name": "GLM 4.5 Air",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.19999999999999998,
				"output": 1.1,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 96000
		},
		"zai/glm-4.5v": {
			"id": "zai/glm-4.5v",
			"name": "GLM 4.5V",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.6,
				"output": 1.7999999999999998,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 65536,
			"maxTokens": 16384
		},
		"zai/glm-4.6": {
			"id": "zai/glm-4.6",
			"name": "GLM 4.6",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.44999999999999996,
				"output": 1.7999999999999998,
				"cacheRead": 0.11,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 96000
		},
		"zai/glm-4.6v": {
			"id": "zai/glm-4.6v",
			"name": "GLM-4.6V",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 0.8999999999999999,
				"cacheRead": 0.049999999999999996,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 24000
		},
		"zai/glm-4.6v-flash": {
			"id": "zai/glm-4.6v-flash",
			"name": "GLM-4.6V-Flash",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 24000
		},
		"zai/glm-4.7": {
			"id": "zai/glm-4.7",
			"name": "GLM 4.7",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.43,
				"output": 1.75,
				"cacheRead": 0.08,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 120000
		},
		"zai/glm-4.7-flashx": {
			"id": "zai/glm-4.7-flashx",
			"name": "GLM 4.7 FlashX",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.06,
				"output": 0.39999999999999997,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"zai/glm-5": {
			"id": "zai/glm-5",
			"name": "GLM-5",
			"api": "anthropic-messages",
			"baseUrl": "https://ai-gateway.vercel.sh",
			"provider": "vercel-ai-gateway",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3.1999999999999997,
				"cacheRead": 0.19999999999999998,
				"cacheWrite": 0
			},
			"contextWindow": 202800,
			"maxTokens": 131072
		}
	},
	"kimi-code": {
		"kimi-for-coding": {
			"id": "kimi-for-coding",
			"name": "Kimi For Coding",
			"api": "openai-completions",
			"provider": "kimi-code",
			"baseUrl": "https://api.kimi.com/coding/v1",
			"headers": {
				"User-Agent": "KimiCLI/1.0",
				"X-Msh-Platform": "kimi_cli"
			},
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32000,
			"compat": {
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content",
				"supportsDeveloperRole": false
			}
		},
		"kimi-k2": {
			"id": "kimi-k2",
			"name": "Kimi K2",
			"api": "openai-completions",
			"provider": "kimi-code",
			"baseUrl": "https://api.kimi.com/coding/v1",
			"headers": {
				"User-Agent": "KimiCLI/1.0",
				"X-Msh-Platform": "kimi_cli"
			},
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144,
			"compat": {
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content",
				"supportsDeveloperRole": false
			}
		},
		"kimi-k2-turbo-preview": {
			"id": "kimi-k2-turbo-preview",
			"name": "Kimi K2 Turbo Preview",
			"api": "openai-completions",
			"provider": "kimi-code",
			"baseUrl": "https://api.kimi.com/coding/v1",
			"headers": {
				"User-Agent": "KimiCLI/1.0",
				"X-Msh-Platform": "kimi_cli"
			},
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 32000,
			"compat": {
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content",
				"supportsDeveloperRole": false
			}
		},
		"kimi-k2.5": {
			"id": "kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "kimi-code",
			"baseUrl": "https://api.kimi.com/coding/v1",
			"headers": {
				"User-Agent": "KimiCLI/1.0",
				"X-Msh-Platform": "kimi_cli"
			},
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536,
			"compat": {
				"thinkingFormat": "zai",
				"reasoningContentField": "reasoning_content",
				"supportsDeveloperRole": false
			}
		}
	},
	"synthetic": {
		"hf:deepseek-ai/DeepSeek-R1-0528": {
			"id": "hf:deepseek-ai/DeepSeek-R1-0528",
			"name": "deepseek-ai/DeepSeek-R1-0528",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"hf:deepseek-ai/DeepSeek-V3": {
			"id": "hf:deepseek-ai/DeepSeek-V3",
			"name": "deepseek-ai/DeepSeek-V3",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"hf:deepseek-ai/DeepSeek-V3-0324": {
			"id": "hf:deepseek-ai/DeepSeek-V3-0324",
			"name": "deepseek-ai/DeepSeek-V3-0324",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"hf:deepseek-ai/DeepSeek-V3.2": {
			"id": "hf:deepseek-ai/DeepSeek-V3.2",
			"name": "deepseek-ai/DeepSeek-V3.2",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 162816,
			"maxTokens": 8192
		},
		"hf:meta-llama/Llama-3.3-70B-Instruct": {
			"id": "hf:meta-llama/Llama-3.3-70B-Instruct",
			"name": "meta-llama/Llama-3.3-70B-Instruct",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"hf:MiniMaxAI/MiniMax-M2.1": {
			"id": "hf:MiniMaxAI/MiniMax-M2.1",
			"name": "MiniMaxAI/MiniMax-M2.1",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 196608,
			"maxTokens": 8192
		},
		"hf:MiniMaxAI/MiniMax-M2.5": {
			"id": "hf:MiniMaxAI/MiniMax-M2.5",
			"name": "MiniMaxAI/MiniMax-M2.5",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 191488,
			"maxTokens": 8192
		},
		"hf:moonshotai/Kimi-K2-Instruct-0905": {
			"id": "hf:moonshotai/Kimi-K2-Instruct-0905",
			"name": "moonshotai/Kimi-K2-Instruct-0905",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:moonshotai/Kimi-K2-Thinking": {
			"id": "hf:moonshotai/Kimi-K2-Thinking",
			"name": "moonshotai/Kimi-K2-Thinking",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:moonshotai/Kimi-K2.5": {
			"id": "hf:moonshotai/Kimi-K2.5",
			"name": "moonshotai/Kimi-K2.5",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:nvidia/Kimi-K2.5-NVFP4": {
			"id": "hf:nvidia/Kimi-K2.5-NVFP4",
			"name": "nvidia/Kimi-K2.5-NVFP4",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:openai/gpt-oss-120b": {
			"id": "hf:openai/gpt-oss-120b",
			"name": "openai/gpt-oss-120b",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"hf:Qwen/Qwen3-235B-A22B-Thinking-2507": {
			"id": "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
			"name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:Qwen/Qwen3-Coder-480B-A35B-Instruct": {
			"id": "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
			"name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:Qwen/Qwen3.5-397B-A17B": {
			"id": "hf:Qwen/Qwen3.5-397B-A17B",
			"name": "Qwen/Qwen3.5-397B-A17B",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"hf:zai-org/GLM-4.7": {
			"id": "hf:zai-org/GLM-4.7",
			"name": "zai-org/GLM-4.7",
			"api": "openai-completions",
			"provider": "synthetic",
			"baseUrl": "https://api.synthetic.new/openai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 202752,
			"maxTokens": 8192
		}
	},
	"venice": {
		"claude-opus-4-5": {
			"id": "claude-opus-4-5",
			"name": "Claude Opus 4.5 (latest)",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"claude-opus-4-6": {
			"id": "claude-opus-4-6",
			"name": "Claude Opus 4.6",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 128000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"claude-opus-45": {
			"id": "claude-opus-45",
			"name": "Claude Opus 4.5",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"claude-sonnet-4-5": {
			"id": "claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5 (latest)",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"claude-sonnet-4-6": {
			"id": "claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"claude-sonnet-45": {
			"id": "claude-sonnet-45",
			"name": "Claude Sonnet 4.5",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"deepseek-v3.2": {
			"id": "deepseek-v3.2",
			"name": "DeepSeek V3.2",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 160000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"gemini-3-1-pro-preview": {
			"id": "gemini-3-1-pro-preview",
			"name": "gemini-3-1-pro-preview",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"gemini-3-flash-preview": {
			"id": "gemini-3-flash-preview",
			"name": "Gemini 3 Flash Preview",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"google-gemma-3-27b-it": {
			"id": "google-gemma-3-27b-it",
			"name": "Google Gemma 3 27B Instruct",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"grok-41-fast": {
			"id": "grok-41-fast",
			"name": "Grok 4.1 Fast",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"grok-code-fast-1": {
			"id": "grok-code-fast-1",
			"name": "Grok Code Fast 1",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 10000,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"hermes-3-llama-3.1-405b": {
			"id": "hermes-3-llama-3.1-405b",
			"name": "Hermes 3 Llama 3.1 405b",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"kimi-k2-5": {
			"id": "kimi-k2-5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"kimi-k2-thinking": {
			"id": "kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"llama-3.2-3b": {
			"id": "llama-3.2-3b",
			"name": "Llama 3.2 3B",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"llama-3.3-70b": {
			"id": "llama-3.3-70b",
			"name": "Llama 3.3 70B",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"minimax-m21": {
			"id": "minimax-m21",
			"name": "MiniMax M2.1",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"minimax-m25": {
			"id": "minimax-m25",
			"name": "MiniMax M2.5",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"mistral-31-24b": {
			"id": "mistral-31-24b",
			"name": "Venice Medium",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"nvidia-nemotron-3-nano-30b-a3b": {
			"id": "nvidia-nemotron-3-nano-30b-a3b",
			"name": "nvidia-nemotron-3-nano-30b-a3b",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"olafangensan-glm-4.7-flash-heretic": {
			"id": "olafangensan-glm-4.7-flash-heretic",
			"name": "GLM 4.7 Flash Heretic",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"openai-gpt-4o-2024-11-20": {
			"id": "openai-gpt-4o-2024-11-20",
			"name": "openai-gpt-4o-2024-11-20",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"openai-gpt-4o-mini-2024-07-18": {
			"id": "openai-gpt-4o-mini-2024-07-18",
			"name": "openai-gpt-4o-mini-2024-07-18",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"openai-gpt-52": {
			"id": "openai-gpt-52",
			"name": "GPT-5.2",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"openai-gpt-52-codex": {
			"id": "openai-gpt-52-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"openai-gpt-53-codex": {
			"id": "openai-gpt-53-codex",
			"name": "openai-gpt-53-codex",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"openai-gpt-oss-120b": {
			"id": "openai-gpt-oss-120b",
			"name": "OpenAI GPT OSS 120B",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-235b-a22b-instruct-2507": {
			"id": "qwen3-235b-a22b-instruct-2507",
			"name": "Qwen 3 235B A22B Instruct 2507",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-235b-a22b-thinking-2507": {
			"id": "qwen3-235b-a22b-thinking-2507",
			"name": "Qwen 3 235B A22B Thinking 2507",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-4b": {
			"id": "qwen3-4b",
			"name": "Venice Small",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-5-35b-a3b": {
			"id": "qwen3-5-35b-a3b",
			"name": "qwen3-5-35b-a3b",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-coder-480b-a35b-instruct": {
			"id": "qwen3-coder-480b-a35b-instruct",
			"name": "Qwen 3 Coder 480b",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-coder-480b-a35b-instruct-turbo": {
			"id": "qwen3-coder-480b-a35b-instruct-turbo",
			"name": "qwen3-coder-480b-a35b-instruct-turbo",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-next-80b": {
			"id": "qwen3-next-80b",
			"name": "Qwen 3 Next 80b",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"qwen3-vl-235b-a22b": {
			"id": "qwen3-vl-235b-a22b",
			"name": "Qwen3 VL 235B",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"venice-uncensored": {
			"id": "venice-uncensored",
			"name": "Venice Uncensored 1.1",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 32000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"zai-org-glm-4.6": {
			"id": "zai-org-glm-4.6",
			"name": "zai-org-glm-4.6",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 222222,
			"maxTokens": 8888,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"zai-org-glm-4.7": {
			"id": "zai-org-glm-4.7",
			"name": "GLM 4.7",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"zai-org-glm-4.7-flash": {
			"id": "zai-org-glm-4.7-flash",
			"name": "GLM 4.7 Flash",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		},
		"zai-org-glm-5": {
			"id": "zai-org-glm-5",
			"name": "GLM 5",
			"api": "openai-completions",
			"provider": "venice",
			"baseUrl": "https://api.venice.ai/api/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 198000,
			"maxTokens": 8192,
			"compat": {
				"supportsUsageInStreaming": false
			}
		}
	},
	"litellm": {
		"claude-3-5-haiku": {
			"id": "claude-3-5-haiku",
			"name": "Claude Haiku 3.5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 8192
		},
		"claude-3-5-haiku-20241022": {
			"id": "claude-3-5-haiku-20241022",
			"name": "claude-3-5-haiku-20241022",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"claude-3-7-sonnet": {
			"id": "claude-3-7-sonnet",
			"name": "claude-3-7-sonnet",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"claude-3-7-sonnet-20250219": {
			"id": "claude-3-7-sonnet-20250219",
			"name": "claude-3-7-sonnet-20250219",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"claude-haiku-4-5": {
			"id": "claude-haiku-4-5",
			"name": "Claude Haiku 4.5 (latest)",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-haiku-4-5-20251001": {
			"id": "claude-haiku-4-5-20251001",
			"name": "Claude Haiku 4.5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4": {
			"id": "claude-opus-4",
			"name": "claude-opus-4",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"claude-opus-4-1": {
			"id": "claude-opus-4-1",
			"name": "Claude Opus 4.1 (latest)",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-1-20250805": {
			"id": "claude-opus-4-1-20250805",
			"name": "Claude Opus 4.1",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-20250514": {
			"id": "claude-opus-4-20250514",
			"name": "Claude Opus 4",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 32000
		},
		"claude-opus-4-5": {
			"id": "claude-opus-4-5",
			"name": "Claude Opus 4.5 (latest)",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-5-20251101": {
			"id": "claude-opus-4-5-20251101",
			"name": "Claude Opus 4.5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-6": {
			"id": "claude-opus-4-6",
			"name": "Claude Opus 4.6",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"claude-sonnet-4": {
			"id": "claude-sonnet-4",
			"name": "Claude Sonnet 4",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-20250514": {
			"id": "claude-sonnet-4-20250514",
			"name": "Claude Sonnet 4",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5": {
			"id": "claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5 (latest)",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5-20250929": {
			"id": "claude-sonnet-4-5-20250929",
			"name": "Claude Sonnet 4.5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-6": {
			"id": "claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"gemini-2.5-flash": {
			"id": "gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite": {
			"id": "gemini-2.5-flash-lite",
			"name": "Gemini 2.5 Flash Lite",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-flash": {
			"id": "gemini-3-flash",
			"name": "Gemini 3 Flash",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-flash-preview": {
			"id": "gemini-3-flash-preview",
			"name": "Gemini 3 Flash Preview",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro": {
			"id": "gemini-3-pro",
			"name": "Gemini 3 Pro",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		},
		"glm-4.5": {
			"id": "glm-4.5",
			"name": "GLM-4.5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 98304
		},
		"glm-4.5-air": {
			"id": "glm-4.5-air",
			"name": "GLM-4.5-Air",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 98304
		},
		"glm-4.6": {
			"id": "glm-4.6",
			"name": "GLM-4.6",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-4.7": {
			"id": "glm-4.7",
			"name": "GLM-4.7",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"glm-5": {
			"id": "glm-5",
			"name": "GLM-5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 204800,
			"maxTokens": 131072
		},
		"gpt-5": {
			"id": "gpt-5",
			"name": "GPT-5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5-codex": {
			"id": "gpt-5-codex",
			"name": "GPT-5-Codex",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5-codex-mini": {
			"id": "gpt-5-codex-mini",
			"name": "gpt-5-codex-mini",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 4096
		},
		"gpt-5.1": {
			"id": "gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex": {
			"id": "gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-max": {
			"id": "gpt-5.1-codex-max",
			"name": "GPT-5.1 Codex Max",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-mini": {
			"id": "gpt-5.1-codex-mini",
			"name": "GPT-5.1 Codex mini",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.2": {
			"id": "gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.2-codex": {
			"id": "gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex": {
			"id": "gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex-spark": {
			"id": "gpt-5.3-codex-spark",
			"name": "GPT-5.3 Codex Spark",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000,
			"contextPromotionTarget": "litellm/gpt-5.3-codex"
		},
		"grok-4-1-fast-non-reasoning": {
			"id": "grok-4-1-fast-non-reasoning",
			"name": "Grok 4.1 Fast (Non-Reasoning)",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"grok-4-1-fast-reasoning": {
			"id": "grok-4-1-fast-reasoning",
			"name": "grok-4-1-fast-reasoning",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"grok-4-fast-non-reasoning": {
			"id": "grok-4-fast-non-reasoning",
			"name": "Grok 4 Fast (Non-Reasoning)",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 2000000,
			"maxTokens": 30000
		},
		"grok-4-fast-reasoning": {
			"id": "grok-4-fast-reasoning",
			"name": "grok-4-fast-reasoning",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"grok-code-fast-1": {
			"id": "grok-code-fast-1",
			"name": "Grok Code Fast 1",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 10000
		},
		"grok-imagine-image": {
			"id": "grok-imagine-image",
			"name": "grok-imagine-image",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"grok-imagine-video": {
			"id": "grok-imagine-video",
			"name": "grok-imagine-video",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 4096,
			"maxTokens": 4096
		},
		"kimi-k2": {
			"id": "kimi-k2",
			"name": "Kimi K2",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"kimi-k2-thinking": {
			"id": "kimi-k2-thinking",
			"name": "Kimi K2 Thinking",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 262144
		},
		"kimi-k2.5": {
			"id": "kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		},
		"zai-glm-4.7": {
			"id": "zai-glm-4.7",
			"name": "Z.AI GLM-4.7",
			"api": "openai-completions",
			"provider": "litellm",
			"baseUrl": "http://localhost:4000/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 40000
		}
	},
	"cursor": {
		"claude-4.5-opus-high": {
			"id": "claude-4.5-opus-high",
			"name": "Claude 4.5 Opus",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.5-opus-high-thinking": {
			"id": "claude-4.5-opus-high-thinking",
			"name": "Claude 4.5 Opus (Thinking)",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.5-sonnet": {
			"id": "claude-4.5-sonnet",
			"name": "Claude 4.5 Sonnet",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.5-sonnet-thinking": {
			"id": "claude-4.5-sonnet-thinking",
			"name": "Claude 4.5 Sonnet (Thinking)",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.6-opus-high": {
			"id": "claude-4.6-opus-high",
			"name": "Claude 4.6 Opus",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.6-opus-high-thinking": {
			"id": "claude-4.6-opus-high-thinking",
			"name": "Claude 4.6 Opus (Thinking)",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.6-sonnet-medium": {
			"id": "claude-4.6-sonnet-medium",
			"name": "Claude 4.6 Sonnet",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-4.6-sonnet-medium-thinking": {
			"id": "claude-4.6-sonnet-medium-thinking",
			"name": "Claude 4.6 Sonnet (Thinking)",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"composer-1": {
			"id": "composer-1",
			"name": "Composer 1",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"composer-1.5": {
			"id": "composer-1.5",
			"name": "Composer 1.5",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"default": {
			"id": "default",
			"name": "Auto",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"gemini-3-flash": {
			"id": "gemini-3-flash",
			"name": "Gemini 3 Flash",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro": {
			"id": "gemini-3-pro",
			"name": "Gemini 3 Pro",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3.1-pro": {
			"id": "gemini-3.1-pro",
			"name": "Gemini 3.1 Pro Preview",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gpt-5.1-codex-max": {
			"id": "gpt-5.1-codex-max",
			"name": "GPT-5.1 Codex Max",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-max-high": {
			"id": "gpt-5.1-codex-max-high",
			"name": "GPT-5.1 Codex Max High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-codex-mini": {
			"id": "gpt-5.1-codex-mini",
			"name": "GPT-5.1 Codex mini",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.1-high": {
			"id": "gpt-5.1-high",
			"name": "GPT-5.1 High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"gpt-5.2": {
			"id": "gpt-5.2",
			"name": "GPT-5.2",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.2-codex": {
			"id": "gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.2-codex-fast": {
			"id": "gpt-5.2-codex-fast",
			"name": "GPT-5.2 Codex Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-codex-high": {
			"id": "gpt-5.2-codex-high",
			"name": "GPT-5.2 Codex High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-codex-high-fast": {
			"id": "gpt-5.2-codex-high-fast",
			"name": "GPT-5.2 Codex High Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-codex-low": {
			"id": "gpt-5.2-codex-low",
			"name": "GPT-5.2 Codex Low",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-codex-low-fast": {
			"id": "gpt-5.2-codex-low-fast",
			"name": "GPT-5.2 Codex Low Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-codex-xhigh": {
			"id": "gpt-5.2-codex-xhigh",
			"name": "GPT-5.2 Codex Extra High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-codex-xhigh-fast": {
			"id": "gpt-5.2-codex-xhigh-fast",
			"name": "GPT-5.2 Codex Extra High Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.2-high": {
			"id": "gpt-5.2-high",
			"name": "GPT-5.2 High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex": {
			"id": "gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"gpt-5.3-codex-fast": {
			"id": "gpt-5.3-codex-fast",
			"name": "GPT-5.3 Codex Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-high": {
			"id": "gpt-5.3-codex-high",
			"name": "GPT-5.3 Codex High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-high-fast": {
			"id": "gpt-5.3-codex-high-fast",
			"name": "GPT-5.3 Codex High Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-low": {
			"id": "gpt-5.3-codex-low",
			"name": "GPT-5.3 Codex Low",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-low-fast": {
			"id": "gpt-5.3-codex-low-fast",
			"name": "GPT-5.3 Codex Low Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-spark-preview": {
			"id": "gpt-5.3-codex-spark-preview",
			"name": "GPT-5.3 Codex Spark",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-xhigh": {
			"id": "gpt-5.3-codex-xhigh",
			"name": "GPT-5.3 Codex Extra High",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"gpt-5.3-codex-xhigh-fast": {
			"id": "gpt-5.3-codex-xhigh-fast",
			"name": "GPT-5.3 Codex Extra High Fast",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 64000
		},
		"grok-code-fast-1": {
			"id": "grok-code-fast-1",
			"name": "Grok Code Fast 1",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 256000,
			"maxTokens": 10000
		},
		"kimi-k2.5": {
			"id": "kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "cursor-agent",
			"provider": "cursor",
			"baseUrl": "https://api2.cursor.sh",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		}
	},
	"gitlab-duo": {
		"claude-haiku-4-5-20251001": {
			"id": "claude-haiku-4-5-20251001",
			"name": "Claude Haiku 4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"provider": "gitlab-duo"
		},
		"claude-opus-4-5-20251101": {
			"id": "claude-opus-4-5-20251101",
			"name": "Claude Opus 4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"provider": "gitlab-duo"
		},
		"claude-sonnet-4-5-20250929": {
			"id": "claude-sonnet-4-5-20250929",
			"name": "Claude Sonnet 4.5",
			"api": "anthropic-messages",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000,
			"provider": "gitlab-duo"
		},
		"duo-chat-gpt-5-1": {
			"id": "duo-chat-gpt-5-1",
			"name": "Duo Chat GPT-5.1",
			"api": "openai-completions",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"duo-chat-gpt-5-2": {
			"id": "duo-chat-gpt-5-2",
			"name": "Duo Chat GPT-5.2",
			"api": "openai-completions",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"duo-chat-gpt-5-2-codex": {
			"id": "duo-chat-gpt-5-2-codex",
			"name": "Duo Chat GPT-5.2 Codex",
			"api": "openai-responses",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"duo-chat-gpt-5-codex": {
			"id": "duo-chat-gpt-5-codex",
			"name": "Duo Chat GPT-5 Codex",
			"api": "openai-responses",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000
		},
		"duo-chat-gpt-5-mini": {
			"id": "duo-chat-gpt-5-mini",
			"name": "Duo Chat GPT-5 Mini",
			"api": "openai-completions",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384
		},
		"duo-chat-haiku-4-5": {
			"id": "duo-chat-haiku-4-5",
			"name": "Duo Chat Haiku 4.5",
			"api": "anthropic-messages",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1,
				"output": 5,
				"cacheRead": 0.1,
				"cacheWrite": 1.25
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"duo-chat-opus-4-5": {
			"id": "duo-chat-opus-4-5",
			"name": "Duo Chat Opus 4.5",
			"api": "anthropic-messages",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 15,
				"output": 75,
				"cacheRead": 1.5,
				"cacheWrite": 18.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"duo-chat-opus-4-6": {
			"id": "duo-chat-opus-4-6",
			"name": "Duo Chat Opus 4.6",
			"api": "anthropic-messages",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"duo-chat-sonnet-4-5": {
			"id": "duo-chat-sonnet-4-5",
			"name": "Duo Chat Sonnet 4.5",
			"api": "anthropic-messages",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 3,
				"output": 15,
				"cacheRead": 0.3,
				"cacheWrite": 3.75
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"duo-chat-sonnet-4-6": {
			"id": "duo-chat-sonnet-4-6",
			"name": "Duo Chat Sonnet 4.6",
			"api": "anthropic-messages",
			"provider": "gitlab-duo",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/anthropic/",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"gpt-5-codex": {
			"id": "gpt-5-codex",
			"name": "GPT-5-Codex",
			"api": "openai-responses",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"provider": "gitlab-duo"
		},
		"gpt-5-mini-2025-08-07": {
			"id": "gpt-5-mini-2025-08-07",
			"name": "GPT-5 Mini",
			"api": "openai-responses",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384,
			"provider": "gitlab-duo"
		},
		"gpt-5.1-2025-11-13": {
			"id": "gpt-5.1-2025-11-13",
			"name": "GPT-5.1",
			"api": "openai-responses",
			"baseUrl": "https://cloud.gitlab.com/ai/v1/proxy/openai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2.5,
				"output": 10,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 16384,
			"provider": "gitlab-duo"
		}
	},
	"openai-codex": {
		"gpt-5": {
			"id": "gpt-5",
			"name": "GPT-5",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 11
		},
		"gpt-5-codex": {
			"id": "gpt-5-codex",
			"name": "GPT-5-Codex",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 10
		},
		"gpt-5-codex-mini": {
			"id": "gpt-5-codex-mini",
			"name": "gpt-5-codex-mini",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 13
		},
		"gpt-5.1": {
			"id": "gpt-5.1",
			"name": "GPT-5.1",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 7
		},
		"gpt-5.1-codex": {
			"id": "gpt-5.1-codex",
			"name": "GPT-5.1 Codex",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 5
		},
		"gpt-5.1-codex-max": {
			"id": "gpt-5.1-codex-max",
			"name": "GPT-5.1 Codex Max",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 4
		},
		"gpt-5.1-codex-mini": {
			"id": "gpt-5.1-codex-mini",
			"name": "GPT-5.1 Codex mini",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 12
		},
		"gpt-5.2": {
			"id": "gpt-5.2",
			"name": "GPT-5.2",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 400000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 6
		},
		"gpt-5.2-codex": {
			"id": "gpt-5.2-codex",
			"name": "GPT-5.2 Codex",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"preferWebsockets": true,
			"priority": 3
		},
		"gpt-5.3-codex": {
			"id": "gpt-5.3-codex",
			"name": "GPT-5.3 Codex",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 272000,
			"maxTokens": 128000,
			"priority": 0
		},
		"gpt-5.3-codex-spark": {
			"id": "gpt-5.3-codex-spark",
			"name": "GPT-5.3 Codex Spark",
			"api": "openai-codex-responses",
			"provider": "openai-codex",
			"baseUrl": "https://chatgpt.com/backend-api",
			"reasoning": true,
			"preferWebsockets": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.75,
				"output": 14,
				"cacheRead": 0.175,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 32000,
			"contextPromotionTarget": "openai-codex/gpt-5.3-codex"
		}
	},
	"google-antigravity": {
		"claude-opus-4-5-thinking": {
			"id": "claude-opus-4-5-thinking",
			"name": "Claude Opus 4.5 Thinking (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-opus-4-6-thinking": {
			"id": "claude-opus-4-6-thinking",
			"name": "Claude Opus 4.6 (Thinking) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5": {
			"id": "claude-sonnet-4-5",
			"name": "Claude Sonnet 4.5 (latest)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-5-thinking": {
			"id": "claude-sonnet-4-5-thinking",
			"name": "Claude Sonnet 4.5 Thinking (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-6": {
			"id": "claude-sonnet-4-6",
			"name": "Claude Sonnet 4.6",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 64000
		},
		"claude-sonnet-4-6-thinking": {
			"id": "claude-sonnet-4-6-thinking",
			"name": "Claude Sonnet 4.6 Thinking (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 200000,
			"maxTokens": 128000
		},
		"gemini-2.5-flash": {
			"id": "gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-thinking": {
			"id": "gemini-2.5-flash-thinking",
			"name": "Gemini 2.5 Flash (Thinking) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-flash": {
			"id": "gemini-3-flash",
			"name": "Gemini 3 Flash",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro-high": {
			"id": "gemini-3-pro-high",
			"name": "Gemini 3 Pro (High) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"gemini-3-pro-low": {
			"id": "gemini-3-pro-low",
			"name": "Gemini 3 Pro (Low) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"gemini-3.1-pro-high": {
			"id": "gemini-3.1-pro-high",
			"name": "Gemini 3.1 Pro (High) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"gemini-3.1-pro-low": {
			"id": "gemini-3.1-pro-low",
			"name": "Gemini 3.1 Pro (Low) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65535
		},
		"gpt-oss-120b-medium": {
			"id": "gpt-oss-120b-medium",
			"name": "GPT-OSS 120B (Medium) (Antigravity)",
			"api": "google-gemini-cli",
			"provider": "google-antigravity",
			"baseUrl": "https://daily-cloudcode-pa.sandbox.googleapis.com",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 114000,
			"maxTokens": 32768
		}
	},
	"moonshot": {
		"kimi-k2.5": {
			"id": "kimi-k2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "moonshot",
			"baseUrl": "https://api.moonshot.ai/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 262144,
			"maxTokens": 65536
		}
	},
	"qianfan": {
		"deepseek-v3.2": {
			"id": "deepseek-v3.2",
			"name": "DeepSeek V3.2",
			"api": "openai-completions",
			"provider": "qianfan",
			"baseUrl": "https://qianfan.baidubce.com/v2",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 98304,
			"maxTokens": 32768
		}
	},
	"together": {
		"deepseek-ai/DeepSeek-R1": {
			"id": "deepseek-ai/DeepSeek-R1",
			"name": "DeepSeek R1",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 7,
				"cacheRead": 3,
				"cacheWrite": 3
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"deepseek-ai/DeepSeek-V3.1": {
			"id": "deepseek-ai/DeepSeek-V3.1",
			"name": "DeepSeek V3.1",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 1.25,
				"cacheRead": 0.6,
				"cacheWrite": 0.6
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"meta-llama/Llama-3.3-70B-Instruct-Turbo": {
			"id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
			"name": "Llama 3.3 70B Instruct Turbo",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.88,
				"output": 0.88,
				"cacheRead": 0.88,
				"cacheWrite": 0.88
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
			"id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
			"name": "Llama 4 Maverick 17B 128E Instruct FP8",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.27,
				"output": 0.85,
				"cacheRead": 0.27,
				"cacheWrite": 0.27
			},
			"contextWindow": 20000000,
			"maxTokens": 32768
		},
		"meta-llama/Llama-4-Scout-17B-16E-Instruct": {
			"id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
			"name": "Llama 4 Scout 17B 16E Instruct",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.18,
				"output": 0.59,
				"cacheRead": 0.18,
				"cacheWrite": 0.18
			},
			"contextWindow": 10000000,
			"maxTokens": 32768
		},
		"moonshotai/Kimi-K2-Instruct-0905": {
			"id": "moonshotai/Kimi-K2-Instruct-0905",
			"name": "Kimi K2-Instruct 0905",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 1,
				"output": 3,
				"cacheRead": 1,
				"cacheWrite": 3
			},
			"contextWindow": 262144,
			"maxTokens": 8192
		},
		"moonshotai/Kimi-K2.5": {
			"id": "moonshotai/Kimi-K2.5",
			"name": "Kimi K2.5",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 2.8,
				"cacheRead": 0.5,
				"cacheWrite": 2.8
			},
			"contextWindow": 262144,
			"maxTokens": 32768
		},
		"zai-org/GLM-4.7": {
			"id": "zai-org/GLM-4.7",
			"name": "GLM 4.7 Fp8",
			"api": "openai-completions",
			"provider": "together",
			"baseUrl": "https://api.together.xyz/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.45,
				"output": 2,
				"cacheRead": 0.45,
				"cacheWrite": 2
			},
			"contextWindow": 202752,
			"maxTokens": 8192
		}
	},
	"qwen-portal": {
		"coder-model": {
			"id": "coder-model",
			"name": "Qwen Coder",
			"api": "openai-completions",
			"provider": "qwen-portal",
			"baseUrl": "https://portal.qwen.ai/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		},
		"vision-model": {
			"id": "vision-model",
			"name": "Qwen Vision",
			"api": "openai-completions",
			"provider": "qwen-portal",
			"baseUrl": "https://portal.qwen.ai/v1",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 128000,
			"maxTokens": 8192
		}
	},
	"google-gemini-cli": {
		"gemini-2.0-flash": {
			"id": "gemini-2.0-flash",
			"name": "Gemini 2.0 Flash",
			"api": "google-gemini-cli",
			"provider": "google-gemini-cli",
			"baseUrl": "https://cloudcode-pa.googleapis.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"gemini-2.5-flash": {
			"id": "gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "google-gemini-cli",
			"provider": "google-gemini-cli",
			"baseUrl": "https://cloudcode-pa.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "google-gemini-cli",
			"provider": "google-gemini-cli",
			"baseUrl": "https://cloudcode-pa.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-flash-preview": {
			"id": "gemini-3-flash-preview",
			"name": "Gemini 3 Flash Preview",
			"api": "google-gemini-cli",
			"provider": "google-gemini-cli",
			"baseUrl": "https://cloudcode-pa.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "google-gemini-cli",
			"provider": "google-gemini-cli",
			"baseUrl": "https://cloudcode-pa.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		}
	},
	"google-vertex": {
		"gemini-1.5-flash": {
			"id": "gemini-1.5-flash",
			"name": "Gemini 1.5 Flash",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0.01875,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 8192
		},
		"gemini-1.5-flash-8b": {
			"id": "gemini-1.5-flash-8b",
			"name": "Gemini 1.5 Flash-8B",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.0375,
				"output": 0.15,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 8192
		},
		"gemini-1.5-pro": {
			"id": "gemini-1.5-pro",
			"name": "Gemini 1.5 Pro",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 5,
				"cacheRead": 0.3125,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 8192
		},
		"gemini-2.0-flash": {
			"id": "gemini-2.0-flash",
			"name": "Gemini 2.0 Flash",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.15,
				"output": 0.6,
				"cacheRead": 0.0375,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"gemini-2.0-flash-lite": {
			"id": "gemini-2.0-flash-lite",
			"name": "Gemini 2.0 Flash Lite",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": false,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.075,
				"output": 0.3,
				"cacheRead": 0.01875,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 8192
		},
		"gemini-2.5-flash": {
			"id": "gemini-2.5-flash",
			"name": "Gemini 2.5 Flash",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.3,
				"output": 2.5,
				"cacheRead": 0.03,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite": {
			"id": "gemini-2.5-flash-lite",
			"name": "Gemini 2.5 Flash Lite",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-flash-lite-preview-09-2025": {
			"id": "gemini-2.5-flash-lite-preview-09-2025",
			"name": "Gemini 2.5 Flash Lite Preview 09-25",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.1,
				"output": 0.4,
				"cacheRead": 0.01,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-2.5-pro": {
			"id": "gemini-2.5-pro",
			"name": "Gemini 2.5 Pro",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 1.25,
				"output": 10,
				"cacheRead": 0.125,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-flash-preview": {
			"id": "gemini-3-flash-preview",
			"name": "Gemini 3 Flash Preview",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 0.5,
				"output": 3,
				"cacheRead": 0.05,
				"cacheWrite": 0
			},
			"contextWindow": 1048576,
			"maxTokens": 65536
		},
		"gemini-3-pro-preview": {
			"id": "gemini-3-pro-preview",
			"name": "Gemini 3 Pro Preview",
			"api": "google-vertex",
			"provider": "google-vertex",
			"baseUrl": "https://{location}-aiplatform.googleapis.com",
			"reasoning": true,
			"input": [
				"text",
				"image"
			],
			"cost": {
				"input": 2,
				"output": 12,
				"cacheRead": 0.2,
				"cacheWrite": 0
			},
			"contextWindow": 1000000,
			"maxTokens": 64000
		}
	},
	"huggingface": {
		"deepseek-ai/DeepSeek-R1": {
			"id": "deepseek-ai/DeepSeek-R1",
			"name": "DeepSeek R1",
			"api": "openai-completions",
			"provider": "huggingface",
			"baseUrl": "https://router.huggingface.co/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 3,
				"output": 7,
				"cacheRead": 3,
				"cacheWrite": 3
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"deepseek-ai/DeepSeek-V3.1": {
			"id": "deepseek-ai/DeepSeek-V3.1",
			"name": "DeepSeek V3.1",
			"api": "openai-completions",
			"provider": "huggingface",
			"baseUrl": "https://router.huggingface.co/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.6,
				"output": 1.25,
				"cacheRead": 0.6,
				"cacheWrite": 0.6
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"meta-llama/Llama-3.3-70B-Instruct-Turbo": {
			"id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
			"name": "Llama 3.3 70B Instruct Turbo",
			"api": "openai-completions",
			"provider": "huggingface",
			"baseUrl": "https://router.huggingface.co/v1",
			"reasoning": false,
			"input": [
				"text"
			],
			"cost": {
				"input": 0.88,
				"output": 0.88,
				"cacheRead": 0.88,
				"cacheWrite": 0.88
			},
			"contextWindow": 131072,
			"maxTokens": 8192
		},
		"openai/gpt-oss-120b": {
			"id": "openai/gpt-oss-120b",
			"name": "GPT OSS 120B",
			"api": "openai-completions",
			"provider": "huggingface",
			"baseUrl": "https://router.huggingface.co/v1",
			"reasoning": true,
			"input": [
				"text"
			],
			"cost": {
				"input": 0,
				"output": 0,
				"cacheRead": 0,
				"cacheWrite": 0
			},
			"contextWindow": 131072,
			"maxTokens": 65536
		}
	}
}